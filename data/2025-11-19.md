<div id=toc></div>

# Table of Contents

- [eess.SY](#eess.SY) [Total: 22]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.LG](#cs.LG) [Total: 57]


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [1] [Deep reinforcement learning-based spacecraft attitude control with pointing keep-out constraint](https://arxiv.org/abs/2511.13746)
*Juntang Yang,Mohamed Khalil Ben-Larbi*

Main category: eess.SY

TL;DR: 论文通过深度强化学习（DRL）实现航天器的单指向禁区重新定向控制，采用SAC算法处理连续状态和动作空间。


<details>
  <summary>Details</summary>
Motivation: 航天器在重新定向时需避开特定禁区，传统方法难以处理复杂约束，因此研究基于DRL的解决方案。

Method: 使用SAC算法，设计新状态表示以明确包含禁区信息，并设计奖励函数以实现控制目标。通过课程学习训练智能体。

Result: 仿真结果表明该方法在航天器指向约束的姿态控制中有效。

Conclusion: 基于DRL的方法为航天器复杂约束控制提供了有效解决方案。

Abstract: This paper implements deep reinforcement learning (DRL) for spacecraft reorientation control with a single pointing keep-out zone. The Soft Actor-Critic (SAC) algorithm is adopted to handle continuous state and action space. A new state representation is designed to explicitly include a compact representation of the attitude constraint zone. The reward function is formulated to achieve the control objective while enforcing the attitude constraint. A curriculum learning approach is used for the agent training. Simulation results demonstrate the effectiveness of the proposed DRL-based method for spacecraft pointing-constrained attitude control.

</details>


### [2] [Game-theoretic Decentralized Coordination for Airspace Sector Overload Mitigation](https://arxiv.org/abs/2511.13770)
*Jaehan Im,Daniel Delahaye,David Fridovich-Keil,Ufuk Topcu*

Main category: eess.SY

TL;DR: 提出了一种基于最佳响应动态的分散式空中交通管理系统机制，通过调整航班起飞时间减少拥堵，无需共享决策，实验证明能大幅减少超载。


<details>
  <summary>Details</summary>
Motivation: 分散式空中交通管理系统假设高度合作，但实践中各部门独立运作且优先考虑本地目标，导致假设失效，本文旨在解决部门超载问题。

Method: 设计了一种机制，各部门通过最佳响应动态调整航班起飞时间以减少自身拥堵，引入可调合作因子模拟对其他部门超载的容忍度。

Result: 机制满足潜在博弈结构，确保最佳响应动态收敛至纯纳什均衡；数值实验显示即使部门间仅有最小合作，也能显著减少超载。

Conclusion: 该机制在可扩展性和解质量上媲美集中式求解器，为分散式空中交通管理提供了有效解决方案。

Abstract: Decentralized air traffic management systems offer a scalable alternative to centralized control, but often assume high levels of cooperation. In practice, such assumptions frequently break down since airspace sectors operate independently and prioritize local objectives. We address the problem of sector overload in decentralized air traffic management by proposing a mechanism that models self-interested behaviors based on best response dynamics. Each sector adjusts the departure times of flights under its control to reduce its own congestion, without any shared decision making. A tunable cooperativeness factor models the degree to which each sector is willing to reduce overload in other sectors. We prove that the proposed mechanism satisfies a potential game structure, ensuring that best response dynamics converge to a pure Nash equilibrium, under a mild restriction. In addition, we identify a sufficient condition under which an overload-free solution corresponds to a global minimizer of the potential function. Numerical experiments using 24 hours of European flight data demonstrate that the proposed algorithm substantially reduces overload even with only minimal cooperation between sectors, while maintaining scalability and matching the solution quality of centralized solvers.

</details>


### [3] [Quantifying Distribution Shift in Traffic Signal Control with Histogram-Based GEH Distance](https://arxiv.org/abs/2511.13785)
*Federico Taschin,Ozan K. Tonguz*

Main category: eess.SY

TL;DR: 论文提出了一种基于需求直方图和GEH距离的方法，用于量化交通信号控制算法中的分布偏移，并在实验中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 交通信号控制算法在遇到与训练条件不同的交通场景时性能下降，需要一种可解释且独立于控制策略的方法来量化这种分布偏移。

Method: 通过将交通场景表示为需求直方图，并基于GEH距离函数进行比较，提出了一种量化分布偏移的方法。

Result: 实验表明，较大的场景距离对应更长的旅行时间和更低吞吐量，尤其在基于学习的控制器中表现显著。

Conclusion: 该方法优于现有技术，适用于交通信号控制的基准测试、训练设计和状态监控。

Abstract: Traffic signal control algorithms are vulnerable to distribution shift, where performance degrades under traffic conditions that differ from those seen during design or training. This paper introduces a principled approach to quantify distribution shift by representing traffic scenarios as demand histograms and comparing them with a GEH-based distance function. The method is policy-independent, interpretable, and leverages a widely used traffic engineering statistic. We validate the approach on 20 simulated scenarios using both a NEMA actuated controller and a reinforcement learning controller (FRAP++). Results show that larger scenario distances consistently correspond to increased travel time and reduced throughput, with particularly strong explanatory power for learning-based control. Overall, this method can predict performance degradation under distribution shift better than previously published techniques. These findings highlight the utility of the proposed framework for benchmarking, training regime design, and monitoring in adaptive traffic signal control.

</details>


### [4] [Just Few States are Enough: Randomized Sparse Feedback for Stability of Dynamical Systems](https://arxiv.org/abs/2511.13870)
*Zaid Hadach,Hajar El Hammouti,El Houcine Bergou,Adnane Saoud*

Main category: eess.SY

TL;DR: 该论文研究了在控制器只能随机访问状态向量子集的情况下，如何设计反馈增益矩阵和测量稀疏化策略，以确保闭环系统的渐近均方稳定性（AMSS），并提出了基于LMI的算法来优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统控制理论假设控制器可以访问全部状态测量值，而实际场景中可能只能随机访问部分状态。论文旨在解决这种更现实的反馈控制问题。

Method: 通过分析动态系统的条件，提出基于线性矩阵不等式（LMI）的算法，联合计算稳定的增益矩阵和随机稀疏化策略。

Result: 在特定情况下，系统仅需测量0.3%的状态坐标，即可实现与全状态反馈相当的性能。

Conclusion: 论文首次研究了依赖随机状态测量的控制系统稳定性，提供了理论条件和算法，为实际应用提供了新的解决方案。

Abstract: While classical control theory assumes that the controller has access to measurements of the entire state (or output) at every time instant, this paper investigates a setting where the feedback controller can only access a randomly selected subset of the state vector at each time step. Due to the random sparsification that selects only a subset of the state components at each step, we analyze the stability of the closed-loop system in terms of Asymptotic Mean-Square Stability (AMSS), which ensures that the system state converges to zero in the mean-square sense. We consider the problem of designing both a feedback gain matrix and a measurement sparsification strategy that minimizes the number of state components required for feedback, while ensuring AMSS of the closed-loop system. Interestingly, (1) we provide conditions on the dynamics of the system under which it is possible to find a sparsification strategy, and (2) we propose a Linear Matrix Inequality (LMI) based algorithm that jointly computes a stabilizing gain matrix, and a randomized sparsification strategy that minimizes the expected number of measured state coordinates while preserving the AMSS. Our approach is then extended to the case where the sparsification probabilities vary across the state components. Based on these theoretical findings, we propose an algorithmic procedure to compute the vector of sparsification parameters, along with the corresponding feedback gain matrix. To the best of our knowledge, this is the first study to investigate the stability properties of control systems that rely solely on randomly selected state measurements. Numerical simulations demonstrate that, in some settings, the system achieves comparable performance to full-state feedback while requiring measurements from only $0.3\%$ of the state coordinates.

</details>


### [5] [Dynamic state estimation of hybrid systems: Inverters that switch between grid-following and grid-forming control schemes](https://arxiv.org/abs/2511.13872)
*Bukunmi G. Odunlami,Marcos Netto*

Main category: eess.SY

TL;DR: 该论文提出了一种用于逆变器的混合系统建模框架，能够在电网跟随和电网形成控制方案之间切换，通过改进状态估计和动态稳定性表现优于连续模型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为逆变器设计一种混合系统建模框架，使其能够在电网跟随和电网形成控制方案之间灵活切换，并解决模式切换时的状态一致性问题。

Method: 论文方法是将逆变器建模为带有电压和频率保护条件的混合自动机，并嵌入扩展卡尔曼滤波器来评估模式切换下的估计性能。

Result: 结果显示，该框架能够确保稳定且良好的动态性能，并在切换时刻附近显著改善状态估计。

Conclusion: 论文结论是该混合建模框架在逆变器控制中具有优越性，特别是在模式切换时的动态性能和状态估计方面。

Abstract: This paper develops a hybrid system modeling framework for inverters that switch between grid-following and grid-forming control schemes. In particular, such inverters are modeled as hybrid automata with guard conditions on voltage and frequency, and reset maps that maintain consistent phase, frequency, and droop references during mode transitions. The hybrid model is embedded within an extended Kalman filter to assess estimation performance under explicit mode switching. Results show that the proposed framework ensures stable, well-behaved dynamics and improves state estimation, especially near switching instants, compared with smooth continuous models.

</details>


### [6] [L-Functions Certify Set Attractivity for Discrete-Time Uncertain Nonlinear Switched Systems](https://arxiv.org/abs/2511.13906)
*Alejandro Anderson,Esteban A. Hernandez-Vargas,Giulia Giordano*

Main category: eess.SY

TL;DR: 该论文提出了一种用于离散时间不确定非线性切换系统的L函数类，以验证集合的吸引性。通过构造性方法获得分段连续的L函数，证明了其存在性与鲁棒局部吸引性的关联，并通过案例展示了方法的实用性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为不确定非线性切换系统提供一种验证集合吸引性的方法，解决鲁棒局部吸引性问题，并通过生物系统案例验证其实际应用价值。

Method: 方法是通过构造分段连续的L函数，基于系统的收缩集来证明集合的鲁棒局部吸引性。

Result: 结果表明，存在鲁棒控制收缩集时，相应的L函数也存在，从而验证了集合的吸引性。

Conclusion: 结论是提出的框架能有效地验证非线性切换系统的集合吸引性，且在实际生物系统分析中具有应用潜力。

Abstract: We introduce the class of L-functions to certify the attractivity of sets for uncertain nonlinear switched systems in discrete time. The existence of an L-function associated with a set guarantees the robust local attractivity of that set under the system dynamics. We propose a constructive method for obtaining piecewise-continuous L-functions based on contractive sets for the system, and show that the existence of a robust control contractive set for the dynamics implies the existence of an appropriate L-function, and hence the robust local attractivity of the set itself. We illustrate the proposed framework through examples that elucidate the theoretical concepts, and through the case study of a nonlinear switched system modelling antimicrobial resistance, which highlights the relevance of the approach to the analysis of biological systems.

</details>


### [7] [dkpy: Robust Control with Structured Uncertainty in Python](https://arxiv.org/abs/2511.13927)
*Timothy Everett Adams,Steven Dahdah,James Richard Forbes*

Main category: eess.SY

TL;DR: 论文介绍了一个名为dkpy的开源Python工具包，用于处理结构化不确定性下的鲁棒控制器分析和设计，同时支持基于扰动系统数据的模型不确定性表征。


<details>
  <summary>Details</summary>
Motivation: 针对控制系统设计中模型不确定性问题，需要确保闭环系统的鲁棒性。现有的μ分析和μ综合方法能够处理结构化不确定性问题，但缺乏开源工具支持。

Method: 作者开发了dkpy，一个Python包，用于实现鲁棒控制器的分析和设计，并提供工具通过扰动系统数据表征模型不确定性。

Result: dkpy实现了对结构化不确定性系统的鲁棒性分析和控制器设计，并通过开源方式提供。

Conclusion: dkpy为鲁棒控制研究提供了一个实用且开源的工具，支持结构化不确定性系统的分析和设计。

Abstract: Models used for control design are, to some degree, uncertain. Model uncertainty must be accounted for to ensure the robustness of the closed-loop system. $μ$-analysis and $μ$-synthesis methods allow for the analysis and design of controllers subject to structured uncertainties. Moreover, these tools can be applied to robust performance problems as they are fundamentally robust control problems with structured uncertainty. The contribution of this paper is dkpy, an open-source Python package for performing robust controller analysis and synthesis for systems subject to structured uncertainty. dkpy also provides tools for performing model uncertainty characterization using data from a set of perturbed systems. The open-source project can be found at https://github.com/decargroup/dkpy.

</details>


### [8] [Power Delivery for Cryogenic Scalable Quantum Applications: Challenges and Opportunities](https://arxiv.org/abs/2511.13965)
*Yating Zou,Batuhan Keskin,Gregor G. Taylor,Zenghui Li,Jie Wang,Eduard Alarcon,Fabio Sebastiano,Masoud Babaie,Edoardo Charbon*

Main category: eess.SY

TL;DR: 该论文探讨了在稀释冰箱中实现可扩展功率传输的几种候选架构，分析了各种方案在热负载、功率损耗、噪声等方面的表现，最终提出高压非辐射传输是一个有前景的方案。


<details>
  <summary>Details</summary>
Motivation: 随着量子系统规模扩展到数百万个量子比特，传统室温控制与低温量子比特之间的线材传输方法会带来严重挑战，如热负载和噪声耦合，需要更高效的功率传输架构。

Method: 论文评估了四种候选架构：高压有线传输、辐射无线传输、非辐射无线传输，以及高压与非辐射传输的混合方案，并对它们在热负载、功率损耗等多个维度进行了对比分析。

Result: 比较分析表明，高压非辐射传输在热负载、功率密度和可扩展性方面表现出色，适合大规模量子系统的需求。

Conclusion: 高压非辐射传输被认为是解决量子系统中功率传输问题的有前景方案。

Abstract: Quantum technologies offer unprecedented capabilities in computation and secure information transfer. Their implementation requires qubits to operate at cryogenic temperatures (CT) while control and readout electronics typically still remains at room temperature (RT). As systems scale to millions of qubits, the electronics should also operate at CT to avoid a wiring bottleneck. However, wired power transfer from RT for such electronics introduces severe challenges, including thermal load between cooling stages, Joule heating, noise coupling, and wiring scalability. This paper addresses those challenges by evaluating several candidate architectures for scalable power transfer in the dilution frige: high-voltage (HV) wired power transfer, radiative wireless transfer, non-radiative wireless transfer, and a hybrid HV and non-radiative transfer. These architectures are analyzed in terms of thermal load, power loss, heating, coupling noise, power density, scalability, reliability, and complexity. Comparative analysis demonstrates the trade-offs among these architectures, while highlighting HV non-radiative transfer as a promising candidate for scalable quantum systems.

</details>


### [9] [Data Center Control Against Sub-Synchronous Resonance: A Data-Driven Approach](https://arxiv.org/abs/2511.14141)
*Grant Ruan,Marija D. Ilic,Le Xie*

Main category: eess.SY

TL;DR: 论文研究了数据中心与电网互联时可能引发的次同步共振(SSR)风险，通过两频扫描和阻抗建模评估风险，并开发了预防性控制器以提高安全性。


<details>
  <summary>Details</summary>
Motivation: 由于数据中心的独特运行特性，电网运营商对其可靠性风险了解有限，尤其是可能引发次同步共振(SSR)的问题，可能导致设备损坏或级联故障。此研究旨在填补这一知识空白。

Method: 采用两频扫描技术研究数据中心的阻抗特性(幅值和相位角随频率变化)，并通过阻抗建模直接评估SSR风险。基于阻抗模型，开发了数据驱动的预防控制器，用于早期预警和灵活工作负载管理。

Result: 阻抗模型能有效捕捉数据中心独特的阻抗下降并跟踪不同工作负载场景下的变化。早期预警和预防控制方法可显著提高安全裕度，同时最小化工作负载重新调度。

Conclusion: 该研究为电网运营商和数据中心管理者提供了评估和预防SSR风险的实用工具，并为未来大规模数据中心并网提供了技术支持。

Abstract: Data centers host a variety of essential services such as cloud computing and artificial intelligence. Electric grid operators, however, have limited knowledge of the reliability risks of data center interconnection due to their unique operational characteristics. An emerging concern is the sub-synchronous resonance (SSR) which refer to unexpected voltage/current oscillations at typical frequencies below 60/50 Hz. It remains unknown whether and how the interactions between data centers and the grid may trigger resonances, equipment damages, and even cascading failures. In this paper, we focus on grid-connected data centers that draw electricity from the grid through power factor correction (PFC) converters. We conduct two-tone frequency sweep to investigate the data centers' impedance characteristics, i.e. magnitude and phase angle variations over frequencies, and showcase their deep dependence on compute workloads. The impedance modeling provides a direct approach to evaluating SSR risks and enable a cooperative mechanism to alarm and avoid resonance-prone situations. Building upon the impedance, a data-driven preventive controller is then established to raise early warnings of risky operation and suggest flexible workload management according to the given grid conditions. Through case study, we demonstrate how to use impedance to understand the unexpected interactions. Data-driven impedance is validated to show decent performance in capturing the unique impedance dips and tracking the impedance variations across a range of workload scenarios. The early warning and preventive control approaches are further effective to improve the safety margins with minimal workload rescheduling. The key findings of this work will provide valuable insights for grid operators and data center managers, and support preparation for future scenarios involving large-scale data center integration.

</details>


### [10] [Uncertainty Discounting in Deterministic Black Box Price Predictions for Energy Arbitrage](https://arxiv.org/abs/2511.14158)
*Arnab Bhattacharjee*

Main category: eess.SY

TL;DR: 研究探讨了预测能源管理中后验不确定性折扣的经济影响，通过简单启发式方法提高电池能源套利的经济回报。


<details>
  <summary>Details</summary>
Motivation: 传统MPC框架依赖确定性电价预测，缺乏对不确定性的考虑，导致策略易受极端价格波动影响。

Method: 提出无需访问预测模型架构的简单启发式不确定性折扣方法，集成到现有MPC框架中。

Result: 在相同操作约束下，经济回报提高了20%以上。

Conclusion: 该方法提升了能源套利的决策效果，同时保持实用性和可扩展性。

Abstract: This study examines the economic impact of post-hoc uncertainty discounting in predictive energy management, specifically in battery energy arbitrage. A 2.2 MWh, 1.1 MW Tesla battery, emulating operations at the University of Queensland's St. Lucia campus, is used as a test system. Traditionally, Model Predictive Control (MPC) frameworks rely on deterministic spot price forecasts from the Australian Energy Market Operator (AEMO) to optimize battery scheduling. However, these forecasts lack uncertainty awareness, making arbitrage strategies vulnerable to extreme price volatility. To address this, we propose simple heuristic uncertainty discounting methods, which require no access to the predictive model's architecture or inputs. By integrating these strategies into existing MPC frameworks, we demonstrate a more than 20% improvement in economic returns under identical operational constraints. This approach enhances decision-making in energy arbitrage while remaining practical, scalable, and independent of specific forecasting models

</details>


### [11] [A Receding Horizon Reinforcement Learning Framework for Campus Chiller Energy Management - A case study from an Australian University](https://arxiv.org/abs/2511.14160)
*Laura Musgrave,Arnab Bhattacharjee,Tapan Kumar Saha*

Main category: eess.SY

TL;DR: 本研究通过强化学习优化澳大利亚某大学校园大型HVAC系统的能源管理，相比传统方法节省28%的电力。


<details>
  <summary>Details</summary>
Motivation: 通过优化HVAC系统能源管理，减少电力消耗并提高效率。

Method: 使用强化学习（PPO算法）和预测性冷却需求模型，动态调整冷水机组的质量流量。

Result: 相比传统规则控制方法，节省28%的电力且约束违规次数极少。

Conclusion: 基于强化学习的控制器显著提高HVAC系统的能源效率，具有实际应用潜力。

Abstract: This work presents a case study of optimal energy management of a large Heating Ventilation and Cooling (HVAC) system within a university campus in Australia using Reinforcement Learning (RL). The HVAC system supplies to nine university buildings with an annual average electricity consumption of $\sim2$ GWh. Updated chiller Coefficient of Performance (COP) curves are identified, and a predictive building cooling demand model is developed using historical data from the HVAC system. Based on these inputs, a Proximal Policy Optimization based RL model is trained to optimally schedule the chillers in a receding horizon control framework with a priority reward function for constraint satisfaction. Compared to the traditional way of controlling the HVAC system based on a reactive rule-based method, the proposed controller saves up to 28\% of the electricity consumed by simply controlling the mass flow rates of the chiller banks and with minimal constraint violations.

</details>


### [12] [Entirely Transformerless Universal Direct-Injection Power-Flow Controller](https://arxiv.org/abs/2511.14209)
*Davood Keshavarzi,Alexander Koehler,Wolfram H. Wellssow,Stefan M. Goetz*

Main category: eess.SY

TL;DR: 本文介绍了一种新型的高电流全功率流控制电路，用于解决低压电网中的电力管理问题，避免了传统解决方案中笨重且昂贵的变压器。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源、电动汽车充电器和储能系统的普及，低压电网面临电力管理和稳定性问题（如反向功率流、线路过载和电压过高/过低）。传统的解决方案因使用变压器而体积庞大且成本高昂。

Method: 提出了一种无变压器的紧凑型部分功率转换高电流全功率流控制电路，结合了硅和碳化硅的优势，减少了半导体需求，并通过非隔离逆变器与低压串联模块双向连接。

Result: 通过数学分析、仿真和实验验证，该电路能够有效运行，解决了传统方案的成本和体积问题。

Conclusion: 该电路在成本和尺寸上优于传统解决方案，为低压电网的电力管理提供了高效且紧凑的新方法。

Abstract: An increasing penetration of renewable energy resources, electric vehicle chargers, and energy storage systems into low-voltage power grids causes several power management and stability problems, such as reverse power flow, (local) overload lines, and over- / under-voltage. Previous power-flow and soft-open-point solutions are bulky and expensive. They need transformers and large magnetics, some on grid frequency, others more compact at high frequency. Even suggested circuits with high-frequency transformers still struggle with cost and size. We present a compact partial power-conversion high-current full-power-flow control circuit without a single transformer. We combine silicon and silicon-carbide, each with their specific advantages for current-dense direct injection. The circuit further needs fewer semiconductors than previous concepts. The circuit links a shunt converter through a non-isolated inverter bidirectionally with low-voltage series modules that practically float with their respective phases can serve between different feeders in low-voltage power grids. We analyze the circuit mathematically and evaluate the operation in simulation and experimental results.

</details>


### [13] [Secure parameter identification of ARX systems with CKKS cryptosystem](https://arxiv.org/abs/2511.14267)
*Jialong Chen,Jimin Wang,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 该论文提出了一种基于CKKS加密系统的ARX系统参数识别算法，保护系统输入输出数据，兼具安全性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决云端ARX系统参数识别中的隐私保护问题，确保输入输出数据的安全性。

Method: 采用CKKS加密系统，通过投影映射和随机逼近方法，确保算法的正确加密解密和收敛性。

Result: 算法与标准CKKS具有相同安全级别，并通过数值示例验证其有效性。

Conclusion: 该算法成功实现了隐私保护的ARX系统参数识别，兼具安全性和可靠性。

Abstract: This paper focuses on the cloud-based parameter identification problem of ARX systems while protecting the system input and output. To do so, a CKKS-cryptosystem-based parameter identification algorithm is proposed. By rigorously proving that the statistical distance between the Gaussian distribution and the truncated discrete one is negligible, the algorithm has the same security level as the standard CKKS cryptosystem. By utilizing the projection mapping on the estimates, the conditions for correct encryption and decryption are given. Based on these conditions, the stochastic approximation method is further employed to achieve the almost sure and mean square convergence of the algorithm. The effectiveness is demonstrated through a numerical example.

</details>


### [14] [Multi-Timescale Model Predictive Control for Slow-Fast Systems](https://arxiv.org/abs/2511.14311)
*Lukas Schroth,Daniel Morton,Amon Lahr,Daniele Gammelli,Andrea Carron,Marco Pavone*

Main category: eess.SY

TL;DR: 该论文提出了一种多时间尺度的MPC方案，通过使用简化的慢动态模型和指数增加的积分步长，显著提高了计算效率，同时保持了对快速和慢动态系统的控制效果。


<details>
  <summary>Details</summary>
Motivation: 由于MPC中模型的高保真度需求与实时优化问题计算的复杂性之间的矛盾，论文提出了基于灵敏度指数衰减（EDS）结果的多时间尺度MPC方案，以解决这一问题。

Method: 论文采用多时间尺度MPC方法，包括切换到仅捕捉慢动态的简化模型和沿预测范围指数增加积分步长，以减少模型细节并提高计算效率。

Result: 在三个机器人控制问题的仿真中，该方法实现了高达一个数量级的加速效果。

Conclusion: 所提出的多时间尺度MPC方案能有效平衡模型保真度与计算效率，适用于具有快慢动态的系统。

Abstract: Model Predictive Control (MPC) has established itself as the primary methodology for constrained control, enabling autonomy across diverse applications. While model fidelity is crucial in MPC, solving the corresponding optimization problem in real time remains challenging when combining long horizons with high-fidelity models that capture both short-term dynamics and long-term behavior. Motivated by results on the Exponential Decay of Sensitivities (EDS), which imply that, under certain conditions, the influence of modeling inaccuracies decreases exponentially along the prediction horizon, this paper proposes a multi-timescale MPC scheme for fast-sampled control. Tailored to systems with both fast and slow dynamics, the proposed approach improves computational efficiency by i) switching to a reduced model that captures only the slow, dominant dynamics and ii) exponentially increasing integration step sizes to progressively reduce model detail along the horizon. We evaluate the method on three practically motivated robotic control problems in simulation and observe speed-ups of up to an order of magnitude.

</details>


### [15] [An adaptive extension to robust data-driven predictive control under parametric uncertainty](https://arxiv.org/abs/2511.14319)
*Ignacio Sanchez,Filiberto Fele,Daniel Limon*

Main category: eess.SY

TL;DR: 本文提出了一种结合离线与在线数据的鲁棒数据驱动控制方法，用于稳定参数时变的线性系统。通过放松持续激励要求，利用半定优化设计稳定控制器。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒数据驱动控制器依赖历史实验数据，但无法完全适应时变系统操作条件。本文旨在结合离线与在线数据，提高控制性能。

Method: 采用数据信息框架，同时利用覆盖系统参数极端变化的离线数据集和最新状态的在线滚动窗口数据，通过半定优化设计状态反馈控制律。

Result: 数值实验表明，该方法有效稳定了时变线性系统，并为与在线数据一致的系统提供了成本上限。

Conclusion: 该方法通过结合离线与在线数据，放松了对持续激励的要求，成功设计出稳定控制器，适用于参数时变的线性系统。

Abstract: Robust data-driven controllers typically rely on datasets from previous experiments, which embed information on the variability of the system parameters across past operational conditions. Complementarily, data collected online can contribute to improving the feedback performance relative to the current system's conditions, but are unable to account for the overall -- possibly time-varying -- system operation.
  With this in mind, we consider the problem of stabilizing a time-varying linear system, whose parameters are only known to lie within a bounded polytopic set. Taking a robust data-driven approach, we synthesize the control law by simultaneously leveraging two sets of historical state and input measures: an offline dataset -- which covers the extreme variations of the system parameters -- and an online dataset consisting of a rolling window of the latest state and input samples.
  Our approach relies on the data informativity framework: we thus relax persistent excitation requirements (i.e., the collected samples need not be sufficient for system identification), while still allowing for the design of a stabilizing controller. The state feedback law is obtained from standard Lyapunov arguments, implemented via semi-definite optimization: this also yields an upper bound on the cost-to-go for the class of systems that are consistent with the online data, while guaranteeing a decreasing cost for all systems compatible with the offline data. Numerical experiments are presented to illustrate the effectiveness of the proposed controller.

</details>


### [16] [Offset-free Data-Driven Predictive Control for Grid-Connected Power Converters in Weak Grid Faults](https://arxiv.org/abs/2511.14337)
*Ivo Kraayeveld,Thomas de Jong,Mircea Lazar*

Main category: eess.SY

TL;DR: 论文提出了一种无偏移数据驱动预测控制器，用于替代传统的PI控制器，以提升弱电网故障下的电网故障穿越能力。


<details>
  <summary>Details</summary>
Motivation: 传统PI控制器在弱电网故障下响应振荡且性能不佳，亟需一种更稳定、高效的解决方案。

Method: 采用无偏移数据驱动预测控制器，利用故障前或故障时数据构建输入-输出预测器，无需依赖物理模型。

Result: 仿真显示，该控制器在故障时将临界等效电网阻抗提升一倍，并将均方根误差降低40倍，计算时间与传统PI控制相当。

Conclusion: 无偏移数据预测控制器简单、鲁棒且计算高效，显著提升了弱电网转换器的故障穿越能力。

Abstract: Grid-connected power converters encounter significant stability challenges during weak grid faults, when conventional PI-based controllers exhibit an oscillatory response and poor fault-ride-through performance. This paper addresses this problem by replacing the conventional outer PI controllers that regulate DC-link and PCC voltages with an offset-free data-driven predictive controller. The developed algorithm leverages either pre-fault or fault-time data to construct input-output predictors, yielding offset-free control without the need for physics-based modelling. Simulation results show that pre-fault offset-free DPC doubles the critical equivalent grid impedance that can be handled and reduces the root mean squared error during faults by a factor of 40, while maintaining computation times comparable to conventional PI control. These findings demonstrate that the developed offset-free data predictive controller offers a simple, robust, and computationally efficient alternative to conventional control, significantly enhancing fault-ride-through capabilities of converters in weak grids.

</details>


### [17] [Identifying Time-varying Costs in Finite-horizon Linear Quadratic Gaussian Games](https://arxiv.org/abs/2511.14358)
*Kai Ren,Maryam Kamgarpour*

Main category: eess.SY

TL;DR: 论文研究了有限时域线性二次高斯博弈中的成本识别问题，提出了一种反向传播算法，用于识别给定纳什均衡策略的成本参数，并在数值和驾驶模拟中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在博弈论中，理解玩家行为背后的成本参数是关键。现有研究在识别这些参数时存在不足，因此需要一种高效的方法来准确识别产生特定纳什均衡策略的成本参数。

Method: 采用反向传播算法识别时变成本参数，并通过有限轨迹的数据推导了概率误差界限。

Result: 算法成功识别出能够复现纳什均衡策略和轨迹观测的成本参数，数值和驾驶模拟验证了其准确性。

Conclusion: 该方法为博弈中的成本参数识别提供了有效工具，特别是对于需要精确行为建模的应用场景。

Abstract: We address cost identification in a finite-horizon linear quadratic Gaussian game. We characterize the set of cost parameters that generate a given Nash equilibrium policy. We propose a backpropagation algorithm to identify the time-varying cost parameters. We derive a probabilistic error bound when the cost parameters are identified from finite trajectories. We test our method in numerical and driving simulations. Our algorithm identifies the cost parameters that can reproduce the Nash equilibrium policy and trajectory observations.

</details>


### [18] [Accelerating Automatic Differentiation of Direct Form Digital Filters](https://arxiv.org/abs/2511.14390)
*Chin-Yun Yu,György Fazekas*

Main category: eess.SY

TL;DR: 提出了一种通用的自动微分方法，通过直接形式滤波器的封闭式反向传播，包括初始条件梯度，实现了高效并行计算。


<details>
  <summary>Details</summary>
Motivation: 传统方法在计算滤波器梯度时效率较低，且不支持并行化，需要一种更高效的方法。

Method: 使用直接形式滤波器，生成封闭式反向传播表达式，支持初始条件梯度，并实现C++/CUDA加速。

Result: PyTorch实现比朴素Python快1000倍以上，GPU上运行最快，低阶滤波器在时间域方法中表现更优。

Conclusion: 该方法在速度和效率上显著优于传统方法，适用于实际应用中的低阶滤波器。

Abstract: We introduce a general formulation for automatic differentiation through direct form filters, yielding a closed-form backpropagation that includes initial condition gradients. The result is a single expression that can represent both the filter and its gradients computation while supporting parallelism. C++/CUDA implementations in PyTorch achieve at least 1000x speedup over naive Python implementations and consistently run fastest on the GPU. For the low-order filters commonly used in practice, exact time-domain filtering with analytical gradients outperforms the frequency-domain method in terms of speed. The source code is available at https://github.com/yoyolicoris/philtorch.

</details>


### [19] [Ultra-Low Insertion Loss Stepped Impedance Resonator Topology for HTSC RF Front-End](https://arxiv.org/abs/2511.14447)
*Ilan Kurtser,Yoav Koral,Eldad Holdengreber,Shmuel E. Schacham,Eliyahu Farber*

Main category: eess.SY

TL;DR: 论文设计并测试了一种用于S波段的高温超导阶梯阻抗谐振器带通滤波器，展示了超低插入损耗和优异的性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在验证高温超导体（HTSC）在射频前端应用中的可行性，以提高雷达和通信系统的性能。

Method: 通过设计和制造基于YBa2Cu3O(7-x)（YBCO）薄膜的11极滤波器，并将其集成到低温接收器级联中，进行性能测试。

Result: 滤波器表现出超低插入损耗（-0.1 dB）、陡峭的滚降（100 MHz）和高抑制水平（>80 dB），系统仿真显示噪声系数低至0.34 dB。

Conclusion: 研究表明，高温超导滤波器在下一代通信和雷达系统中具有实际应用的潜力，能显著提升系统性能。

Abstract: We present the design, fabrication, and measurement of a high-temperature superconductor (HTSC) Stepped Impedance Resonator (SIR) band-pass filter for S-band applications, and its incorporation into a cryogenic receiver cascade. The 11-pole filter, implemented in YBa2Cu3O(7-x) (YBCO) thin films on sapphire, exhibits an ultra-low insertion loss (IL) of -0.1~dB, a sharp roll-off of 100~MHz, and a rejection level exceeding --80~dB. These measured results represent, to the best of our knowledge, the lowest reported IL for an S-band filter with this number of poles. When integrated with a cryogenic low-noise amplifier (LNA), system-level simulations and measurements predict a receiver noise figure (NF) of 0.34~dB at 3.39~GHz, enabling a 20% increase in radar detection range compared with conventional copper-based front ends. This work demonstrates the feasibility of practical HTSC-based RF front-ends for next-generation communication and radar systems.

</details>


### [20] [Stratospheric Grid: A Wireless Power Transfer Enabled HAP Network with Integrated Generation-Grid-Load-Storage Functions](https://arxiv.org/abs/2511.14527)
*Peng Wang,Eros Kuikel,Jia Ye,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: 论文提出了一种平流层能源网格，通过无线电力传输（WPT）互联和高空平台（HAP）作为动态可重构的能源节点，实现能源的优化分配和系统韧性。


<details>
  <summary>Details</summary>
Motivation: 解决传统高空平台因间歇性光伏发电、有限储能能力和高任务负载而难以实现全天候连续运行的挑战。

Method: 建立平流层能源网格，HAP作为动态可重构的IGGLS节点，支持能源的收集、缓冲、消耗和点对点传输。通过协作调度，实现能源跨域优化。

Result: 案例研究验证了方法的有效性，提升了能源利用率和系统韧性。

Conclusion: 提出的平流层能源网格为高空平台的持续运行提供了可行方案，并拓展了未来研究方向。

Abstract: Conventional high-altitude platforms (HAPs) face challenges in achieving continuous all-weather operation due to intermittent photovoltaic power generation, limited energy storage capacity, and high mission loads resulting from functional integration. To address this fundamental issue, we propose a stratospheric energy grid in which wireless power transfer (WPT) interconnections constitute the grid layer, while HAPs operate as dynamically reconfigurable integrated generation-grid-load-storage (IGGLS) nodes that harvest, buffer, consume, and peer-to-peer transfer energy for constellation-level balancing and resilience. In this system, each HAP node can flexibly switch among energy source, load, and storage roles according to its energy status and mission requirements, enabling energy exchange and spatiotemporal optimization within the stratosphere. Through cooperative scheduling, the stratospheric grid not only enables surplus-to-deficit energy support among HAPs but also extends upward to satellites and downward to the terrestrial grid and communication infrastructure, forming a heterogeneous, WPT-mediated interconnection. As an IGGLS ecosystem, it exploits peer-to-peer energy logistics, spatiotemporal smoothing of intermittency, cross-domain backup via the terrestrial grid, and service-aware dispatch, thereby boosting overall energy utilization and operational resilience. The proposed approach is validated through case studies, and we delineate an agenda of feasible research directions.

</details>


### [21] [Robust Offset-free Kernelized Data-Driven Predictive Control for Nonlinear Systems](https://arxiv.org/abs/2511.14652)
*Mahmood Mazare,Hossein Ramezani*

Main category: eess.SY

TL;DR: 提出了一种新颖的Kernelized Data-Driven Predictive Control (KDPC)方案，实现了非线性系统的鲁棒、无偏移跟踪，通过核岭回归和核映射的线性化，将控制器转化为标准QP问题，验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 针对非线性系统的鲁棒性和无偏移跟踪问题，提出一种结合数据驱动和核方法的预测控制方案，以提高控制精度和计算效率。

Method: 采用核岭回归学习非线性映射，并通过核映射的解析线性化近似未来输入的影响，将控制器转化为标准QP问题。

Result: 在非线性Van der Pol振荡器上验证，成功抑制未测量扰动并消除稳态误差，表现优于传统基于模型的控制器。

Conclusion: KDPC方案结合了数据驱动和核方法的优势，提供了理论保证和实际应用的优越性能。

Abstract: This paper proposes a novel Kernelized Data-Driven Predictive Control (KDPC) scheme for robust, offset-free tracking of nonlinear systems. Our computationally efficient hybrid approach separates the prediction: (1) kernel ridge regression learns the nonlinear map from past trajectories, and (2) analytical linearization of the kernel map approximates the effect of future inputs. This linearization is key, allowing the controller to be formulated as a standard Quadratic Program (QP) for efficient real-time implementation. Offset-free tracking is inherently achieved by using input increments. We provide theoretical guarantees for recursive feasibility and asymptotic stability. The algorithm is validated on a nonlinear Van der Pol oscillator, where it successfully rejects unmeasured disturbances and eliminates steady-state errors, outperforming a standard model-based controller.

</details>


### [22] [Towards AC Feasibility of DCOPF Dispatch](https://arxiv.org/abs/2511.14725)
*Michael A. Boateng,Russell Bent,Sidhant Misra,Parikshit Pareek,Pascal Van Hentenryck,Daniel Molzahn*

Main category: eess.SY

TL;DR: 论文提出了一种统一的DCOPF-ACPF流程，从DCOPF调度中恢复AC可行解，显著提升了AC可行性和运行效率。


<details>
  <summary>Details</summary>
Motivation: DCOPF因其简单和高效被广泛使用，但其忽略损耗和无功功率的模型导致实际运行中不可行。本文旨在解决这一问题。

Method: 使用四种DCOPF变体，结合分布式松弛分配和PV/PQ切换技术，开发统一流程以恢复AC可行性。

Result: 在多个测试案例中，流程显著提升了AC可行性，减少误差和成本差异，极端负载下违规减少3至5倍。

Conclusion: 统一流程有效解决了DCOPF的局限性，为实际工程应用提供了更高的可行性和效率。

Abstract: DC Optimal Power Flow (DCOPF) is widely utilized in power system operations due to its simplicity and computational efficiency. However, its lossless, reactive power-agnostic model often yields dispatches that are infeasible under practical operating scenarios such as the nonlinear AC power flow (ACPF) equations. While theoretical analysis demonstrates that DCOPF solutions are inherently AC-infeasible, their widespread industry adoption suggests substantial practical utility. This paper develops a unified DCOPF-ACPF pipeline to recover AC feasible solutions from DCOPF-based dispatches. The pipeline uses four DCOPF variants and applies AC feasibility recovery using both distributed slack allocation and PV/PQ switching. The main objective is to identify the most effective pipeline for restoring AC feasibility. Evaluation across over 10,000 dispatch scenarios on various test cases demonstrates that the structured ACPF model yields solutions that satisfy both the ACPF equations, and all engineering inequality constraints. In a 13,659 bus case, the mean absolute error and cost differences between DCOPF and ACOPF are reduced by 75% and 93%, respectively, compared to conventional single slack bus methods. Under extreme loading conditions, the pipeline reduces inequality constraint violations by a factor of 3 to 5.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [23] [FICO: Finite-Horizon Closed-Loop Factorization for Unified Multi-Agent Path Finding](https://arxiv.org/abs/2511.13961)
*Jiarui Li,Alessandro Zanardi,Runyu Zhang,Gioele Zardini*

Main category: cs.RO

TL;DR: 该论文提出了一种系统级框架（MAPF系统），用于多智能体路径规划（MAPF），整合了规划与执行，并引入FICO算法实现高效闭环操作。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF方法通常将规划与执行分开处理，且缺乏对不确定性的显式建模。该论文旨在通过系统级框架解决这些问题，提升实时性和扩展性。

Method: 提出了MAPF系统框架，将MAPF建模为控制设计问题，并开发了FICO算法。该算法基于分解思想和滚动时域控制，实现高效闭环操作。

Result: FICO算法能够在毫秒级开始执行，支持数千智能体规模，并显著减少计算时间（比开环基线快两个数量级），同时在高不确定性环境中表现优异。

Conclusion: 该研究为MAPF提供了系统级建模、分解和闭环设计的理论基础，为未来研究指明了方向。

Abstract: Multi-Agent Path Finding is a fundamental problem in robotics and AI, yet most existing formulations treat planning and execution separately and address variants of the problem in an ad hoc manner. This paper presents a system-level framework for MAPF that integrates planning and execution, generalizes across variants, and explicitly models uncertainties. At its core is the MAPF system, a formal model that casts MAPF as a control design problem encompassing classical and uncertainty-aware formulations. To solve it, we introduce Finite-Horizon Closed-Loop Factorization (FICO), a factorization-based algorithm inspired by receding-horizon control that exploits compositional structure for efficient closed-loop operation. FICO enables real-time responses -- commencing execution within milliseconds -- while scaling to thousands of agents and adapting seamlessly to execution-time uncertainties. Extensive case studies demonstrate that it reduces computation time by up to two orders of magnitude compared with open-loop baselines, while delivering significantly higher throughput under stochastic delays and agent arrivals. These results establish a principled foundation for analyzing and advancing MAPF through system-level modeling, factorization, and closed-loop design.

</details>


### [24] [LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry](https://arxiv.org/abs/2511.13985)
*Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 本文提出了一种新的激光雷达-惯性里程计（LIO-MARS），通过结合多分辨率面元地图和高斯混合模型（GMM），利用B样条轨迹实现连续时间对齐，提高了自主机器人系统的导航精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自主机器人系统在搜索与救援任务中需要依赖环境感知，而现有的激光雷达-惯性里程计系统在实时性、连续性和计算效率方面存在改进空间。

Method: LIO-MARS通过非均匀时间节点放置确保轨迹连续性，利用Kronecker和与乘积加速协方差和GMM计算，并通过无迹变换和分段补偿运动失真。此外，采用软约束和预积分IMU伪测量进一步提升鲁棒性。

Result: 实验结果表明，LIO-MARS在手持、地面和空中车辆数据集上均表现出优于现有LIO系统的性能，计算速度提升了3.3倍。

Conclusion: LIO-MARS通过创新的算法设计和优化，实现了高精度和高效的实时导航，为自主机器人系统在复杂环境中的应用提供了可靠解决方案。

Abstract: Autonomous robotic systems heavily rely on environment knowledge to safely navigate. For search & rescue, a flying robot requires robust real-time perception, enabled by complementary sensors. IMU data constrains acceleration and rotation, whereas LiDAR measures accurate distances around the robot. Building upon the LiDAR odometry MARS, our LiDAR-inertial odometry (LIO) jointly aligns multi-resolution surfel maps with a Gaussian mixture model (GMM) using a continuous-time B-spline trajectory. Our new scan window uses non-uniform temporal knot placement to ensure continuity over the whole trajectory without additional scan delay. Moreover, we accelerate essential covariance and GMM computations with Kronecker sums and products by a factor of 3.3. An unscented transform de-skews surfels, while a splitting into intra-scan segments facilitates motion compensation during spline optimization. Complementary soft constraints on relative poses and preintegrated IMU pseudo-measurements further improve robustness and accuracy. Extensive evaluation showcases the state-of-the-art quality of our LIO-MARS w.r.t. recent LIO systems on various handheld, ground and aerial vehicle-based datasets.

</details>


### [25] [Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval](https://arxiv.org/abs/2511.14004)
*Taijing Chen,Sateesh Kumar,Junhong Xu,George Pavlakos,J oydeep Biswas,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: STAR框架统一处理时空对象检索问题，通过结合长期记忆和工作记忆，利用视觉语言模型选择时空动作，在模拟和真实环境中优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 服务机器人需在动态开放环境中检索对象，而现有方法仅部分解决此问题，缺乏对时空问题的统一处理。

Method: 提出STAR框架，结合非参数化长期记忆和工作记忆，通过视觉语言模型动态选择时空动作。

Result: 在模拟和真实环境中，STAR优于基于场景图和记忆的基线方法，验证了时空统一检索的有效性。

Conclusion: STAR框架为解决动态环境中的对象检索问题提供了有效方案，凸显了时空统一处理的重要性。

Abstract: Service robots must retrieve objects in dynamic, open-world settings where requests may reference attributes ("the red mug"), spatial context ("the mug on the table"), or past states ("the mug that was here yesterday"). Existing approaches capture only parts of this problem: scene graphs capture spatial relations but ignore temporal grounding, temporal reasoning methods model dynamics but do not support embodied interaction, and dynamic scene graphs handle both but remain closed-world with fixed vocabularies. We present STAR (SpatioTemporal Active Retrieval), a framework that unifies memory queries and embodied actions within a single decision loop. STAR leverages non-parametric long-term memory and a working memory to support efficient recall, and uses a vision-language model to select either temporal or spatial actions at each step. We introduce STARBench, a benchmark of spatiotemporal object search tasks across simulated and real environments. Experiments in STARBench and on a Tiago robot show that STAR consistently outperforms scene-graph and memory-only baselines, demonstrating the benefits of treating search in time and search in space as a unified problem.

</details>


### [26] [FACA: Fair and Agile Multi-Robot Collision Avoidance in Constrained Environments with Dynamic Priorities](https://arxiv.org/abs/2511.14024)
*Jaskirat Singh,Rohan Chandra*

Main category: cs.RO

TL;DR: FACA是一种公平且敏捷的机器人碰撞避免方法，通过自然语言协调任务，采用新型人工势场算法提升效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在紧急应用中需高速穿越受限空间，但动态优先级和异构性带来了挑战，FACA旨在平衡安全性与敏捷性。

Method: 通过自然语言协调任务，利用人工势场算法在冲突时实现自动“环形”效果。

Result: 实验表明FACA效率显著提升，任务完成速度快3.5倍以上，时间减少70%，同时保持安全。

Conclusion: FACA在多机器人系统中有效平衡敏捷性和安全性，适用于动态优先级场景。

Abstract: Multi-robot systems are increasingly being used for critical applications such as rescuing injured people, delivering food and medicines, and monitoring key areas. These applications usually involve navigating at high speeds through constrained spaces such as small gaps. Navigating such constrained spaces becomes particularly challenging when the space is crowded with multiple heterogeneous agents all of which have urgent priorities. What makes the problem even harder is that during an active response situation, roles and priorities can quickly change on a dime without informing the other agents. In order to complete missions in such environments, robots must not only be safe, but also agile, able to dodge and change course at a moment's notice. In this paper, we propose FACA, a fair and agile collision avoidance approach where robots coordinate their tasks by talking to each other via natural language (just as people do). In FACA, robots balance safety with agility via a novel artificial potential field algorithm that creates an automatic ``roundabout'' effect whenever a conflict arises. Our experiments show that FACA achieves a improvement in efficiency, completing missions more than 3.5X faster than baselines with a time reduction of over 70% while maintaining robust safety margins.

</details>


### [27] [BIM-Discrepancy-Driven Active Sensing for Risk-Aware UAV-UGV Navigation](https://arxiv.org/abs/2511.14037)
*Hesam Mojtahedi,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出了一种基于BIM差异驱动的主动感知框架，用于无人机和无人地面车辆在动态建筑环境中的协作导航，显著降低了导航风险和地图熵。


<details>
  <summary>Details</summary>
Motivation: 传统的导航方法依赖于静态BIM先验或有限的机载感知，无法动态适应环境变化，因此需要一种能实时融合LiDAR数据与BIM先验的创新框架。

Method: 框架通过融合无人机和地面机器人的实时LiDAR数据与BIM先验，生成动态2D占据地图，并使用统一的走廊风险度量来触发无人机的主动重扫描。

Result: 验证结果表明，风险触发的重扫描使平均走廊风险降低58%，地图熵降低43%，同时保持了0.4米以上的安全距离，且在任务时间上优于前沿探索方法。

Conclusion: 该研究证明，将BIM先验与风险自适应空中感知结合，可为建筑机器人提供可扩展的、不确定性感知的自主性。

Abstract: This paper presents a BIM-discrepancy-driven active sensing framework for cooperative navigation between unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) in dynamic construction environments. Traditional navigation approaches rely on static Building Information Modeling (BIM) priors or limited onboard perception. In contrast, our framework continuously fuses real-time LiDAR data from aerial and ground robots with BIM priors to maintain an evolving 2D occupancy map. We quantify navigation safety through a unified corridor-risk metric integrating occupancy uncertainty, BIM-map discrepancy, and clearance. When risk exceeds safety thresholds, the UAV autonomously re-scans affected regions to reduce uncertainty and enable safe replanning. Validation in PX4-Gazebo simulation with Robotec GPU LiDAR demonstrates that risk-triggered re-scanning reduces mean corridor risk by 58% and map entropy by 43% compared to static BIM navigation, while maintaining clearance margins above 0.4 m. Compared to frontier-based exploration, our approach achieves similar uncertainty reduction in half the mission time. These results demonstrate that integrating BIM priors with risk-adaptive aerial sensing enables scalable, uncertainty-aware autonomy for construction robotics.

</details>


### [28] [FlexiCup: Wireless Multimodal Suction Cup with Dual-Zone Vision-Tactile Sensing](https://arxiv.org/abs/2511.14139)
*Junhao Gong,Shoujie Li,Kit-Wa Sou,Changqing Guo,Hourong Huang,Tong Wu,Yifan Xie,Chenxin Liang,Chuqiao Lyu,Xiaojun Liang,Wenbo Ding*

Main category: cs.RO

TL;DR: FlexiCup是一种集成双区视觉-触觉传感的全无线多模态吸盘，支持真空和Bernoulli吸附模式，通过模块化设计实现无线自主操作，验证了其在结构化表面的抓取性能。


<details>
  <summary>Details</summary>
Motivation: 传统吸盘在非结构化环境中缺乏接触感知能力，FlexiCup旨在解决这一问题，提供多功能感知和操纵能力。

Method: FlexiCup通过双区视觉-触觉传感（中央区动态切换视觉与触觉模态，外围区提供空间感知）和模块化机械配置，实现真空和Bernoulli吸附模式。采用扩散端到端学习协调双区观测。

Result: 真空吸附和Bernoulli吸附的平均成功率分别为90.0%和86.7%；在倾斜运输和橙子提取任务中，学习方法的成功率分别为73.3%和66.7%；双区观测协调提升接触感知能力13%。

Conclusion: FlexiCup展示了模块化设计、多模态感知和无线自主操作的潜力，为接触感知操纵提供了高效解决方案。

Abstract: Conventional suction cups lack sensing capabilities for contact-aware manipulation in unstructured environments. This paper presents FlexiCup, a fully wireless multimodal suction cup that integrates dual-zone vision-tactile sensing. The central zone dynamically switches between vision and tactile modalities via illumination control for contact detection, while the peripheral zone provides continuous spatial awareness for approach planning. FlexiCup supports both vacuum and Bernoulli suction modes through modular mechanical configurations, achieving complete wireless autonomy with onboard computation and power. We validate hardware versatility through dual control paradigms. Modular perception-driven grasping across structured surfaces with varying obstacle densities demonstrates comparable performance between vacuum (90.0% mean success) and Bernoulli (86.7% mean success) modes. Diffusion-based end-to-end learning achieves 73.3% success on inclined transport and 66.7% on orange extraction tasks. Ablation studies confirm that multi-head attention coordinating dual-zone observations provides 13% improvements for contact-aware manipulation. Hardware designs and firmware are available at https://anonymous.4open.science/api/repo/FlexiCup-DA7D/file/index.html?v=8f531b44.

</details>


### [29] [AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models](https://arxiv.org/abs/2511.14148)
*Yuhua Jiang,Shuang Cheng,Yan Ding,Feifei Gao,Biqing Qi*

Main category: cs.RO

TL;DR: 提出了一种异步流匹配的视觉-语言-动作模型AsyncVLA，通过非均匀时间调度和自我纠正机制解决传统同步流匹配在长时任务中的不稳定问题，并在实验中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 传统同步流匹配（SFM）在视觉-语言-动作（VLA）模型中缺乏动作上下文感知和异步自我纠正能力，导致长时任务中动作错误的累积和失败。

Method: 提出异步流匹配（AFM）框架AsyncVLA，引入动作上下文感知的非均匀时间调度和置信度评分机制，动态校正生成的动作令牌。同时，设计了SFM和AFM的统一训练过程，提升KV缓存利用率。

Result: 在机器人操作基准测试中，AsyncVLA展现了数据高效性和自我纠正能力，并在通用评测中达到最优性能。

Conclusion: AsyncVLA通过异步生成和动态校正显著提升了VLA模型的稳定性和性能，为解决长时任务中的动作生成问题提供了新思路。

Abstract: Vision-language-action (VLA) models have recently emerged as a powerful paradigm for building generalist robots. However, traditional VLA models that generate actions through flow matching (FM) typically rely on rigid and uniform time schedules, i.e., synchronous FM (SFM). Without action context awareness and asynchronous self-correction, SFM becomes unstable in long-horizon tasks, where a single action error can cascade into failure. In this work, we propose asynchronous flow matching VLA (AsyncVLA), a novel framework that introduces temporal flexibility in asynchronous FM (AFM) and enables self-correction in action generation. AsyncVLA breaks from the vanilla SFM in VLA models by generating the action tokens in a non-uniform time schedule with action context awareness. Besides, our method introduces the confidence rater to extract confidence of the initially generated actions, enabling the model to selectively refine inaccurate action tokens before execution. Moreover, we propose a unified training procedure for SFM and AFM that endows a single model with both modes, improving KV-cache utilization. Extensive experiments on robotic manipulation benchmarks demonstrate that AsyncVLA is data-efficient and exhibits self-correction ability. AsyncVLA achieves state-of-the-art results across general embodied evaluations due to its asynchronous generation in AFM. Our code is available at https://github.com/YuhuaJiang2002/AsyncVLA.

</details>


### [30] [RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action](https://arxiv.org/abs/2511.14161)
*Xiaoquan Sun,Ruijian Zhang,Kang Pang,Bingchen Miao,Yuxiang Tan,Zhen Yang,Ming Li,Jiayu Chen*

Main category: cs.RO

TL;DR: RoboTidy是一个统一的基准测试，用于语言引导的家庭整理任务，支持视觉-语言-动作（VLA）和视觉-语言-导航（VLN）的训练与评估。


<details>
  <summary>Details</summary>
Motivation: 现有的家庭整理基准测试缺乏对用户偏好的建模和移动性支持，且泛化能力差，难以全面评估语言到动作的集成能力。

Method: RoboTidy提供了500个高保真3D高斯散射（3DGS）家庭场景，支持碰撞检测，并整理了6400条高质量操作轨迹和1500条导航轨迹。

Result: 该基准测试在真实世界中部署，为家庭整理提供了一个端到端的测试平台。

Conclusion: RoboTidy填补了具身AI领域的空白，实现了语言引导机器人的全面和现实评估。

Abstract: Household tidying is an important application area, yet current benchmarks neither model user preferences nor support mobility, and they generalize poorly, making it hard to comprehensively assess integrated language-to-action capabilities. To address this, we propose RoboTidy, a unified benchmark for language-guided household tidying that supports Vision-Language-Action (VLA) and Vision-Language-Navigation (VLN) training and evaluation. RoboTidy provides 500 photorealistic 3D Gaussian Splatting (3DGS) household scenes (covering 500 objects and containers) with collisions, formulates tidying as an "Action (Object, Container)" list, and supplies 6.4k high-quality manipulation demonstration trajectories and 1.5k naviagtion trajectories to support both few-shot and large-scale training. We also deploy RoboTidy in the real world for object tidying, establishing an end-to-end benchmark for household tidying. RoboTidy offers a scalable platform and bridges a key gap in embodied AI by enabling holistic and realistic evaluation of language-guided robots.

</details>


### [31] [Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion](https://arxiv.org/abs/2511.14178)
*Zhuo Li,Junjia Liu,Zhipeng Dong,Tao Teng,Quentin Rouxel,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: VLA-Pilot 是一种即插即用的推理时策略导向方法，无需微调或数据收集即可实现预训练 VLA 模型的零样本部署，显著提升了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉-语言-动作 (VLA) 模型在下游部署时性能下降严重，而传统微调方法成本高昂且不切实际。VLA-Pilot 旨在解决这一问题。

Method: VLA-Pilot 是一种无需额外微调或数据收集的推理时策略导向方法，通过实时调整策略提升预训练 VLA 模型的性能。

Result: 在六项真实世界下游操作任务中验证，VLA-Pilot 显著提高了预训练 VLA 策略的成功率，实现了对多样任务和机器人形态的零样本泛化。

Conclusion: VLA-Pilot 提供了一种高效、低成本的方法，能够在不进行额外训练的情况下显著提升预训练 VLA 模型的实际部署性能。

Abstract: Vision-Language-Action (VLA) models have demonstrated significant potential in real-world robotic manipulation. However, pre-trained VLA policies still suffer from substantial performance degradation during downstream deployment. Although fine-tuning can mitigate this issue, its reliance on costly demonstration collection and intensive computation makes it impractical in real-world settings. In this work, we introduce VLA-Pilot, a plug-and-play inference-time policy steering method for zero-shot deployment of pre-trained VLA without any additional fine-tuning or data collection. We evaluate VLA-Pilot on six real-world downstream manipulation tasks across two distinct robotic embodiments, encompassing both in-distribution and out-of-distribution scenarios. Experimental results demonstrate that VLA-Pilot substantially boosts the success rates of off-the-shelf pre-trained VLA policies, enabling robust zero-shot generalization to diverse tasks and embodiments. Experimental videos and code are available at: https://rip4kobe.github.io/vla-pilot/.

</details>


### [32] [Dual-Variable Force Characterisation method for Human-Robot Interaction in Wearable Robotics](https://arxiv.org/abs/2511.14327)
*Felipe Ballen-Moreno,Pasquale Ferrentino,Milan Amighi,Bram Vanderborght,Tom Verstraten*

Main category: cs.RO

TL;DR: 本文提出了一种双变量表征方法，通过纳入法向和切向力，解决了现有单变量方法在与可穿戴机器人交互时的局限性，提高了物理接口的压力和剪切应力模拟精度。


<details>
  <summary>Details</summary>
Motivation: 理解可穿戴机器人与用户之间的物理交互对确保安全和舒适至关重要，但现有方法因单变量表征在多自由度场景中的局限性而难以满足需求。

Method: 提出了一种双变量表征方法，结合法向和切向力，通过分析不同场景和材料模型的归一化均方误差（NMSE），验证了其有效性。

Result: 该方法证明了双变量表征的重要性，为模拟可穿戴机器人与人体肢体间的物理交互提供了更接近实际的建模基础。

Conclusion: 双变量表征方法显著提升了对可穿戴机器人物理交互的理解和模拟能力，为未来的设计和优化提供了重要依据。

Abstract: Understanding the physical interaction with wearable robots is essential to ensure safety and comfort. However, this interaction is complex in two key aspects: (1) the motion involved, and (2) the non-linear behaviour of soft tissues. Multiple approaches have been undertaken to better understand this interaction and to improve the quantitative metrics of physical interfaces or cuffs. As these two topics are closely interrelated, finite modelling and soft tissue characterisation offer valuable insights into pressure distribution and shear stress induced by the cuff. Nevertheless, current characterisation methods typically rely on a single fitting variable along one degree of freedom, which limits their applicability, given that interactions with wearable robots often involve multiple degrees of freedom. To address this limitation, this work introduces a dual-variable characterisation method, involving normal and tangential forces, aimed at identifying reliable material parameters and evaluating the impact of single-variable fitting on force and torque responses. This method demonstrates the importance of incorporating two variables into the characterisation process by analysing the normalized mean square error (NMSE) across different scenarios and material models, providing a foundation for simulation at the closest possible level, with a focus on the cuff and the human limb involved in the physical interaction between the user and the wearable robot.

</details>


### [33] [MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning](https://arxiv.org/abs/2511.14330)
*Yizhen Yin,Yuhua Qi,Dapeng Feng,Hongbo Chen,Hongjun Ma,Jin Wu,Yi Jiang*

Main category: cs.RO

TL;DR: MA-SLAM是一种基于深度强化学习的主动SLAM系统，旨在提高大规模环境中的探索效率，通过结构化地图表示和全局规划器优化路径，显著减少了探索时间和距离。


<details>
  <summary>Details</summary>
Motivation: 当前主动SLAM方法在小规模环境中表现良好，但在大规模多样化环境中面临探索时间长和路径效率低的挑战。

Method: 提出了一种结构化地图表示方法，结合边界点和历史轨迹作为输入，并采用基于深度强化学习的决策模块和全局规划器优化路径。

Result: 在三个模拟环境和实际无人地面车辆上的实验表明，该方法比现有技术显著减少了探索时间和距离。

Conclusion: MA-SLAM通过结构化地图和全局规划技术，有效解决了大规模环境中的探索效率问题。

Abstract: Active Simultaneous Localization and Mapping (Active SLAM) involves the strategic planning and precise control of a robotic system's movement in order to construct a highly accurate and comprehensive representation of its surrounding environment, which has garnered significant attention within the research community. While the current methods demonstrate efficacy in small and controlled settings, they face challenges when applied to large-scale and diverse environments, marked by extended periods of exploration and suboptimal paths of discovery. In this paper, we propose MA-SLAM, a Map-Aware Active SLAM system based on Deep Reinforcement Learning (DRL), designed to address the challenge of efficient exploration in large-scale environments. In pursuit of this objective, we put forward a novel structured map representation. By discretizing the spatial data and integrating the boundary points and the historical trajectory, the structured map succinctly and effectively encapsulates the visited regions, thereby serving as input for the deep reinforcement learning based decision module. Instead of sequentially predicting the next action step within the decision module, we have implemented an advanced global planner to optimize the exploration path by leveraging long-range target points. We conducted experiments in three simulation environments and deployed in a real unmanned ground vehicle (UGV), the results demonstrate that our approach significantly reduces both the duration and distance of exploration compared with state-of-the-art methods.

</details>


### [34] [Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors](https://arxiv.org/abs/2511.14335)
*Jeryes Danial,Yosi Ben Asher,Itzik Klein*

Main category: cs.RO

TL;DR: 提出了一种边缘感知的轻量级单目SLAM系统，结合稀疏关键点位姿估计与密集边缘重建，实时运行于低功耗平台，并解决尺度模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有单目SLAM算法稀疏方法缺乏几何细节，学习驱动方法计算量大，且存在尺度模糊问题。本文旨在解决这些挑战。

Method: 结合深度学习深度预测与边缘检测，通过优化关键点和边缘实现几何一致性；融合惯性数据以解决尺度模糊；避免全局闭环或复杂神经计算。

Result: 系统在DJI Tello无人机上成功运行，实现实时室内导航与避障，并在TUM RGBD数据集上验证了鲁棒性。

Conclusion: 提出了一种高效、实用的解决方案，适用于资源受限环境中的实时建图与导航。

Abstract: Monocular simultaneous localization and mapping (SLAM) algorithms estimate drone poses and build a 3D map using a single camera. Current algorithms include sparse methods that lack detailed geometry, while learning-driven approaches produce dense maps but are computationally intensive. Monocular SLAM also faces scale ambiguities, which affect its accuracy. To address these challenges, we propose an edge-aware lightweight monocular SLAM system combining sparse keypoint-based pose estimation with dense edge reconstruction. Our method employs deep learning-based depth prediction and edge detection, followed by optimization to refine keypoints and edges for geometric consistency, without relying on global loop closure or heavy neural computations. We fuse inertial data with vision by using an extended Kalman filter to resolve scale ambiguity and improve accuracy. The system operates in real time on low-power platforms, as demonstrated on a DJI Tello drone with a monocular camera and inertial sensors. In addition, we demonstrate robust autonomous navigation and obstacle avoidance in indoor corridors and on the TUM RGBD dataset. Our approach offers an effective, practical solution to real-time mapping and navigation in resource-constrained environments.

</details>


### [35] [Going Places: Place Recognition in Artificial and Natural Systems](https://arxiv.org/abs/2511.14341)
*Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 该综述总结了机器人系统、动物研究和人类研究中的地点识别能力，探讨了不同系统的编码和回忆策略，旨在通过跨领域研究推动人工地点识别系统的发展。


<details>
  <summary>Details</summary>
Motivation: 地点识别对于生物导航和自主系统至关重要，研究希望整合不同领域的发现，揭示地点识别的共性和独特性，以促进人工系统的发展。

Method: 通过分析机器人系统、动物研究和人类研究的计算和表征策略，重点关注拓扑映射、线索整合和记忆管理等解决方案。

Result: 研究发现动物演化出多模式导航和环境适应机制，人类研究提供了语义地点概念和文化影响等独特见解，人工系统展示了可扩展架构和数据驱动模型。

Conclusion: 提出了一套统一的概念来思考和发展地点识别机制，并指出泛化性、鲁棒性和环境变异性等关键挑战，旨在通过跨领域研究推动人工系统的创新。

Abstract: Place recognition, the ability to identify previously visited locations, is critical for both biological navigation and autonomous systems. This review synthesizes findings from robotic systems, animal studies, and human research to explore how different systems encode and recall place. We examine the computational and representational strategies employed across artificial systems, animals, and humans, highlighting convergent solutions such as topological mapping, cue integration, and memory management. Animal systems reveal evolved mechanisms for multimodal navigation and environmental adaptation, while human studies provide unique insights into semantic place concepts, cultural influences, and introspective capabilities. Artificial systems showcase scalable architectures and data-driven models. We propose a unifying set of concepts by which to consider and develop place recognition mechanisms and identify key challenges such as generalization, robustness, and environmental variability. This review aims to foster innovations in artificial localization by connecting future developments in artificial place recognition systems to insights from both animal navigation research and human spatial cognition studies.

</details>


### [36] [Perception-aware Exploration for Consumer-grade UAVs](https://arxiv.org/abs/2511.14393)
*Svetlana Seliunina,Daniel Schleich,Sven Behnke*

Main category: cs.RO

TL;DR: 研究将当前先进的多无人机自主探索方法扩展到消费级无人机（如DJI Mini 3 Pro），提出一种从视角对估计深度并满足运动约束的轨迹规划流程，并通过半分布式通信方案平衡多无人机工作负载。模拟实验验证了其在硬件限制下仍能安全探索环境并重建地图。


<details>
  <summary>Details</summary>
Motivation: 将先进的多无人机自主探索方法应用于消费级无人机，突破硬件限制，实现低成本、高效的环境探索和地图重建。

Method: 1. 提出从视角对估计深度的轨迹规划流程；2. 设计半分布式通信方案以平衡多无人机工作负载。

Result: 模拟实验表明，该方法在不同数量无人机下均能安全探索环境并重建地图，适应消费级无人机的硬件限制。

Conclusion: 研究成功将多无人机自主探索技术扩展到消费级设备，为低成本、高效率的环境探索提供了可行方案。

Abstract: In our work, we extend the current state-of-the-art approach for autonomous multi-UAV exploration to consumer-level UAVs, such as the DJI Mini 3 Pro. We propose a pipeline that selects viewpoint pairs from which the depth can be estimated and plans the trajectory that satisfies motion constraints necessary for odometry estimation. For the multi-UAV exploration, we propose a semi-distributed communication scheme that distributes the workload in a balanced manner. We evaluate our model performance in simulation for different numbers of UAVs and prove its ability to safely explore the environment and reconstruct the map even with the hardware limitations of consumer-grade UAVs.

</details>


### [37] [Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning](https://arxiv.org/abs/2511.14396)
*Xiuxiu Qi,Yu Yang,Jiannong Cao,Luyao Bai,Chongshan Fan,Chengtai Cao,Hongpeng Wang*

Main category: cs.RO

TL;DR: 论文提出了一种名为CCoL的新行为克隆框架，通过连续协同学习视觉、语言和本体感知输入，解决了动作决策中的误差累积问题，提升了执行的连贯性和语义-物理对齐。实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的行为克隆方法因物理不连续性和语义-物理不对齐问题，导致动作克隆不准确和执行间断。需要一种新方法来克服这些问题。

Method: CCoL框架通过连续协同学习视觉、语言和本体感知输入，生成鲁棒且平滑的动作执行轨迹，并通过双向跨注意力机制将语言语义锚定到视觉运动表征上。

Result: 在三个模拟套件中，CCoL平均相对提升了8.0%，在双手机器人插入任务中最高提升了19.2%。真实世界测试也证明了其泛化能力。

Conclusion: CCoL通过语义-物理对齐和连续协同学习，有效提升了行为克隆的准确性和执行连贯性，适用于复杂任务和真实场景。

Abstract: Language-conditioned manipulation facilitates human-robot interaction via behavioral cloning (BC), which learns control policies from human demonstrations and serves as a cornerstone of embodied AI. Overcoming compounding errors in sequential action decisions remains a central challenge to improving BC performance. Existing approaches mitigate compounding errors through data augmentation, expressive representation, or temporal abstraction. However, they suffer from physical discontinuities and semantic-physical misalignment, leading to inaccurate action cloning and intermittent execution. In this paper, we present Continuous vision-language-action Co-Learning with Semantic-Physical Alignment (CCoL), a novel BC framework that ensures temporally consistent execution and fine-grained semantic grounding. It generates robust and smooth action execution trajectories through continuous co-learning across vision, language, and proprioceptive inputs (e.g., robot internal states). Meanwhile, we anchor language semantics to visuomotor representations by a bidirectional cross-attention to learn contextual information for action generation, successfully overcoming the problem of semantic-physical misalignment. Extensive experiments show that CCoL achieves an average 8.0% relative improvement across three simulation suites, with up to 19.2% relative gain in human-demonstrated bimanual insertion tasks. Real-world tests on a 7-DoF robot further confirm CCoL's generalization under unseen and noisy object states.

</details>


### [38] [Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning](https://arxiv.org/abs/2511.14427)
*Rickmer Krohn,Vignesh Prasad,Gabriele Tiboni,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: MSDP是一种新型的多感官动态预训练框架，通过掩码自编码和交叉注意力机制，提升机器人在多感官环境中的任务学习效率，并在仿真和现实中表现出优异的鲁棒性和快速学习能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决强化学习在多感官环境（尤其是动态变化和噪声干扰下）中学习的困难，提出一种更高效的表示学习方法。

Method: 采用掩码自编码训练基于变换器的编码器，通过部分传感器嵌入重建多感官观测，并设计了一种不对称架构，分别优化演员和评论家的输入特征。

Result: 方法在仿真和真实机器人任务中表现出快速学习和鲁棒性，仅需6000次在线交互即可实现高成功率。

Conclusion: MSDP为复杂多感官机器人控制提供了一种简单有效的解决方案，具有广泛的应用潜力。

Abstract: Effective contact-rich manipulation requires robots to synergistically leverage vision, force, and proprioception. However, Reinforcement Learning agents struggle to learn in such multisensory settings, especially amidst sensory noise and dynamic changes. We propose MultiSensory Dynamic Pretraining (MSDP), a novel framework for learning expressive multisensory representations tailored for task-oriented policy learning. MSDP is based on masked autoencoding and trains a transformer-based encoder by reconstructing multisensory observations from only a subset of sensor embeddings, leading to cross-modal prediction and sensor fusion. For downstream policy learning, we introduce a novel asymmetric architecture, where a cross-attention mechanism allows the critic to extract dynamic, task-specific features from the frozen embeddings, while the actor receives a stable pooled representation to guide its actions. Our method demonstrates accelerated learning and robust performance under diverse perturbations, including sensor noise, and changes in object dynamics. Evaluations in multiple challenging, contact-rich robot manipulation tasks in simulation and the real world showcase the effectiveness of MSDP. Our approach exhibits strong robustness to perturbations and achieves high success rates on the real robot with as few as 6,000 online interactions, offering a simple yet powerful solution for complex multisensory robotic control.

</details>


### [39] [Mutation Testing for Industrial Robotic Systems](https://arxiv.org/abs/2511.14432)
*Marcela Gonçalves dos Santos,Sylvain Hallé,Fábio Petrillo*

Main category: cs.RO

TL;DR: 论文探讨了如何将突变测试应用于工业机器人系统，通过定义领域特定突变操作符来改进测试套件的有效性，从而提升系统可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 工业机器人系统的可靠性至关重要，传统突变操作符不适用于机器人程序。本研究旨在解决这一问题。

Method: 提出了定义领域特定突变操作符的方法，生成包括运动、夹爪动作和传感器噪声注入等高级操作的有意义突变。

Result: 实证研究表明，该方法生成的突变更具信息性，减少了无效或等价情况，优于传统操作符。

Conclusion: 突变测试可显著提升工业机器人系统测试套件的质量，增强系统可靠性和安全性。

Abstract: Industrial robotic systems (IRS) are increasingly deployed in diverse environments, where failures can result in severe accidents and costly downtime. Ensuring the reliability of the software controlling these systems is therefore critical. Mutation testing, a technique widely used in software engineering, evaluates the effectiveness of test suites by introducing small faults, or mutants, into the code. However, traditional mutation operators are poorly suited to robotic programs, which involve message-based commands and interactions with the physical world. This paper explores the adaptation of mutation testing to IRS by defining domain-specific mutation operators that capture the semantics of robot actions and sensor readings. We propose a methodology for generating meaningful mutants at the level of high-level read and write operations, including movement, gripper actions, and sensor noise injection. An empirical study on a pick-and-place scenario demonstrates that our approach produces more informative mutants and reduces the number of invalid or equivalent cases compared to conventional operators. Results highlight the potential of mutation testing to enhance test suite quality and contribute to safer, more reliable industrial robotic systems.

</details>


### [40] [Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies](https://arxiv.org/abs/2511.14434)
*Marlow Fawn,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出一种方法，将基于STL规范的HCLBF与机器人策略结合，将不安全策略转化为具有形式化保证的安全策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人策略在执行任务时可能存在的安全问题，同时保留其任务驱动的行为。

Method: 通过HCLBF生成的安全证书与现有策略结合，确保行为的安全性和任务完成性。

Result: 实验证明，该方法成功将强化学习训练出的策略转化为安全策略，能够在桌面上避免碰撞障碍物。

Conclusion: 该方法可扩展至更复杂的规范与动态任务场景。

Abstract: We propose a method for combining Harmonic Control Lyapunov-Barrier Functions (HCLBFs) derived from Signal Temporal Logic (STL) specifications with any given robot policy to turn an unsafe policy into a safe one with formal guarantees.  The two components are combined via HCLBF-derived safety certificates, thus producing commands that preserve both safety and task-driven behavior.  We demonstrate with a simple proof-of-concept implementation for an object-centric force-based policy trained through reinforcement learning for a movement task of a stationary robot arm that is able to avoid colliding with obstacles on a table top after combining the policy with the safety constraints.  The proposed method can be generalized to more complex specifications and dynamic task settings.

</details>


### [41] [Advancing Minimally Invasive Precision Surgery in Open Cavities with Robotic Flexible Endoscopy](https://arxiv.org/abs/2511.14458)
*Michelle Mattille,Alexandre Mesot,Miriam Weisskopf,Nicole Ochsenbein-Kölble,Ueli Moehrlen,Bradley J. Nelson,Quentin Boehler*

Main category: cs.RO

TL;DR: 论文提出了一种新型机器人平台，旨在解决柔性机器人在开放性手术中的控制问题，结合磁驱动和自主导航技术，并通过实时拼接扩展视野，提升了手术的精准性和安全性。


<details>
  <summary>Details</summary>
Motivation: 柔性机器人在微创手术中具有显著优势，但在开放性手术中的控制和使用面临挑战，如缺乏解剖约束、视野受限等问题。

Method: 开发了一种结合磁驱动柔性内窥镜和远程操作/半自主导航技术的机器人平台，并通过实时场景拼接扩展视野。

Result: 在羊模型中的体内实验验证了该平台能够有效解决开放性手术中的关键限制，提高了手术的精准性和视野。

Conclusion: 该机器人平台为开放性微创手术提供了一种创新的解决方案，展现出在复杂手术中的潜力。

Abstract: Flexible robots hold great promise for enhancing minimally invasive surgery (MIS) by providing superior dexterity, precise control, and safe tissue interaction. Yet, translating these advantages into endoscopic interventions within open cavities remains challenging. The lack of anatomical constraints and the inherent flexibility of such devices complicate their control, while the limited field of view of endoscopes restricts situational awareness. We present a robotic platform designed to overcome these challenges and demonstrate its potential in fetoscopic laser coagulation, a complex MIS procedure typically performed only by highly experienced surgeons. Our system combines a magnetically actuated flexible endoscope with teleoperated and semi-autonomous navigation capabilities for performing targeted laser ablations. To enhance surgical awareness, the platform reconstructs real-time mosaics of the endoscopic scene, providing an extended and continuous visual context. The ability of this system to address the key limitations of MIS in open spaces is validated in vivo in an ovine model.

</details>


### [42] [Aerial Assistance System for Automated Firefighting during Turntable Ladder Operations](https://arxiv.org/abs/2511.14504)
*Jan Quenzel,Valerij Sekin,Daniel Schleich,Alexander Miller,Merlin Stampa,Norbert Pahlke,Christof Röhrig,Sven Behnke*

Main category: cs.RO

TL;DR: 提出了一种基于无人机和消防设备的自动辅助系统，用于提高工业火灾的灭火效率。


<details>
  <summary>Details</summary>
Motivation: 工业设施火灾因其建筑规模大、视觉障碍多，导致灭火精确性低，增加了损失和灭火时间。

Method: 利用无人机在无障碍飞行区域内自主检测热源并定位，同时通过消防设备自动调节水喷射方向。

Result: 初步测试显示，系统能成功定位多个热源并精确喷射水柱。

Conclusion: 该系统有望显著提升工业火灾的灭火效率和安全性。

Abstract: Fires in industrial facilities pose special challenges to firefighters, e.g., due to the sheer size and scale of the buildings. The resulting visual obstructions impair firefighting accuracy, further compounded by inaccurate assessments of the fire's location. Such imprecision simultaneously increases the overall damage and prolongs the fire-brigades operation unnecessarily.
  We propose an automated assistance system for firefighting using a motorized fire monitor on a turntable ladder with aerial support from an unmanned aerial vehicle (UAV). The UAV flies autonomously within an obstacle-free flight funnel derived from geodata, detecting and localizing heat sources. An operator supervises the operation on a handheld controller and selects a fire target in reach. After the selection, the UAV automatically plans and traverses between two triangulation poses for continued fire localization. Simultaneously, our system steers the fire monitor to ensure the water jet reaches the detected heat source. In preliminary tests, our assistance system successfully localized multiple heat sources and directed a water jet towards the fires.

</details>


### [43] [Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language](https://arxiv.org/abs/2511.14565)
*Minyoung Hwang,Alexandra Forsey-Smerek,Nathaniel Dennler,Andreea Bobu*

Main category: cs.RO

TL;DR: 提出了Masked IRL框架，通过结合自然语言和演示数据，利用大语言模型（LLM）消除不相关状态细节，提高奖励模型的泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 为解决奖励模型在有限数据下过度拟合和泛化能力差的问题，提出利用语言指令补充演示数据的不足，明确任务重点。

Method: 提出Masked IRL框架，利用LLM从语言指令推断状态相关性掩码，忽略不相关状态部分；对模糊指令，结合演示数据进行澄清。

Result: 在仿真和真实机器人实验中，Masked IRL比现有方法性能提升15%，数据需求减少4.7倍，泛化性和鲁棒性显著提高。

Conclusion: Masked IRL通过整合语言和演示数据，显著提升了奖励学习的效果和效率，特别适合处理模糊指令和数据不足的场景。

Abstract: Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details. Natural language can more directly specify what the robot should focus on, and, in principle, disambiguate between many reward functions consistent with the demonstrations. However, existing language-conditioned reward learning methods typically treat instructions as simple conditioning signals, without fully exploiting their potential to resolve ambiguity. Moreover, real instructions are often ambiguous themselves, so naive conditioning is unreliable. Our key insight is that these two input types carry complementary information: demonstrations show how to act, while language specifies what is important. We propose Masked Inverse Reinforcement Learning (Masked IRL), a framework that uses large language models (LLMs) to combine the strengths of both input types. Masked IRL infers state-relevance masks from language instructions and enforces invariance to irrelevant state components. When instructions are ambiguous, it uses LLM reasoning to clarify them in the context of the demonstrations. In simulation and on a real robot, Masked IRL outperforms prior language-conditioned IRL methods by up to 15% while using up to 4.7 times less data, demonstrating improved sample-efficiency, generalization, and robustness to ambiguous language. Project page: https://MIT-CLEAR-Lab.github.io/Masked-IRL and Code: https://github.com/MIT-CLEAR-Lab/Masked-IRL

</details>


### [44] [Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks](https://arxiv.org/abs/2511.14592)
*Xianhui Meng,Yuchen Zhang,Zhijian Huang,Zheng Lu,Ziling Ji,Yaoyao Yin,Hongyuan Zhang,Guangfeng Jiang,Yandan Lin,Long Chen,Hangjun Ye,Li Zhang,Jun Liu,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: DSBench是一个全面的驾驶安全基准，用于评估视觉语言模型（VLMs）在安全关键场景下的性能，涵盖外部环境风险和车内行为安全两类，共10大类28小类。评估显示现有VLM表现不佳，但通过大规模数据集微调可显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: VLMs在自动驾驶中有潜力，但其在安全关键场景下的适用性尚未充分研究，缺乏同时评估外部环境风险和车内行为安全的综合基准。

Method: 提出DSBench基准，涵盖两大类别、10关键类别和28子类别，构建包含98K实例的数据集用于微调VLM。

Result: 评估发现主流VLM在复杂安全关键场景下性能显著下降，但微调后可大幅提升安全性。

Conclusion: DSBench填补了评估VLM安全性能的空白，为自动驾驶技术进步提供了重要工具和数据支持。

Abstract: Vision-Language Models (VLMs) show great promise for autonomous driving, but their suitability for safety-critical scenarios is largely unexplored, raising safety concerns. This issue arises from the lack of comprehensive benchmarks that assess both external environmental risks and in-cabin driving behavior safety simultaneously. To bridge this critical gap, we introduce DSBench, the first comprehensive Driving Safety Benchmark designed to assess a VLM's awareness of various safety risks in a unified manner. DSBench encompasses two major categories: external environmental risks and in-cabin driving behavior safety, divided into 10 key categories and a total of 28 sub-categories. This comprehensive evaluation covers a wide range of scenarios, ensuring a thorough assessment of VLMs' performance in safety-critical contexts. Extensive evaluations across various mainstream open-source and closed-source VLMs reveal significant performance degradation under complex safety-critical situations, highlighting urgent safety concerns. To address this, we constructed a large dataset of 98K instances focused on in-cabin and external safety scenarios, showing that fine-tuning on this dataset significantly enhances the safety performance of existing VLMs and paves the way for advancing autonomous driving technology. The benchmark toolkit, code, and model checkpoints will be publicly accessible.

</details>


### [45] [Gallant: Voxel Grid-based Humanoid Locomotion and Local-navigation across 3D Constrained Terrains](https://arxiv.org/abs/2511.14625)
*Qingwei Ben,Botian Xu,Kailin Li,Feiyu Jia,Wentao Zhang,Jingping Wang,Jingbo Wang,Dahua Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Gallant是一种基于体素网格的人形机器人运动和局部导航框架，通过轻量化的LiDAR数据表示和端到端优化，解决了传统方法在3D环境感知上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人感知模块（如深度图像或高程图）仅提供部分和平坦的环境视图，无法完整捕获3D结构，限制了机器人在复杂地形中的表现。

Method: Gallant利用体素化的LiDAR数据作为感知表示，采用分组2D CNN将其映射到控制策略，实现了端到端优化。开发了高保真LiDAR仿真以支持训练和模拟到现实的转换。

Result: 实验表明，Gallant的感知范围更广，单一策略能应对地面障碍物、侧面障碍、多级结构等复杂场景，在楼梯攀爬等高难度任务中成功率接近100%。

Conclusion: Gallant通过改进的端到端优化，显著提升了人形机器人在3D约束地形中的运动能力和导航效率，展现了在复杂环境中的潜力。

Abstract: Robust humanoid locomotion requires accurate and globally consistent perception of the surrounding 3D environment. However, existing perception modules, mainly based on depth images or elevation maps, offer only partial and locally flattened views of the environment, failing to capture the full 3D structure. This paper presents Gallant, a voxel-grid-based framework for humanoid locomotion and local navigation in 3D constrained terrains. It leverages voxelized LiDAR data as a lightweight and structured perceptual representation, and employs a z-grouped 2D CNN to map this representation to the control policy, enabling fully end-to-end optimization. A high-fidelity LiDAR simulation that dynamically generates realistic observations is developed to support scalable, LiDAR-based training and ensure sim-to-real consistency. Experimental results show that Gallant's broader perceptual coverage facilitates the use of a single policy that goes beyond the limitations of previous methods confined to ground-level obstacles, extending to lateral clutter, overhead constraints, multi-level structures, and narrow passages. Gallant also firstly achieves near 100% success rates in challenging scenarios such as stair climbing and stepping onto elevated platforms through improved end-to-end optimization.

</details>


### [46] [NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards](https://arxiv.org/abs/2511.14659)
*Chia-Yu Hung,Navonil Majumder,Haoyuan Deng,Liu Renhang,Yankang Ang,Amir Zadeh,Chuan Li,Dorien Herremans,Ziwei Wang,Soujanya Poria*

Main category: cs.RO

TL;DR: NORA-1.5是一种VLA模型，通过添加基于流匹配的动作专家和奖励驱动的后训练，显著提升了性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在跨环境和任务中的可靠性和泛化能力不足。

Method: 通过添加动作专家模块和改进的后训练奖励模型（结合世界模型和启发式评价）来优化模型。

Result: NORA-1.5在模拟和真实环境中均表现优异，奖励驱动的后训练进一步提升了性能。

Conclusion: NORA-1.5及其后训练方法是提高VLA模型可靠性的有效途径。

Abstract: Vision--language--action (VLA) models have recently shown promising performance on a variety of embodied tasks, yet they still fall short in reliability and generalization, especially when deployed across different embodiments or real-world environments. In this work, we introduce NORA-1.5, a VLA model built from the pre-trained NORA backbone by adding to it a flow-matching-based action expert. This architectural enhancement alone yields substantial performance gains, enabling NORA-1.5 to outperform NORA and several state-of-the-art VLA models across both simulated and real-world benchmarks. To further improve robustness and task success, we develop a set of reward models for post-training VLA policies. Our rewards combine (i) an action-conditioned world model (WM) that evaluates whether generated actions lead toward the desired goal, and (ii) a deviation-from-ground-truth heuristic that distinguishes good actions from poor ones. Using these reward signals, we construct preference datasets and adapt NORA-1.5 to target embodiments through direct preference optimization (DPO). Extensive evaluations show that reward-driven post-training consistently improves performance in both simulation and real-robot settings, demonstrating significant VLA model-reliability gains through simple yet effective reward models. Our findings highlight NORA-1.5 and reward-guided post-training as a viable path toward more dependable embodied agents suitable for real-world deployment.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: 论文研究了当前先进视觉语言模型（VLM）在空间推理任务中的局限性，提出了新的基准框架SpatiaLite，并揭示了模型依赖语言表征的缺陷，同时提出了一种基于想象的改进框架。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类认知的重要组成部分，但当前的视觉语言模型在这一领域表现不佳。本研究旨在探讨其空间推理机制，并提出改进方案。

Method: 研究者开发了SpatiaLite基准，用于系统测量VLM的空间推理能力，并通过实验分析了模型的缺陷和模式。此外，提出了基于想象的改进框架（IDF）。

Result: 研究发现VLM依赖语言表征导致视觉中心任务的缺陷，且推理效率低下。IDF框架能够帮助模型隐式构建内部世界模型，提升空间推理能力。

Conclusion: 研究揭示了当前VLM的空间推理局限性，并通过IDF框架为未来的模型改进提供了方向。

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [48] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: Bjøru等人的研究提出了一种新颖的分治法，用于在结构因果模型中界定反事实概率。本文探讨了将该方法扩展至半马尔可夫结构因果模型的挑战和策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决纯观测数据学习结构因果模型时对外生变量边缘分布的不精确表征问题，并探索将分治法从马尔可夫模型扩展到更具表达能力的半马尔可夫模型的应用。

Method: 通过将高基数外生变量的模型分解为多个子模型，利用子模型进行高效精确推断，随后将结果聚合以界定原始模型中的反事实概率。本文进一步探讨了将该方法扩展到半马尔可夫模型（多外生变量影响多内生变量）的挑战和解决策略。

Result: 针对半马尔可夫模型的扩展提出了替代解决方案，并通过理论和计算研究对这些策略进行了评估。

Conclusion: 研究表明，扩展分治法至半马尔可夫模型虽然面临挑战，但仍具有可行性，并且通过提出的策略能够有效解决相关问题。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [49] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 该论文系统地分析了智能交通系统中集成的大型视觉语言模型（LVLMs）在精心设计的越狱攻击下的漏洞，并提出了攻击方法和防御技术。


<details>
  <summary>Details</summary>
Motivation: 研究LVLMs在智能交通系统中的脆弱性，以揭示其可能受到的越狱攻击风险，并提出有效的防御措施。

Method: 构建交通相关有害查询数据集，设计基于图像排版操纵和多轮提示的越狱攻击，并提出多层响应过滤防御技术。

Result: 实验表明，所提出的攻击方法有效，防御技术能防止模型生成不当响应，并揭示了现有越狱技术的严重安全风险。

Conclusion: 论文强调了LVLMs在智能交通系统中的安全问题，并提出了有效的攻击和防御方法，为未来研究提供了重要参考。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [50] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: 论文提出了一种新的匹配算法CORGI，用于解决规则匹配中的时间和空间复杂性问题，相比RETE算法具有更优的性能。


<details>
  <summary>Details</summary>
Motivation: 解决规则匹配系统中因匹配模式复杂导致的指数级时间和空间需求问题，特别是在AI系统和数据库查询中的实时性要求。

Method: 提出CORGI算法，采用两步法（前向构建关系图和反向迭代生成匹配），避免RETE算法中的β内存问题，提供平方级时间和空间保证。

Result: 在性能测试中，CORGI在组合匹配任务中显著优于SOAR和OPS5的RETE实现。

Conclusion: CORGI通过创新的设计和迭代匹配机制，有效解决了规则匹配中的效率和内存问题，适用于实时应用。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [51] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 提出了一种基于场景图引导的生成AI框架，通过历史OSHA事故报告生成逼真的危险场景图像，并用VQA框架评估其真实性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 由于现实中难以捕捉事故触发场景，研究旨在通过生成逼真图像来解决数据集稀缺问题。

Method: 使用GPT-4o分析OSHA报告，提取结构化风险信息并转换为场景图，再通过扩散模型生成图像，最后设计VQA框架评估生成效果。

Result: 提出的VQA Graph Score在评估生成图像时优于CLIP和BLIP指标，验证了其更高的判别敏感性。

Conclusion: 该方法能够有效生成逼真的危险场景图像，并显著提升评估指标的敏感性。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [52] [Artificial Intelligence Agents in Music Analysis: An Integrative Perspective Based on Two Use Cases](https://arxiv.org/abs/2511.13987)
*Antonio Manuel Martínez-Heredia,Dolores Godrid Rodríguez,Andrés Ortiz García*

Main category: cs.AI

TL;DR: 本文综述并验证了AI在音乐分析与教育中的应用，涵盖从规则模型到深度学习的历史演变，并通过双案例实验证明AI在音乐模式识别和教育反馈中的优势。


<details>
  <summary>Details</summary>
Motivation: 探索AI在音乐教学与分析中的潜力，解决传统方法的局限性，推动透明、可解释的AI应用。

Method: 采用双案例研究方法：(1)生成式AI在中学教育中的应用，(2)多智能体系统在符号音乐分析中的设计。

Result: 实验证明AI在音乐模式识别和教学反馈中表现优于传统方法，但也面临透明度与文化偏见等挑战。

Conclusion: 提出统一框架，结合技术、教学与伦理，为AI在计算音乐学和教育中的负责任应用提供指导。

Abstract: This paper presents an integrative review and experimental validation of artificial intelligence (AI) agents applied to music analysis and education. We synthesize the historical evolution from rule-based models to contemporary approaches involving deep learning, multi-agent architectures, and retrieval-augmented generation (RAG) frameworks. The pedagogical implications are evaluated through a dual-case methodology: (1) the use of generative AI platforms in secondary education to foster analytical and creative skills; (2) the design of a multiagent system for symbolic music analysis, enabling modular, scalable, and explainable workflows.
  Experimental results demonstrate that AI agents effectively enhance musical pattern recognition, compositional parameterization, and educational feedback, outperforming traditional automated methods in terms of interpretability and adaptability. The findings highlight key challenges concerning transparency, cultural bias, and the definition of hybrid evaluation metrics, emphasizing the need for responsible deployment of AI in educational environments.
  This research contributes to a unified framework that bridges technical, pedagogical, and ethical considerations, offering evidence-based guidance for the design and application of intelligent agents in computational musicology and music education.

</details>


### [53] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX是一个轻量级知识编辑框架，通过分层内存架构和高效检索模块，显著提升了多跳问题回答的准确性和可靠性，同时降低了搜索空间。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型(LLM)静态知识无法适应动态信息的问题，以及现有方法在扩展性和检索效率上的不足。

Method: 提出ALEX框架，包含分层内存架构、推理查询合成模块(IQS)和动态证据裁决引擎(DEA)，将检索复杂度从O(N)降至O(K+N/C)。

Result: 在MQUAKE基准测试中，ALEX显著提高了多跳答案准确性(MultiHop-ACC)和推理路径可靠性(HopWise-ACC)，并减少了80%以上的搜索空间。

Conclusion: ALEX为构建可扩展、高效且准确的知识编辑系统提供了有前途的解决方案。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [54] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: 该论文提出了Syn-STARTS框架，利用LLM生成分诊案例，其生成的数据在质量上与人工整理的TRIAGE数据集难以区分，且在准确性评估中表现稳定，展示了合成数据在高性能AI模型开发中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于大规模伤亡事件(MCI)发生频率低，难以积累足够的高质量真实数据集来支持AI分诊研究，因此需要一种替代方法来生成高质量的合成数据。

Method: 研究者开发了Syn-STARTS框架，利用LLM生成分诊案例，并通过与人工整理的TRIAGE数据集对比，验证生成数据的质量与稳定性。

Result: Syn-STARTS生成的分诊案例质量与人工整理的数据集相当，且在标准分诊方法START的分类准确性评估中表现稳定。

Conclusion: 研究表明，合成数据可以用于开发高性能AI分诊模型，尤其在紧急医疗情况下具有重要价值。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [55] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 该研究提出了一种由教师主导的反馈循环系统，将概念级评估证据转化为经过验证的微干预，解决了自适应学习诊断精准但干预薄弱的问题，实现了高覆盖和低冗余的个性化学习。


<details>
  <summary>Details</summary>
Motivation: 自适应学习虽然能精准诊断学习问题，但干预往往不足或时机不当，导致效果有限。研究者提出了一种更高效的干预方法，通过教师主导的反馈循环提升干预质量。

Method: 研究设计了一种自适应学习算法，包含三个保障机制：充分的差距闭合保障、预算约束的时间和冗余控制、以及防止过拟合的多样性保护。干预分配被形式化为一个二值整数规划问题，包含覆盖、时间、难度窗口等约束。

Result: 在模拟和实际物理课程（1204名学生）中，算法实现了几乎全学生的技能覆盖，梯度法在减少冗余和提高难度一致性方面优于贪心法，而贪心法在资源匮乏时计算成本更低。

Conclusion: 该研究提出了一种高效、可审计的控制器，能够闭合诊断与教学循环，实现公平且负载感知的个性化学习，适用于课堂规模。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [56] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: APD-agents是一个基于大型语言模型的多智能体框架，用于自动化移动应用页面设计，通过动态协作完成用户设计任务，显著减少设计时间和提高质量。


<details>
  <summary>Details</summary>
Motivation: 移动应用页面设计耗时且复杂，设计师需要反复调整控件和内容的布局与样式。现有设计软件虽能辅助，但学习成本高且跨页面协作效率低。为此，提出APD-agents以自动化设计流程，提高效率与一致性。

Method: 提出APD-agents框架，包含5个智能体：OrchestratorAgent（任务协调）、SemanticParserAgent（结构化解析）、PrimaryLayoutAgent（初始布局生成）、TemplateRetrievalAgent（样例增强）和RecursiveComponentAgent（细粒度子元素生成）。用户描述页面后，框架通过智能体协作完成设计。

Result: 在RICO数据集上的实验表明，APD-agents实现了最佳性能，能够高效生成符合用户需求的页面布局。

Conclusion: APD-agents通过多智能体动态协作，显著提升了移动应用页面设计的自动化水平与质量，为设计师提供了高效且一致的解决方案。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [57] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: R3框架结合大型语言模型（LLMs）的泛化能力和VLN领域专家知识，通过Runner、Ruminator和Regulator模块，高效解决Vision-and-Language Navigation任务的挑战，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的VLN方法在任务完成性能和计算成本上存在不足，需结合LLM的通用推理能力和VLN特定知识以解决问题。

Method: 提出R3双进程思维框架，包含Runner（轻量专家模型）、Ruminator（多模态LLM结构化推理）和Regulator（动态调控模块）。

Result: 在REVERIE基准测试中，R3在SPL和RGSPL上分别超过现有方法3.28%和3.30%。

Conclusion: R3通过融合泛化与领域专长，显著提升VLN任务性能，验证了其高效性和实用性。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [58] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型（LLM）在金融和经济学中的应用，测试了模型对时间顺序的理解能力，发现局部时间顺序相对较好，但全局一致性的时间线表现较差。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在处理时间顺序任务时的表现，特别是在金融实时应用中可能存在的局限性。

Method: 通过三类时间顺序任务（时间排序、条件排序和时代错误检测）对多个语言模型（如GPT-4.1、Claude-3.7 Sonnet等）进行测试，并比较不同推理能力设置下的表现。

Result: 发现模型的精确匹配率随任务复杂度增加而下降，但分配明确的推理预算可以显著提升表现，GPT-5在高推理能力下表现尤为出色。

Conclusion: 研究揭示了当前语言模型在时间顺序任务中的局限性，并为任务复杂性和推理能力的作用提供了重要见解。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [59] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 本文提出了一种两阶段架构，通过自适应层注意力（ALA）和多目标知识蒸馏（KD）框架，显著减少Whisper模型在噪声环境中的幻觉错误，同时保持其在高斯语音上的性能。


<details>
  <summary>Details</summary>
Motivation: Whisper模型在噪声环境下容易产生幻觉错误，而现有的改进方法主要集中在音频预处理或转录后处理，缺乏对模型本身的直接优化。

Method: 1. 使用ALA增强编码器鲁棒性，通过层间相关性分析将编码器层分组为语义一致的块，并利用多头注意力模块融合这些块表示。2. 采用多目标KD框架，在噪声音频上训练学生模型，使其语义和注意力分布与处理干净输入的教师模型对齐。

Result: 实验表明，该方法在噪声语音基准测试中显著减少了幻觉错误和词错误率，同时不影响干净语音的性能。

Conclusion: ALA和KD为改善Whisper模型在真实噪声环境中的可靠性提供了有效策略。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [60] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的物联网设备操作推荐模型DevPiolt，通过持续预训练和多任务微调提升模型性能，结合直接偏好优化和置信度机制，显著优于基线方法，并在实际应用中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有推荐模型难以处理物联网设备操作的复杂性、用户偏好多样性以及对低质量建议的敏感性，因此需要一种更高效的解决方案来优化用户体验和企业收益。

Method: DevPiolt通过持续预训练和多任务微调增强LLM的基础领域知识，利用直接偏好优化对齐用户偏好，并引入置信度控制机制避免低质量推荐。

Result: 实验显示DevPiolt在所有数据集上平均提升69.5%，实际部署后用户设备覆盖率和页面接受率分别提升21.6%和29.1%。

Conclusion: DevPiolt有效解决了物联网设备操作推荐的挑战，显著提升了推荐质量和用户体验。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [61] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 论文提出了一种新颖的时间序列预测框架，用于区域级的Airbnb市场趋势预测，结合LLM和高级时间序列模型，提升了准确性并为政策制定提供了支持。


<details>
  <summary>Details</summary>
Motivation: 短期租赁平台（如Airbnb）对本地住房市场的破坏性影响促使研究预测其市场趋势，以便政策制定者和城市规划者缓解相关问题。

Method: 采用滑动窗口方法预测1至3个月的趋势，将表格数据转化为提示输入LLM生成区域嵌入，再输入到高级时间序列模型（RNN、LSTM、Transformer）中。

Result: 在首尔Airbnb数据集上的实验表明，与传统基线相比，该方法将平均RMSE和MAE降低了约48%。

Conclusion: 该框架不仅提高了预测准确性，还为检测供应过剩区域和支持数据驱动的城市政策决策提供了实用见解。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [62] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind是一个新框架，通过选择性引导LLMs使用重要推理路径来增强忠实和可解释的推理，解决现有LLM-based知识图谱推理方法中的噪声和高检索需求问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型（LLMs）的知识图谱推理（KGR）方法存在两个关键限制：一是盲目提取推理路径导致噪声，二是高检索需求和频繁调用LLMs。

Method: PathMind采用“检索-优先化-推理”模式，包括检索查询子图、通过语义感知路径优先级函数识别重要路径，以及通过双阶段训练策略生成准确响应。

Result: 在基准数据集上的广泛实验表明，PathMind在复杂推理任务中表现优于现有方法，尤其是在输入标记较少时。

Conclusion: PathMind通过选择性路径引导和优化训练策略，显著提升了知识图谱推理的效率和准确性。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [63] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型在自动生成优化和约束编程模型时的表现，发现其在上下文和语言变化下性能显著下降，揭示了模型的浅层理解和对措辞的敏感性。


<details>
  <summary>Details</summary>
Motivation: 长期以来，优化和约束编程领域的目标是能够用自然语言描述问题并自动生成高效的可执行模型。大型语言模型的出现让这一愿景更接近，但其成功可能源于数据污染而非真正的推理能力。

Method: 通过系统性地重述和扰动CSPLib中的经典问题，保留结构但改变上下文并引入误导性元素，比较三个代表性大型语言模型在原始和修改后描述中的表现。

Result: 尽管大型语言模型能生成语法有效且语义合理的模型，但在上下文和语言变化下性能显著下降，表明其理解浅层且对措辞敏感。

Conclusion: 研究揭示了大型语言模型在生成优化和约束编程模型时的局限性，其成功可能依赖于训练数据中的已知问题而非真正的推理能力。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [64] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 研究探讨了如何通过融入多元价值来影响大型语言模型（LLM）的行为，系统评估了人口统计差异和设计参数对模型对齐的影响。


<details>
  <summary>Details</summary>
Motivation: 现有对齐决策常忽视人类社会的多样性，研究旨在探索如何平衡专家驱动和用户驱动的信号以确保安全和公平。

Method: 通过收集美国和德国参与者的数据，在不同维度上评分LLM响应，并基于群体偏好微调模型，分析评分尺度和优化方法的效果。

Result: 结果显示人口统计效应显著，技术设计选择（如评分尺度和优化技术）对模型行为有重要影响，DPO在多元优化中表现优于GRPO。

Conclusion: 研究为平衡模型安全性与公平性提供了初步探索，并强调技术设计和群体偏好在对齐中的重要性。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


### [65] [A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning](https://arxiv.org/abs/2511.14533)
*Jiahao Wu,Shengwen Yu*

Main category: cs.AI

TL;DR: 论文提出了一种神经符号框架，将感知与规划之间的不确定性建模和传递连接起来，通过结合Transformer和GNN实现概率符号状态提取，并在规划中主动收集信息，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统中连续感知信号与离散符号推理之间的不确定性问题，提供一个原则性的连接框架。

Method: 采用基于Transformer的感知前端和GNN关系推理提取概率符号状态，结合不确定性感知的符号规划器，主动在低置信度时收集信息。

Result: 在桌面机器人操作任务中，成功率达到94%/90%/88%，优于基线方法10-14个百分点，且规划时间在15毫秒内。

Conclusion: 该框架具有通用性，适用于任何需要从感知输入到符号规划的不确定性推理领域，并通过理论和实验验证了其有效性。

Abstract: Bridging continuous perceptual signals and discrete symbolic reasoning is a fundamental challenge in AI systems that must operate under uncertainty. We present a neuro-symbolic framework that explicitly models and propagates uncertainty from perception to planning, providing a principled connection between these two abstraction levels. Our approach couples a transformer-based perceptual front-end with graph neural network (GNN) relational reasoning to extract probabilistic symbolic states from visual observations, and an uncertainty-aware symbolic planner that actively gathers information when confidence is low. We demonstrate the framework's effectiveness on tabletop robotic manipulation as a concrete application: the translator processes 10,047 PyBullet-generated scenes (3--10 objects) and outputs probabilistic predicates with calibrated confidences (overall F1=0.68). When embedded in the planner, the system achieves 94\%/90\%/88\% success on Simple Stack, Deep Stack, and Clear+Stack benchmarks (90.7\% average), exceeding the strongest POMDP baseline by 10--14 points while planning within 15\,ms. A probabilistic graphical-model analysis establishes a quantitative link between calibrated uncertainty and planning convergence, providing theoretical guarantees that are validated empirically. The framework is general-purpose and can be applied to any domain requiring uncertainty-aware reasoning from perceptual input to symbolic planning.

</details>


### [66] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 提出了一种基于率失真理论和最优传输几何的知识图谱构建与优化框架，用于从非结构化教育材料生成高质量多选题。


<details>
  <summary>Details</summary>
Motivation: 将非结构化教育材料（如讲义和幻灯片）转化为捕捉关键教学内容的任务知识图谱仍具有挑战性。

Method: 将讲义内容建模为度量-测度空间，利用Fused Gromov-Wasserstein耦合对候选知识图谱进行对齐，并通过率失真拉格朗日优化构建紧凑且信息保留的知识图谱。

Result: 应用于数据科学讲义的原型显示，优化后的知识图谱生成的多选题在15项质量标准上优于原始笔记。

Conclusion: 该研究为信息论知识图谱优化在个性化和AI辅助教育中奠定了理论基础。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [67] [Blurred Encoding for Trajectory Representation Learning](https://arxiv.org/abs/2511.13741)
*Silin Zhou,Yao Chen,Shuo Shang,Lisi Chen,Bingsheng He,Ryosuke Shibasaki*

Main category: cs.LG

TL;DR: BLUE方法通过分层模糊编码保留轨迹的细粒度时空细节，实现了更高的下游任务准确率。


<details>
  <summary>Details</summary>
Motivation: 传统TRL方法在捕获高级语义时会丢失GPS轨迹的细粒度时空细节，BLUE旨在解决这一不足。

Method: 采用分层模糊编码和金字塔结构的编码器-解码器模型，结合Transformer和池化操作。

Result: 在3个下游任务中，BLUE平均比最佳基线方法准确率高30.90%。

Conclusion: BLUE在保留细节和捕捉整体模式方面优于现有方法，适用于多级轨迹表示学习。

Abstract: Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.

</details>


### [68] [SCALEX: Scalable Concept and Latent Exploration for Diffusion Models](https://arxiv.org/abs/2511.13750)
*E. Zhixuan Zeng,Yuhao Chen,Alexander Wong*

Main category: cs.LG

TL;DR: SCALEX是一个可扩展的自动化框架，用于分析扩散模型中的潜在偏差，仅需自然语言提示即可提取语义方向，无需重新训练或标记。


<details>
  <summary>Details</summary>
Motivation: 现有方法对扩散模型中的偏见分析局限于预定义类别或人工解释，难以发现细微或意外模式，SCALEX旨在解决这一问题。

Method: 通过自然语言提示从H空间中提取语义方向，实现零样本解释和系统化概念比较。

Result: SCALEX能检测职业提示中的性别偏见、评估身份描述符的语义对齐，并揭示无监督的聚类概念结构。

Conclusion: SCALEX使扩散模型的偏见分析更具可扩展性、可解释性和扩展性，优于现有方法。

Abstract: Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.
  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.

</details>


### [69] [Robustness of LLM-enabled vehicle trajectory prediction under data security threats](https://arxiv.org/abs/2511.13753)
*Feilong Wang,Fuqiang Liu*

Main category: cs.LG

TL;DR: 该论文研究了基于大语言模型（LLM）的自动驾驶系统在轨迹预测中的脆弱性，提出了一种单特征差分进化攻击方法，揭示了模型在对抗性扰动下的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在自动驾驶决策中的潜力日益增长，但其在安全关键系统中的鲁棒性尚未得到充分研究，因此本文旨在填补这一空白。

Method: 通过提出一种单特征差分进化攻击方法，在无需模型内部信息的黑盒设置下扰动输入提示中的运动学特征。

Result: 实验表明，即使是微小的物理可信扰动也能显著破坏模型输出，同时揭示了准确性与鲁棒性之间的权衡。

Conclusion: 研究揭示了LLM驱动的自动驾驶系统在对抗性攻击下的脆弱性，强调了未来设计中需注重鲁棒性。

Abstract: The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.

</details>


### [70] [Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement](https://arxiv.org/abs/2511.13755)
*Zhe Yang,Wenrui Li,Hongtao Chen,Penghong Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.LG

TL;DR: 论文提出了一种自适应冗余调节方法（RedReg），用于平衡多模态学习中的模态偏差问题，通过监测冗余阶段和设计共信息门控机制，优化模态间梯度调节，提升训练效果。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中，由于模态偏差，优势模态常主导训练过程，导致优化不平衡和冗余信息积累，现有方法未能有效解决这些问题。

Method: 提出RedReg方法，包括构建冗余阶段监测器和共信息门控机制，通过正交投影调节优势模态梯度。

Result: 实验表明，RedReg在多数场景下优于现有方法，消融实验验证了其有效性。

Conclusion: RedReg通过自适应冗余调节，有效平衡多模态训练，提升性能。

Abstract: Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git

</details>


### [71] [VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care](https://arxiv.org/abs/2511.13757)
*Xiuding Cai,Xueyao Wang,Sen Wang,Yaoyao Zhu,Jiao Chen,Yu Yao*

Main category: cs.LG

TL;DR: VitalBench是一个专门用于术中生命体征预测的新基准，旨在解决现有挑战，包括数据标准化、不完整数据和跨中心验证问题。


<details>
  <summary>Details</summary>
Motivation: 术中生命体征的监测和预测对患者安全和手术效果至关重要，但当前面临标准化基准缺失、数据不完整和跨中心验证不足等挑战。

Method: 引入VitalBench基准，包含来自两个医疗中心的4000多例手术数据，提供完整数据、不完整数据和跨中心泛化三个评估轨道，并结合掩码损失技术进行鲁棒评估。

Result: VitalBench为模型开发和比较提供了一个标准化平台，减少了数据预处理的依赖，并支持多样临床环境中的模型适应性和准确性。

Conclusion: VitalBench为术中生命体征预测模型的进一步发展奠定了基础，确保其不仅在准确性上表现优异，还能在不同临床环境中稳健运行。

Abstract: Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.

</details>


### [72] [ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space](https://arxiv.org/abs/2511.13758)
*Jun-Hyoung Park,Ho-Jun Song,Seong-Whan Lee*

Main category: cs.LG

TL;DR: ChemFixer是一个基于深度学习的分⼦修复框架，能够将⽆效分⼦转化为有效分⼦，提升药物候选分⼦的多样性和实⽤性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的分子生成模型常产生化学无效分子，限制了其实际应用。

Method: 提出基于Transformer架构的ChemFixer框架，通过掩码技术预训练，并在大规模有效/无效分子对上微调。

Result: ChemFixer显著提⾼分子有效性，同时保持原始输出的化学和生物学分布特性，并可扩展应用于药物靶点预测等任务。

Conclusion: ChemFixer是⼀种实用的工具，可提升深度学习药物发现中的分子有效性并扩展可探索的化学空间。

Abstract: Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.

</details>


### [73] [Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection](https://arxiv.org/abs/2511.13759)
*Han Wang,Deyi Ji,Junyu Lu,Lanyun Zhu,Hailong Zhang,Haiyang Wu,Liqun Liu,Peng Shu,Roy Ka-Wei Lee*

Main category: cs.LG

TL;DR: 提出了一种基于自训练和多智能体视觉语言模型的框架，用于低资源环境下社交媒体中攻击性内容的检测。


<details>
  <summary>Details</summary>
Motivation: 解决因攻击性实例稀少和标注成本高导致的标签数据稀缺问题。

Method: 通过协作伪标注利用未标注数据，采用多智能体视觉语言模型（MA-VLMs）模拟双重视角，并使用PNU损失优化分类器。

Result: 在基准数据集上的实验表明，该方法在有限监督下显著优于基线，接近大规模模型的性能。

Conclusion: 该框架有效提升了低资源环境下攻击性内容检测的准确性和可靠性。

Abstract: Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models

</details>


### [74] [MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm](https://arxiv.org/abs/2511.13760)
*Xiao Fan,Jingyan Jiang,Zhaoru Chen,Fanding Huang,Xiao Chen,Qinting Jiang,Bowen Zhang,Xing Tang,Zhi Wang*

Main category: cs.LG

TL;DR: MoETTA提出了一种基于熵的测试时间自适应框架，通过Mixture-of-Experts架构适应混合分布偏移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在混合分布偏移下表现不佳，因为它们依赖统一的适应路径，无法适应不同域的最优梯度方向。

Method: 引入MoE架构，通过一组结构解耦的专家实现多样化梯度方向的参数更新，适应异质性偏移。

Result: 在三个混合分布偏移设定下，MoETTA显著优于基线方法，确立了SOTA性能。

Conclusion: MoETTA通过专家级多样性建模多适应路径，有效解决了混合分布偏移下的挑战。

Abstract: Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.

</details>


### [75] [Gene Incremental Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2511.13762)
*Jiaxin Qi,Yan Cui,Jianqiang Huang,Gaogang Xie*

Main category: cs.LG

TL;DR: 该论文研究了基因在单细胞转录组学中的增量学习问题，提出了一个针对基因的增量学习框架，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的增量学习研究主要集中在类别上，而类似的语言标记（如基因）的增量学习研究却很少。论文旨在填补这一空白，探索基因增量学习的可行性和方法。

Method: 作者采用了适应现有类别增量学习方法的策略，针对单细胞转录组学中的基因设计了一个增量学习框架，并进行了广泛实验。

Result: 实验结果表明，该框架设计合理，适应的方法有效缓解了基因增量学习中的遗忘问题。

Conclusion: 论文为单细胞转录组学中的基因增量学习提供了一个完整的基准，推动了该领域的研究。

Abstract: Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.

</details>


### [76] [Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels](https://arxiv.org/abs/2511.13764)
*Arun Thangamani,Md Asghar Ahmad Shahid,Adam Siemieniuk,Rolf Morel,Renato Golin,Alexander Heinecke*

Main category: cs.LG

TL;DR: 论文提出一种编译方案，自动生成可扩展的高性能微核，通过MLIR桥接领域操作与硬件能力，减少对底层库的依赖。


<details>
  <summary>Details</summary>
Motivation: AI和机器学习工作负载快速发展，但高性能实现仍依赖硬件专家，增加了复杂性并限制了可扩展性，本文旨在解决这一问题。

Method: 利用MLIR方言构建编译方案，自动生成接近最优的微核代码，通过低层IR构造高效微核，适用于CPU指令集。

Result: 实验表明生成的纳米核具有生产质量，与最先进的微核库相媲美。

Conclusion: 该编译方案成功降低了硬件依赖性，提升了领域操作到硬件的转换效率。

Abstract: The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.
  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.

</details>


### [77] [PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning](https://arxiv.org/abs/2511.13765)
*Shengjie Sun,Jiafei Lyu,Runze Liu,Mengbei Yan,Bo Liu,Deheng Ye,Xiu Li*

Main category: cs.LG

TL;DR: 该论文提出了一种名为PROF的新框架，利用大型语言模型（LLMs）从自然语言描述和单一专家轨迹中生成和改进可执行的奖励函数代码，并结合奖励偏好排序（RPR）策略，实现自动化选择和优化奖励函数。


<details>
  <summary>Details</summary>
Motivation: 现有的离线模仿学习方法假设轨迹与专家演示的相似性与奖励正相关，但这种方法过于简化了奖励结构。PROF旨在通过更智能的方式生成和优化奖励函数，以更好地与专家偏好对齐。

Method: PROF框架结合了大型语言模型（LLMs）和奖励偏好排序（RPR）策略。LLM用于从自然语言描述和专家轨迹生成奖励函数代码，而RPR则通过计算奖励函数的支配分数来评估其质量，无需环境交互或强化学习训练。

Result: 在D4RL上的实验结果表明，PROF在多个数据集和领域上优于或媲美现有基线方法，证明了其有效性。

Conclusion: PROF通过自动化选择和优化奖励函数，为离线模仿学习提供了一种更高效且无需显式奖励标注的解决方案，展示了与专家偏好更好对齐的潜力。

Abstract: Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.

</details>


### [78] [Credal Ensemble Distillation for Uncertainty Quantification](https://arxiv.org/abs/2511.13766)
*Kaizheng Wang,Fabio Cuzzolin,David Moens,Hans Hallez*

Main category: cs.LG

TL;DR: 为了降低深度集成（DE）的高计算和内存成本，提出了信用集合蒸馏（CED）框架，将其压缩为单一模型CREDIT，用于分类任务。CREDIT预测类间概率区间以量化不确定性，实验表明其性能优于或与现有方法相当，同时显著减少推理开销。


<details>
  <summary>Details</summary>
Motivation: 深度集成在不确定性量化中表现优越，但推理时的高计算和内存成本限制了其实际应用。

Method: 提出信用集合蒸馏（CED）框架，将深度集压缩为单一模型CREDIT，预测类间概率区间以量化不确定性。

Result: 在分布外检测任务中，CED的不确定性估计性能优于或与现有方法相当，同时大幅降低推理开销。

Conclusion: CED是一种高效且可靠的不确定性量化方法，适用于实际部署。

Abstract: Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.

</details>


### [79] [Dynamic Temperature Scheduler for Knowledge Distillation](https://arxiv.org/abs/2511.13767)
*Sibgat Ul Islam,Jawad Ibn Ahad,Fuad Rahman,Mohammad Ruhul Amin,Nabeel Mohammed,Shafin Rahman*

Main category: cs.LG

TL;DR: 论文提出了一种动态温度调节器（DTS），用于知识蒸馏中动态调整温度，解决了传统固定温度方法的不足，并在多个任务上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法使用固定温度，无法适应训练的不同阶段需求，且教师与学生模型的架构差异会导致输入大小不匹配的问题。

Method: 提出动态温度调度器（DTS），根据教师和学生模型之间的交叉熵损失差距动态调整温度，以优化知识蒸馏过程。

Result: 在视觉（CIFAR-100、Tiny-ImageNet）和NLP任务（GLUE等）上验证，DTS方法均优于静态温度基线。

Conclusion: DTS方法能够自适应地调整温度，显著提升知识蒸馏效果，适用于多种任务，代码已开源。

Abstract: Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.

</details>


### [80] [Exploring Transferability of Self-Supervised Learning by Task Conflict Calibration](https://arxiv.org/abs/2511.13787)
*Huijie Guo,Jingyao Wang,Peizheng Guo,Xingchen Shen,Changwen Zheng,Wenwen Qiang*

Main category: cs.LG

TL;DR: 论文通过元学习范式探索自监督学习（SSL）的表示迁移性，并提出任务冲突校准方法（TC²）以提升迁移性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在回答两个核心问题：SSL的表示迁移性是什么？如何有效建模这种迁移性？迁移性定义为从一个任务学到的表示支持另一个任务目标的能力。

Method: 采用元学习范式在每个训练批次内构建多个SSL任务，并提出TC²方法来缓解任务冲突。TC²通过批次分割、因果生成因子提取和权重分配等技术优化样本表示。

Result: 实验表明，TC²方法能显著提升SSL模型的迁移性，在多下游任务中表现一致。

Conclusion: TC²通过校准任务冲突和优化表示，有效提升了SSL的迁移性，为相关研究提供了新思路。

Abstract: In this paper, we explore the transferability of SSL by addressing two central questions: (i) what is the representation transferability of SSL, and (ii) how can we effectively model this transferability? Transferability is defined as the ability of a representation learned from one task to support the objective of another.
  Inspired by the meta-learning paradigm, we construct multiple SSL tasks within each training batch to support explicitly modeling transferability. Based on empirical evidence and causal analysis, we find that although introducing task-level information improves transferability, it is still hindered by task conflict. To address this issue, we propose a Task Conflict Calibration (TC$^2$) method to alleviate the impact of task conflict. Specifically, it first splits batches to create multiple SSL tasks, infusing task-level information. Next, it uses a factor extraction network to produce causal generative factors for all tasks and a weight extraction network to assign dedicated weights to each sample, employing data reconstruction, orthogonality, and sparsity to ensure effectiveness. Finally, TC$^2$ calibrates sample representations during SSL training and integrates into the pipeline via a two-stage bi-level optimization framework to boost the transferability of learned representations. Experimental results on multiple downstream tasks demonstrate that our method consistently improves the transferability of SSL models.

</details>


### [81] [ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design](https://arxiv.org/abs/2511.13809)
*Emanuel Covaci,Fabian Galis,Radu Balan,Daniela Zaharie,Darian Onchis*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的端到端可训练方法，将特征重要性评估直接融入模型训练，实现全局可解释性。其核心是嵌入学习管道的ScoresActivation函数，显著提升特征排名速度与分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有事后解释方法虽提供特征重要性洞察，但与训练过程脱节，限制了其忠实性与实用性。为解决这一问题，作者提出了一种全局可解释性的新方法。

Method: 通过将ScoresActivation函数嵌入学习管道，以可微分的方式在训练中评估特征重要性，实现端到端训练。

Result: 该方法在基准数据集上实现了与SHAP值和真实特征重要性一致的全局忠实特征排名，且特征评分速度比SHAP快150倍，同时显著提高了分类准确性。

Conclusion: 该工作弥合了模型准确性与可解释性之间的差距，为内在地可解释的机器学习提供了可扩展框架。

Abstract: Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.

</details>


### [82] [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)
*Zelei Shao,Vikranth Srivatsa,Sanjana Srivastava,Qingyang Wu,Alpay Ariyak,Xiaoxia Wu,Ameen Patel,Jue Wang,Percy Liang,Tri Dao,Ce Zhang,Yiying Zhang,Ben Athiwaratkun,Chenfeng Xu,Junxiong Wang*

Main category: cs.LG

TL;DR: DAS框架通过分布感知的推测解码，加速了强化学习的后训练过程，减少了50%的生成时间，同时不改变模型输出或学习质量。


<details>
  <summary>Details</summary>
Motivation: 研究发现强化学习后训练中的长尾分布问题导致长生成时间占主导，利用历史生成数据可揭示稳定模式，从而提出优化方案。

Method: DAS框架结合自适应非参数草稿器（基于后缀树）和长度感知的推测策略，动态分配草算预算以提高长轨迹的生成效率。

Result: 实验显示在数学和代码推理任务中，DAS将生成时间减少高达50%，同时保持训练曲线不变。

Conclusion: DAS通过利用历史数据和分布感知的解码策略，在不影响学习质量的前提下显著提升了RL后训练的效率。

Abstract: Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.

</details>


### [83] [AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection](https://arxiv.org/abs/2511.13880)
*Saleh Momeni,Changnan Xiao,Bing Liu*

Main category: cs.LG

TL;DR: 论文提出了一种名为AnaCP的新方法，用于解决类增量学习中的特征适应问题，无需梯度更新即可实现高效的特征调整，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习方法面临灾难性遗忘问题，而现有的基于预训练模型的方法无法持续优化特征表示。AnaCP旨在解决这一局限性。

Method: AnaCP结合分析分类器的高效性和对比投影技术，实现无需梯度训练的特征适应，避免了梯度更新导致的灾难性遗忘。

Result: 实验表明，AnaCP不仅超越现有基准方法，还达到了联合训练的准确率水平，被视为类增量学习的性能上限。

Conclusion: AnaCP为类增量学习提供了一种高效的解决方案，实现了特征表示的自适应优化，同时避免了灾难性遗忘。

Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.

</details>


### [84] [The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks](https://arxiv.org/abs/2511.13952)
*Michał Iwaniuk,Mateusz Jarosz,Bartłomiej Borycki,Bartosz Jezierski,Jan Cwalina,Stanisław Kaźmierczak,Jacek Mańdziuk*

Main category: cs.LG

TL;DR: 研究评估了Bootstrap Rate (BR)对随机森林(RF)性能的影响，发现调优BR可以显著提升模型表现，BR的最佳选择与数据集特性相关。


<details>
  <summary>Details</summary>
Motivation: 探索BR对RF性能的影响，验证其是否可以通过调优提升模型表现。

Method: 在39个异质回归数据集和16种RF配置中，通过重复双折交叉验证和均方误差评估BR（0.2到5.0）的影响。

Result: 调优BR对性能提升显著：BR≤1.0适用于24个数据集，BR>1.0适用于15个，BR=1.0仅在4个中表现最佳。数据集特性与BR偏好相关。

Conclusion: BR是一个重要超参数，需通过调优优化RF回归模型。

Abstract: Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.

</details>


### [85] [Data Whitening Improves Sparse Autoencoder Learning](https://arxiv.org/abs/2511.13981)
*Ashwin Saraswatula,David Klindt*

Main category: cs.LG

TL;DR: 论文探讨了如何通过PCA白化技术提升稀疏自编码器（SAE）的性能和可解释性，研究表明白化能优化训练过程，提高特征可解释性。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在提取可解释特征方面有潜力，但由于输入数据的相关性，其优化过程具有挑战性。白化作为一种预处理技术可能改善这一问题。

Method: 研究通过理论分析和模拟，将PCA白化应用于输入激活，并评估了ReLU和Top-K稀疏自编码器在不同模型架构、宽度和稀疏度下的表现。

Result: 在SAEBench上的实验表明，白化显著提升了可解释性指标（如稀疏探测精度和特征解缠），尽管重建质量略有下降。

Conclusion: 研究结果表明，白化应作为稀疏自编码器训练的默认预处理步骤，尤其是在优先考虑可解释性而非完美重建时。

Abstract: Sparse autoencoders (SAEs) have emerged as a promising approach for learning interpretable features from neural network activations. However, the optimization landscape for SAE training can be challenging due to correlations in the input data. We demonstrate that applying PCA Whitening to input activations -- a standard preprocessing technique in classical sparse coding -- improves SAE performance across multiple metrics. Through theoretical analysis and simulation, we show that whitening transforms the optimization landscape, making it more convex and easier to navigate. We evaluate both ReLU and Top-K SAEs across diverse model architectures, widths, and sparsity regimes. Empirical evaluation on SAEBench, a comprehensive benchmark for sparse autoencoders, reveals that whitening consistently improves interpretability metrics, including sparse probing accuracy and feature disentanglement, despite minor drops in reconstruction quality. Our results challenge the assumption that interpretability aligns with an optimal sparsity--fidelity trade-off and suggest that whitening should be considered as a default preprocessing step for SAE training, particularly when interpretability is prioritized over perfect reconstruction.

</details>


### [86] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://arxiv.org/abs/2511.13984)
*Hilaf Hasson,Ruocheng Guo*

Main category: cs.LG

TL;DR: 提出了一种通过分析SQL抽象语法树（AST）节点级不确定性来检测LLM生成SQL错误的框架，结合语义感知标签和丰富特征分类器，显著提升错误检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如标记级log概率）在检测LLM生成SQL错误时缺乏细粒度解释性，需一种能精准定位AST节点错误并支持后续修复的方法。

Method: 1. 语义感知标签算法为AST节点分配正确性；2. 基于模式感知和词汇特征训练监督分类器预测节点错误概率。

Result: 在多个数据库和数据集上，方法优于标记级log概率（AUC提升27.44%），并能支持跨数据库评估。

Conclusion: 节点级不确定性估计是序列级置信度测量的强可解释替代方案，适用于针对性修复、人机协同审查和选择性执行。

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.

</details>


### [87] [Certified but Fooled! Breaking Certified Defences with Ghost Certificates](https://arxiv.org/abs/2511.14003)
*Quoc Viet Vo,Tashreque M. Haq,Paul Montague,Tamas Abraham,Ehsan Abbasnejad,Damith C. Ranasinghe*

Main category: cs.LG

TL;DR: 论文研究了如何通过小且不易察觉的扰动绕过概率认证框架的防御机制，从而生成欺骗性的稳健性证明，揭示了当前认证方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用概率认证框架的漏洞，通过微小扰动同时实现错误分类和欺骗性认证，以评估稳健性认证方法的实际限制。

Method: 提出了一种区域聚焦的对抗样本生成方法，通过精心设计的小扰动，绕过Densepure等先进认证防御机制。

Result: 实验表明，该方法能够成功生成欺骗性认证，并获得比源类更大的认证半径，验证了其有效性。

Conclusion: 研究强调了深入理解稳健性认证方法的局限性，并为其改进提供了重要参考。

Abstract: Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.

</details>


### [88] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 本文提出了一种名为Radial Compensation（RC）的信息几何方法，用于解决生成模型中曲率与参数纠缠的问题，通过选择切空间中的基密度，使得似然仅依赖于极点的测地距离。


<details>
  <summary>Details</summary>
Motivation: 生成模型在弯曲空间上依赖图表映射欧几里得空间到流形时，曲率与模型参数耦合会导致梯度方差膨胀，影响模型性能。

Method: 引入RC方法，通过调整基密度，使似然仅与测地距离相关，并提出Balanced-Exponential（bExp）图表族，平衡体积失真和测地误差。

Result: 实验表明，RC在生成模型、VAE、流模型等任务中表现稳定，显著提高了似然值，并避免了高维流中的半径爆炸问题。

Conclusion: RC-bExp是一种稳健的默认方法，适用于流形上的似然训练的生成模型。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [89] [A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation](https://arxiv.org/abs/2511.14057)
*Xianghe Liu,Jiajia Liu,Chuxian Xu,Minghan Wang,Hongbo Peng,Tao Sun,Jiaqi Xu*

Main category: cs.LG

TL;DR: 论文提出了一种基于机器学习的多模态框架，集成可穿戴传感器数据，用于同步动作识别和压力估计，旨在提高精确运动如射箭中运动员的表现分析。


<details>
  <summary>Details</summary>
Motivation: 传统运动分析系统昂贵且侵入性强，限制了在自然训练环境中的应用，因此需要一种非侵入、低成本的方法来综合评估运动员的生物力学稳定性和心理韧性。

Method: 开发了一种腕戴设备，集成加速度计和光电容积图(PPG)传感器，采集射箭训练中的同步运动和生理数据；采用Smoothed Differential Acceleration特征和LSTM模型进行动作识别，利用HRV特征和MLP分类器进行压力等级分类。

Result: 动作识别准确率达96.8%，F1分数95.9%；压力等级分类准确率达80%，验证了多模态传感框架的有效性。

Conclusion: 该框架为精确运动中的实时智能反馈系统奠定了基础，可用于优化训练。

Abstract: In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.

</details>


### [90] [CafeMed: Causal Attention Fusion Enhanced Medication Recommendation](https://arxiv.org/abs/2511.14064)
*Kelin Ren,Chan-Yang Ju,Dong-Ho Lee*

Main category: cs.LG

TL;DR: 论文提出CafeMed框架，通过动态因果推理和跨模态注意力提升药物推荐系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略医学实体的协同效应和动态因果关系，CafeMed旨在解决这些问题。

Method: 结合Causal Weight Generator（动态因果权重）和Channel Harmonized Attention Refinement Module（跨模态注意力）。

Result: 在MIMIC-III和MIMIC-IV数据集上表现优于现有方法，推荐准确且安全性更高。

Conclusion: 动态因果关系和跨模态协同可提升药物推荐的个性化和临床一致性。

Abstract: Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.

</details>


### [91] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: 论文提出CFG-EC方法，通过修正无条件噪声预测，优化Classifier-Free Guidance（CFG）的训练与采样一致性，提高生成图像的质量和提示对齐度。


<details>
  <summary>Details</summary>
Motivation: CFG在训练和采样过程中存在噪声估计不一致的问题，影响了生成质量。

Method: 提出CFG-EC方法，通过主动调整无条件噪声误差分量与条件误差分量正交，避免干扰并约束采样误差上限。

Result: 实验表明CFG-EC在低引导采样区间表现优于CFG和CFG++，提示对齐性更一致。

Conclusion: CFG-EC能有效提升生成模型的高保真度和提示对齐性，是一种通用且高效的修正方案。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [92] [Observational Auditing of Label Privacy](https://arxiv.org/abs/2511.14084)
*Iden Kalemaj,Luca Melis,Maxime Boucher,Ilya Mironov,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 提出了一种新的差分隐私审计框架，无需修改原始数据集即可评估隐私保证，适用于大规模系统。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私审计方法需修改训练数据集，资源消耗大且工程开销高，急需一种更高效的方法。

Method: 利用数据分布的固有随机性，提出了一种观察性审计框架，避免对原始数据集进行干预。

Result: 在Criteo和CIFAR-10数据集上的实验验证了该方法在审计标签隐私保证方面的有效性。

Conclusion: 为大规模生产环境中的隐私审计开辟了新途径，弥补了现有技术的不足。

Abstract: Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.

</details>


### [93] [MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts](https://arxiv.org/abs/2511.14102)
*Wenfeng Wang,Jiacheng Liu,Xiaofeng Hou,Xinfeng Xia,Peng Tang,Mingxuan Zhang,Chao Li,Minyi Guo*

Main category: cs.LG

TL;DR: 提出了MoE-SpeQ，一种基于推测执行和专家卸载协同设计的新推理系统，通过少量廉价设备计算隐藏数据传输成本，实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决专家混合模型在推理时因显存不足导致的I/O瓶颈问题。

Method: 利用小规模设备草稿模型预测未来令牌所需的专家序列，预取专家以重叠I/O与计算。

Result: 在内存受限设备上，MoE-SpeQ对Phi-MoE模型的推理速度提升最高达2.34倍。

Conclusion: MoE-SpeQ为资源受限环境下的数据依赖性内存访问管理提供了新方法。

Abstract: The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.
  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.

</details>


### [94] [Soft-Label Training Preserves Epistemic Uncertainty](https://arxiv.org/abs/2511.14117)
*Agamdeep Singh,Ashish Tiwari,Hosein Hasanbeig,Priyanshu Gupta*

Main category: cs.LG

TL;DR: 论文主张将标注分布而非单一标签视为真实情况，以避免模型在模糊数据上表现出虚假的确定性。软标签训练能更好地保留认知不确定性，并在多项任务中表现优于硬标签训练。


<details>
  <summary>Details</summary>
Motivation: 传统方法将多样化的标注合并为单一标签，导致模型在模糊数据上表现过于自信。作者认为标注分布本身应被视为真实情况，以更准确地反映人类感知的多样性。

Method: 采用软标签训练方法，将标注分布作为真实标签，而非传统硬标签训练中的单一标签。

Result: 软标签训练在视觉和NLP任务中表现出色，KL散度降低了32%，熵相关性提高了61%，同时保持了与硬标签训练相同的准确率。

Conclusion: 标注分布应被视为认知不确定性的真实表示，而非需要去除的噪声信号，软标签训练能更准确地反映人类感知的多样性。

Abstract: Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.

</details>


### [95] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: Synthetic Survival Control (SSC) 是一种解决观察数据中时间到事件结果的因果效应估计的新方法，通过加权组合其他单元的观察轨迹来估计反事实风险轨迹。


<details>
  <summary>Details</summary>
Motivation: 由于观察数据中存在截尾、样本量有限和非随机治疗分配等问题，估计时间到事件结果的因果效应具有挑战性。SSC 旨在解决这些挑战，特别是在异质性治疗采用和混杂因素的实际场景中。

Method: SSC利用面板数据的低秩结构框架，将反事实风险轨迹估计为其他单元观察轨迹的加权组合。该方法结合经典参数生存模型，提供识别和有限样本保证。

Result: 在多国癌症治疗结果的临床数据集中验证，发现新治疗方法与生存率提高相关，表现为干预后风险轨迹降低。

Conclusion: SSC为观察数据中的反事实生存推断提供了一个通用且可解释的工具，适用于医学、经济学和公共政策等领域。

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [96] [Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation](https://arxiv.org/abs/2511.14135)
*Promise Ekpo,Saesha Agarwal,Felix Grimm,Lekan Molu,Angelique Taylor*

Main category: cs.LG

TL;DR: 论文提出了一种名为Fair-GNE的方法，通过在多智能体强化学习（MARL）中引入广义纳什均衡（GNE）框架，确保医疗工作者在需求端资源分配中的公平工作负载分配，同时保持任务成功率高。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL方法通过事后协调奖励来引导公平，但缺乏运行时不可变的、可自我执行的公平性保证。在医疗资源分配场景中，这一问题尤为关键。

Method: Fair-GNE将MARL建模为一个约束广义纳什均衡寻求（GNE）游戏，确保群组策略达到安全且局部有效的均衡，避免单个智能体通过单方面改变决策来提升自身效用。

Result: 实验表明，Fair-GNE在工作负载平衡上显著优于固定惩罚基线（0.89 vs. 0.33 JFI，p < 0.01），同时保持了86%的任务成功率。

Conclusion: Fair-GNE为大规模多智能体学习医疗系统提供了清晰的公平性增强框架，并通过自适应约束实现了统计显著的公平性提升。

Abstract: Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\ 0.33 JFI, $p < 0.01$) while maintaining 86\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.

</details>


### [97] [A Comprehensive Study of Implicit and Explicit Biases in Large Language Models](https://arxiv.org/abs/2511.14153)
*Fatima Kazi,Alex Young,Yash Inani,Setareh Rafatirad*

Main category: cs.LG

TL;DR: 研究表明，大语言模型（LLMs）存在显性和隐性偏见，需通过自动偏见识别框架和改进策略解决，增强后模型性能提升20%。


<details>
  <summary>Details</summary>
Motivation: 识别和减轻LLMs中的偏见至关重要，以防止其传播有害刻板印象和错误信息。

Method: 使用偏见特定基准（如StereoSet和CrowSPairs）评估多生成模型，提出自动偏见识别框架，采用双重方法检测显性和隐性偏见，并通过微调和数据增强改进模型。

Result: 微调模型在性别偏见上表现不佳，但在种族偏见上表现良好；改进策略显著提升隐性偏见检测性能，性能提升达20%。

Conclusion: 尽管LLMs在偏见检测上取得一定成效，仍需进一步优化以减少对关键词的过度依赖，并增强模型适应性。

Abstract: Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [98] [Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts](https://arxiv.org/abs/2511.14218)
*Xinlei Xiong,Wenbo Hu,Shuxun Zhou,Kaifeng Bi,Lingxi Xie,Ying Liu,Richang Hong,Qi Tian*

Main category: cs.LG

TL;DR: 提出了一种结合贝叶斯深度学习和传统集合预报的统一框架，用于天气预报中的不确定性量化，并验证其效果。


<details>
  <summary>Details</summary>
Motivation: 传统集合预报计算成本高，而贝叶斯深度学习虽然高效但缺乏理论支持；本文旨在通过统一框架弥补两者差距。

Method: 通过变分推理和物理信息随机扰动方案分解预测不确定性，建立理论框架连接贝叶斯深度学习和集合预报。

Result: 在ERA5数据集上验证，方法提高了预报精度和不确定性校准，并具有更高的计算效率。

Conclusion: 提出的混合框架为天气预报中的不确定性量化提供了高效且理论支持的新方法。

Abstract: Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25° spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.

</details>


### [99] [EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229)
*Jim Broadbent,Felix Cohen,Frederik Hvilshøj,Eric Landau,Eren Sasoglu*

Main category: cs.LG

TL;DR: EBind是一种简单、以数据为中心且参数高效的方法，用于绑定多模态对比模型的嵌入空间，通过在单GPU上几小时内训练出高质量模型。


<details>
  <summary>Details</summary>
Motivation: 简化多模态空间绑定，通过高质量数据和高效方法实现高性能模型训练。

Method: 使用1.8B参数的图像-文本-视频-音频-3D模型，结合三种互补数据源：自动化多模态数据、人工标注数据和已有标注数据。

Result: 模型性能超越规模大4至17倍的模型，并通过13种评估验证数据源的价值。

Conclusion: EBind高效且性能优越，计划开源代码、模型权重和数据集。

Abstract: We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.

</details>


### [100] [Algebraformer: A Neural Approach to Linear Systems](https://arxiv.org/abs/2511.14263)
*Pietro Sittoni,Francesco Tudisco*

Main category: cs.LG

TL;DR: 论文提出了一种基于Transformer的架构Algebraformer，用于端到端学习解决线性系统，特别是在病态严重的情况下，展示了在传统科学计算管道中降低复杂性的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的数值方法在解决病态线性系统时通常需要仔细的参数调整、预处理或领域专业知识，研究人员希望探索通过深度学习模型解决此类问题的可能性。

Method: 提出了Algebraformer，一种基于Transformer的架构，利用新颖的编码方案高效表示矩阵和向量输入，内存复杂度为O(n²)，支持可扩展推理。

Result: 在应用驱动的线性问题上展示了其有效性，包括边界值问题的谱方法插值任务和牛顿法的加速，实现了竞争性精度且显著降低了测试时的计算开销。

Conclusion: 研究表明，通用神经架构可以有效降低传统科学计算管道的复杂性，为解决病态线性系统提供了一种高效的新方法。

Abstract: Recent work in deep learning has opened new possibilities for solving classical algorithmic tasks using end-to-end learned models. In this work, we investigate the fundamental task of solving linear systems, particularly those that are ill-conditioned. Existing numerical methods for ill-conditioned systems often require careful parameter tuning, preconditioning, or domain-specific expertise to ensure accuracy and stability. In this work, we propose Algebraformer, a Transformer-based architecture that learns to solve linear systems end-to-end, even in the presence of severe ill-conditioning. Our model leverages a novel encoding scheme that enables efficient representation of matrix and vector inputs, with a memory complexity of $O(n^2)$, supporting scalable inference. We demonstrate its effectiveness on application-driven linear problems, including interpolation tasks from spectral methods for boundary value problems and acceleration of the Newton method. Algebraformer achieves competitive accuracy with significantly lower computational overhead at test time, demonstrating that general-purpose neural architectures can effectively reduce complexity in traditional scientific computing pipelines.

</details>


### [101] [Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention](https://arxiv.org/abs/2511.14265)
*Rui Zhang,Chao Li,Kezhong Liu,Chen Wang,Bolong Zheng,Hongbo Jiang*

Main category: cs.LG

TL;DR: 论文提出了一种结合可解释导航意图的统一多模态轨迹预测框架，解决了现有方法的场景适用性和可解释性不足问题，实验证明其在不同场景下性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有的船舶多模态轨迹预测方法在复杂海洋环境中的场景适用性和可解释性不足，亟需改进。

Method: 将导航意图分为持续性和瞬时性两类，从历史轨迹构建持续性意图树，用条件变分自编码器（CVAE）建模瞬时意图，并利用非局部注意力机制保持全局场景一致性。

Result: 在真实AIS数据集上的实验表明，该方法在多种场景中具有广泛适用性，ADE和FDE均有显著提升，同时通过明确揭示导航意图提高了可解释性。

Conclusion: 提出的框架在船舶多模态轨迹预测中表现出优越性能和可解释性，为智能海事系统提供了有效工具。

Abstract: Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.

</details>


### [102] [Comparing Task-Agnostic Embedding Models for Tabular Data](https://arxiv.org/abs/2511.14276)
*Frederik Hoppe,Lars Kleinemeier,Astrid Franz,Udo Göbel*

Main category: cs.LG

TL;DR: 该论文探讨了表格数据的基础模型在表示学习上的表现，发现简单的特征工程方法在性能和速度上优于复杂的表格基础模型。


<details>
  <summary>Details</summary>
Motivation: 研究聚焦于可迁移、任务无关的表示学习，比较了表格基础模型与传统特征工程方法在不同任务中的表现。

Method: 系统地评估了TabPFN、TabICL等表格基础模型与TableVectorizer传统方法在异常检测和监督学习任务中的表现。

Result: TableVectorizer特征在性能相当或更优的同时，速度比表格基础模型快三个数量级。

Conclusion: 传统特征工程方法在表格数据表示学习中具有显著优势，尤其是在效率和性能方面。

Abstract: Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifically focuses on representation learning, i.e., on transferable, task-agnostic embeddings. We systematically evaluate task-agnostic representations from tabular foundation models (TabPFN and TabICL) alongside with classical feature engineering (TableVectorizer) across a variety of application tasks as outlier detection (ADBench) and supervised learning (TabArena Lite). We find that simple TableVectorizer features achieve comparable or superior performance while being up to three orders of magnitude faster than tabular foundation models. The code is available at https://github.com/ContactSoftwareAI/TabEmbedBench.

</details>


### [103] [H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata](https://arxiv.org/abs/2511.14312)
*Chenyang Xu,Siming Li,Hao Wang*

Main category: cs.LG

TL;DR: H-LDM是一种生成临床准确且可控的心音图信号的分层潜在扩散模型，通过结构化元数据生成数据，解决了标记病理数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 心音图分析对心血管疾病诊断至关重要，但标记病理数据的稀缺性限制了AI系统的能力。H-LDM旨在通过生成可控的心音图信号解决这一问题。

Method: 方法包括多尺度变分自编码器（VAE）学习生理解耦的潜在空间、分层文本到生物信号管道利用临床元数据实现精细控制，以及由医学注意力模块指导的可解释扩散过程。

Result: 在PhysioNet CirCor数据集上，H-LDM实现了9.7的Fréchet音频距离、92%的属性解耦分数和87.1%的临床有效性。合成数据将罕见疾病分类准确率提高了11.3%。

Conclusion: H-LDM为心脏诊断中的数据增强提供了新方向，通过可解释的临床见解弥合数据稀缺问题。

Abstract: Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fréchet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.

</details>


### [104] [Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect](https://arxiv.org/abs/2511.14317)
*Yuwen Zhang,Viet Tran,Paul Weng*

Main category: cs.LG

TL;DR: 本文针对临床机器学习中由于Rashomon效应（多模型性能相近）带来的部署和评估挑战，提出了两种互补工具：干预效率（IE）和扰动验证框架（PVF），以增强模型的稳健性和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 临床机器学习中，多模型性能相近的问题（Rashomon效应）结合小、不平衡、噪声数据集和高维弱标识特征，使得传统验证方法不可靠。需要在资源限制和临床优先级的背景下选择模型。

Method: 提出了两种工具：干预效率（IE），一种量化模型在有限干预下识别可操作真阳性效率的指标；以及扰动验证框架（PVF），用于评估模型在数据扰动下的稳定性。

Result: 在合成和真实医疗数据集上的实验表明，使用这两种工具可以筛选出更具稳健性且符合资源限制的模型。

Conclusion: IE和PVF为解决临床场景中的Rashomon效应提供了新方向，提升了模型的可信度和实用性。

Abstract: In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.

</details>


### [105] [Learning with Statistical Equality Constraints](https://arxiv.org/abs/2511.14320)
*Aneesh Barthakur,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 论文提出了一种针对涉及等式约束的统计学习问题的泛化理论，并基于此设计了一种实用算法，避免了传统加权方法中需要调整超参数的问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习在处理多需求问题时通常采用加权惩罚方法，但这种方法需要大量超参数调整，且在涉及公平性和边界值问题的等式约束时效率低下。

Method: 作者通过推导等式约束统计学习的泛化理论，提出了一种基于一系列无约束经验学习问题的实用算法。

Result: 该算法在公平学习、插值分类器和边界值问题中表现出高效性，并支持新的等式约束问题表述。

Conclusion: 研究提供了一种有效解决等式约束学习问题的方法，为机器学习的多需求优化提供了新思路。

Abstract: As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.

</details>


### [106] [Enforcing hidden physics in physics-informed neural networks](https://arxiv.org/abs/2511.14348)
*Nanxi Chen,Sifan Wang,Rujin Ma,Airong Chen,Chuanjie Cui*

Main category: cs.LG

TL;DR: PINNs中引入不可逆性正则化策略，解决传统训练中忽略热力学第二定律的问题，显著降低预测误差。


<details>
  <summary>Details</summary>
Motivation: 传统PINNs在训练中常忽略热力学第二定律隐含的不可逆性，导致非物理解或训练失败，需一种新方法填补这一关键空白。

Method: 提出一种简单、通用且稳健的不可逆性正则化策略，将不可逆物理法则作为软约束融入训练过程。

Result: 在多项基准测试中，该方法将预测误差降低超过一个数量级，且对现有PINN框架改动极小。

Conclusion: 该框架适用于广泛PDE主导的物理系统，对科学机器学习领域具有重要影响。

Abstract: Physics-informed neural networks (PINNs) represent a new paradigm for solving partial differential equations (PDEs) by integrating physical laws into the learning process of neural networks. However, despite their foundational role, the hidden irreversibility implied by the Second Law of Thermodynamics is often neglected during training, leading to unphysical solutions or even training failures in conventional PINNs. In this paper, we identify this critical gap and introduce a simple, generalized, yet robust irreversibility-regularized strategy that enforces hidden physical laws as soft constraints during training. This approach ensures that the learned solutions consistently respect the intrinsic one-way nature of irreversible physical processes. Across a wide range of benchmarks spanning traveling wave propagation, steady combustion, ice melting, corrosion evolution, and crack propagation, we demonstrate that our regularization scheme reduces predictive errors by more than an order of magnitude, while requiring only minimal modification to existing PINN frameworks. We believe that the proposed framework is broadly applicable to a wide class of PDE-governed physical systems and will have significant impact within the scientific machine learning community.

</details>


### [107] [Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406)
*Bastien Vuillod,Pierre-Alain Moellic,Jean-Max Dutertre*

Main category: cs.LG

TL;DR: 论文研究了联邦学习中通过LoRA技术进行高效微调时的后门攻击影响，发现攻击后后门的持久性与LoRA的秩相关，并提出了更健壮的后门攻击评估方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的后门攻击威胁日益严重，尤其是在使用LoRA等参数高效微调技术时。论文旨在分析LoRA对后门攻击效果的影响，并提出更可靠的评估方法。

Method: 通过实验分析了LoRA不同秩对后门攻击持久性的影响，并对比了不同攻击场景下的后门寿命。

Result: 实验结果表明，当LoRA的秩较低时，后门攻击的持久性更长。同时论文揭示了当前后门攻击评估中的问题。

Conclusion: 论文工作有助于提升联邦学习系统的风险评估可靠性，并为后门攻击的公平评估提供了新视角。

Abstract: Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.

</details>


### [108] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 论文提出了一种针对跨模态检索中查询偏移问题的在线自适应方法REST，通过优化检索结果和设计梯度解耦模块，有效解决了在线偏移和多样性偏移的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有通用到定制化的跨模态检索方法假设目标域数据完全可用，而实际场景中查询以在线方式到达且多样化，导致查询偏移问题（在线偏移和多样性偏移），影响模型性能。

Method: 提出的REST方法包括两部分：针对在线偏移，通过优化检索结果和设计鲁棒目标函数来保护公共空间；针对多样性偏移，采用梯度解耦模块防止模型遗忘通用知识。

Result: 在三个跨模态检索任务的20个基准测试上，REST方法验证了其对抗查询偏移的有效性。

Conclusion: REST方法能够在线、和谐地适应查询偏移，为跨模态检索中的实际应用提供了有效解决方案。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [109] [FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis](https://arxiv.org/abs/2511.14419)
*Xiaowei Xu,Justin Sonneck,Hongxiao Wang,Roman Burkard,Hendrik Wohrle,Anton Grabmasier,Matthias Gunzer,Jianxu Chen*

Main category: cs.LG

TL;DR: 文章介绍了FlowRoI，一种基于光流的高通量图像压缩框架，用于解决免疫细胞迁移研究中数据存储和传输的挑战。


<details>
  <summary>Details</summary>
Motivation: 高通量成像平台如ComplexEye生成数据量大，对存储和传输造成负担。开发高效压缩方法具有重要意义。

Method: FlowRoI通过光流估计提取ROI掩模，结合JPEG2000进行压缩，高效覆盖迁移细胞区域。

Result: FlowRoI在计算效率和图像质量上表现优异，压缩率比标准JPEG2000高2.0-2.2倍。

Conclusion: FlowRoI为高通量免疫细胞迁移研究提供了高效的数据压缩解决方案。

Abstract: Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.

</details>


### [110] [MiAD: Mirage Atom Diffusion for De Novo Crystal Generation](https://arxiv.org/abs/2511.14426)
*Andrey Okhotin,Maksim Nakhodnov,Nikita Kazeev,Andrey E Ustyuzhanin,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 本文介绍了Mirage Infusion技术，使扩散模型能够在晶体生成过程中动态改变原子数量，从而提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在生成晶体时无法动态改变原子数量，限制了采样的多样性。

Method: 提出Mirage Infusion技术，允许原子状态在存在与非存在之间切换。

Result: 改进后的模型（MiAD）性能提升2.5倍，S.U.N.率达到8.2%。

Conclusion: MiAD显著优于现有方法，为晶体生成提供了新途径。

Abstract: In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \href{https://github.com/andrey-okhotin/miad.git}{\texttt{github.com/andrey-okhotin/miad}}.

</details>


### [111] [Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters](https://arxiv.org/abs/2511.14452)
*Emanuele Palumbo,Sorawit Saengkyongam,Maria R. Cervera,Jens Behrmann,Andrew C. Miller,Guillermo Sapiro,Christina Heinze-Deml,Antoine Wehenkel*

Main category: cs.LG

TL;DR: 该论文提出了一种混合方法，利用血流动力学模拟和无标签临床数据，直接从PPG信号估计心血管生物标志物，解决了PPG信号预测关键心脏生物标志物的挑战。


<details>
  <summary>Details</summary>
Motivation: 持续心血管监测在精准健康中至关重要，但一些关键心脏生物标志物（如每搏输出量和心输出量）通常需要侵入性测量（如动脉压力波形）。作为非侵入性替代方案，光电容积描记（PPG）在医院环境中常规采集，但预测效果仍不理想。因此，论文提出了一种混合方法来解决这一问题。

Method: 采用混合模型，结合在成对PPG-APW数据上训练的条件变分自编码器，以及在模拟APW段上训练的条件密度估计器，直接从PPG信号估计心血管生物标志物。

Result: 实验表明，该方法能够检测心输出量和每搏输出量的波动，并在监测这些生物标志物的时间变化上优于有监督基线方法。

Conclusion: 该方法为通过PPG信号非侵入性预测心脏生物标志物提供了有效解决方案，具有临床应用潜力。

Abstract: Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.

</details>


### [112] [Nonparametric estimation of conditional probability distributions using a generative approach based on conditional push-forward neural networks](https://arxiv.org/abs/2511.14455)
*Nicola Rares Franco,Lorenzo Tedesco*

Main category: cs.LG

TL;DR: CPFN是一种基于随机映射的条件分布生成框架，通过蒙特卡洛方法高效采样并估计条件统计量。


<details>
  <summary>Details</summary>
Motivation: 传统方法在建模条件分布时存在复杂性高或训练困难的问题，CPFN旨在提供一种轻量且易于训练的高效解决方案。

Method: CPFN通过学习随机映射φ(x,u)来近似条件分布Y|X=x，采用Kullback-Leibler目标函数训练，无需可逆性假设或对抗训练。

Result: CPFN在性能上可与现有先进方法（如核估计、树算法和深度学习）竞争甚至超越，同时保持轻量和易训练。

Conclusion: CPFN为条件分布估计提供了一种高效且实用的新方法，适用于蒙特卡洛采样和统计量估计。

Abstract: We introduce conditional push-forward neural networks (CPFN), a generative framework for conditional distribution estimation. Instead of directly modeling the conditional density $f_{Y|X}$, CPFN learns a stochastic map $\varphi=\varphi(x,u)$ such that $\varphi(x,U)$ and $Y|X=x$ follow approximately the same law, with $U$ a suitable random vector of pre-defined latent variables. This enables efficient conditional sampling and straightforward estimation of conditional statistics through Monte Carlo methods. The model is trained via an objective function derived from a Kullback-Leibler formulation, without requiring invertibility or adversarial training. We establish a near-asymptotic consistency result and demonstrate experimentally that CPFN can achieve performance competitive with, or even superior to, state-of-the-art methods, including kernel estimators, tree-based algorithms, and popular deep learning techniques, all while remaining lightweight and easy to train.

</details>


### [113] [nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](https://arxiv.org/abs/2511.14465)
*Clément Dumas*

Main category: cs.LG

TL;DR: 介绍了一种名为nnterp的工具，用于统一分析不同架构的变压器模型，同时保留原始实现的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在分析变压器模型内部机制时遇到的接口不一致或行为不准确的问题。

Method: 开发了nnterp，一个基于NNsight的轻量级包装器，通过自动模块重命名和验证测试，提供统一的接口并支持多种模型架构。

Result: nnterp支持50多种模型变体和16种架构家族，内置常见可解释性方法，并能验证自定义模型的兼容性。

Conclusion: nnterp在保持正确性的同时提高了可用性，填补了机制可解释性工具中的空白。

Abstract: Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.

</details>


### [114] [Notes on Kernel Methods in Machine Learning](https://arxiv.org/abs/2511.14485)
*Diego Armando Pérez-Rosero,Danna Valentina Salazar-Dubois,Juan Camilo Lugo-Rojas,Andrés Marino Álvarez-Meza,Germán Castellanos-Dominguez*

Main category: cs.LG

TL;DR: 该论文提供了对核方法及其在机器学习中几何基础的自包含介绍，强调了它们在统计估计和概率测度表示中的作用。


<details>
  <summary>Details</summary>
Motivation: 旨在为核方法和其几何基础提供一个清晰的入门，为进一步学习高斯过程、核贝叶斯推断等高级主题奠定基础。

Method: 通过构建希尔伯特空间，发展了正定核、再生核希尔伯特空间（RKHS）和希尔伯特-施密特算子的理论，并重新审视了协方差、回归和信息度量等经典概念。

Result: 介绍了核密度估计、分布核嵌入和最大均值差异（MMD）等工具，为高级机器学习方法提供了理论基础。

Conclusion: 该论文为核方法及其应用提供了一个全面的基础，适用于进一步探索高斯过程和现代机器学习的功能分析方法。

Abstract: These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.

</details>


### [115] [Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching](https://arxiv.org/abs/2511.14488)
*Jintao Zhang,Mingyue Cheng,Zirui Liu,Xianquan Wang,Yitong Zhou,Qi Liu*

Main category: cs.LG

TL;DR: PAFM是一种针对时间序列生成的扰动感知流匹配框架，通过捕捉轨迹扰动下的行为改进结构一致性，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 时间序列生成在广泛应用中至关重要，但由于局部扰动导致的时序异质性，生成结构一致的时间序列具有挑战性。现有方法未能充分捕捉扰动时间序列的突变。

Method: 提出PAFM框架，结合扰动引导训练模拟局部干扰，并使用双路径速度场捕捉扰动下的轨迹偏差，通过专家混合解码器动态分配建模能力。

Result: 在无条件与条件生成任务中，PAFM显著优于基线方法。

Conclusion: PAFM通过扰动感知建模和动态容量分配，有效提升了时间序列生成的结构一致性和质量。

Abstract: Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \textbf{PAFM}, a \textbf{P}erturbation-\textbf{A}ware \textbf{F}low \textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.

</details>


### [116] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)
*Jiawei Yi,Ping Gong,Youhui Bai,Jiaqi Ruan,Shengnan Wang,Pengcheng Wang,Haibo Wang,Weiguang Wang,Xia Zhu,Feng Wu,Cheng Li*

Main category: cs.LG

TL;DR: 论文提出CLO系统，通过算法-系统协同设计，优化百万token规模LLMs推理中的KVCache问题，显著减少CPU开销并提升解码吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有系统在迁移KVCache到CPU内存时存在CPU瓶颈问题，包括动态缓存管理开销大、PCIe带宽利用率低、GPU运行时泡沫等问题。

Method: CLO采用粗粒度头部近似缓存策略，结合数据预取和GPU持久缓存，使用零拷贝传输引擎和GPU中心同步方法。

Result: 实验表明，CLO在保持高精度的同时，显著减少CPU开销，最大化带宽利用率，解码吞吐量提升9.3%-66.6%。

Conclusion: 算法-系统协同设计对现代GPU平台上的内存受限LLM推理至关重要。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.

</details>


### [117] [MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation](https://arxiv.org/abs/2511.14543)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: 为了解决混合类型表格数据中不完整数据的问题，作者提出了一种混合确定性扩散框架，将数值和分类特征分开处理，以提高填补精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格数据通常包含数值、分类和离散特征的混合，而现有的基于扩散的填补模型假设特征空间同质，难以保持条件一致性。

Method: 提出了一种混合确定性扩散框架，将数值和分类特征分开处理，分别采用连续的DDIM通道和离散潜在路径扩散通道进行填补。

Result: 在多个真实数据集上，该方法比现有方法表现出更高的填补精度、更稳定的采样轨迹，并在不同缺失机制下均具有鲁棒性。

Conclusion: 结构感知的扩散过程对于提升深度学习处理不完整表格数据的能力具有重要意义。

Abstract: Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.
  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.
  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.

</details>


### [118] [Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction](https://arxiv.org/abs/2511.14544)
*Jaume Ros,Alessio Arleo,Fernando Paulovich*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为 Warping Index (WI) 的新指标，用于衡量高维数据降维投影到 2D 平面的质量，重点关注对点之间空白区域的正确保留。


<details>
  <summary>Details</summary>
Motivation: 现有的降维投影质量指标主要关注数据的全局或局部结构，忽略了视觉上的扭曲和潜在的误导性异常或伪影，这对视觉分析可能产生不良影响。因此，需要一种新方法来量化投影对数据视觉表示的忠实度。

Method: 作者提出了 Warping Index (WI)，这是一种基于点之间空白区域保留程度的新指标，以评估降维投影的视觉质量。

Result: WI 能够有效识别投影中的视觉扭曲和异常，帮助用户更准确地评估降维结果的可信度。

Conclusion: WI 提供了一种更全面的投影质量评估方法，尤其关注视觉保真度，填补了现有指标的不足。

Abstract: Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.

</details>


### [119] [Task Addition and Weight Disentanglement in Closed-Vocabulary Models](https://arxiv.org/abs/2511.14569)
*Adam Hazimeh,Alessandro Favero,Pascal Frossard*

Main category: cs.LG

TL;DR: 研究探讨了任务算术在封闭词汇图像分类模型中的应用，发现权重解缠是预训练的普遍结果，扩展了任务算术的适用性。


<details>
  <summary>Details</summary>
Motivation: 探索任务算术在未经过语言监督预训练的封闭词汇模型中的应用，填补研究空白。

Method: 在不同预训练方案的封闭词汇模型中部署任务加法，分析权重解缠现象，并与线性探测基线对比。

Result: 封闭词汇视觉变换器可通过任务算术编辑，实现高效多任务模型部署，且线性探测表现与之相当。

Conclusion: 任务算术适用于更广泛的预训练模型，为高效利用预训练模型提供新途径。

Abstract: Task arithmetic has recently emerged as a promising method for editing pre-trained \textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.

</details>


### [120] [ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](https://arxiv.org/abs/2511.14584)
*Ankush Kadu,Ashwanth Krishnan*

Main category: cs.LG

TL;DR: ReflexGrad是一种新型架构，通过结合层级任务分解、历史感知因果反思和梯度优化，实现了在零样本情况下的任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习和决策制定中任务间泛化的挑战，探索多种方法的协同整合。

Method: 结合LLM层级分解、历史反思和梯度优化，无需任务特定训练。

Result: 在ALFWorld基准任务中实现67%的零样本成功率，并通过机制改进提升性能。

Conclusion: 互补机制的协同整合能实现接近少样本基准的零样本泛化能力。

Abstract: Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.

</details>


### [121] [Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare](https://arxiv.org/abs/2511.14619)
*Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella*

Main category: cs.LG

TL;DR: 提出了一种名为Fuzzy MAP EM的新算法，通过将专家知识融入EM框架的模糊伪计数，解决了数据有限条件下POMDP参数学习的难题。


<details>
  <summary>Details</summary>
Motivation: 在数据有限的环境中，学习POMDP参数具有挑战性，因此需要一种能够利用专家知识的方法来提升学习效果。

Method: 将专家定义的模糊模型生成的模糊伪计数引入EM框架，转化为MAP估计问题，从而指导有限数据环境下的学习。

Result: 在合成医学模拟中，该算法在数据少和高噪声条件下优于标准EM算法；在重症肌无力的案例中，能恢复临床一致的POMDP模型。

Conclusion: Fuzzy MAP EM算法是一种实用的数据高效建模工具，尤其在医疗领域展现了潜力。

Abstract: Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.

</details>


### [122] [Failure to Mix: Large language models struggle to answer according to desired probability distributions](https://arxiv.org/abs/2511.14630)
*Ivy Yuqian Yang,David Yu Zhang*

Main category: cs.LG

TL;DR: 当前大语言模型（LLMs）在遵循简单概率分布的生成任务中表现不佳，倾向于选择概率略高的输出。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在科学想法生成和选择中遵循目标概率分布的能力，发现当前AI基准测试未能体现这一需求。

Method: 通过系统实验，要求LLMs生成符合简单概率分布的输出，分析其表现。

Result: 所有测试的现代LLMs均严重偏离目标分布，例如在要求生成“1”的概率为49%时，几乎总是生成“0”。

Conclusion: 当前LLMs在概率探索任务中存在局限性，需进一步改进以支持科学创新。

Abstract: Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of "1" 49% of the time produces an answer of "0" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.

</details>


### [123] [Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.14632)
*Yuchen Luo,Xinyu Li,Liuhua Peng,Mingming Gong*

Main category: cs.LG

TL;DR: Adapformer提出了一种基于Transformer的自适应通道管理框架，结合了通道独立和通道依赖方法的优点，通过双阶段编码器-解码器架构提升多元时间序列预测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统多元时间序列预测方法（如通道独立或通道依赖策略）存在局限性，前者忽略通道间交互，后者可能引入过多噪声。Adapformer旨在解决这些问题。

Method: 采用双阶段编码器-解码器架构，包含自适应通道增强器（ACE）和自适应通道预测器（ACF），分别优化嵌入过程和预测结果。

Result: Adapformer在多种数据集上表现优于现有模型，提高了预测精度和计算效率。

Conclusion: Adapformer通过自适应通道管理，成为多元时间序列预测领域的新基准。

Abstract: In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \textbf{channel-independent} (CI) or \textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \textbf{A}daptive \textbf{C}hannel \textbf{E}nhancer (\textbf{ACE}) for enriching embedding processes and the \textbf{A}daptive \textbf{C}hannel \textbf{F}orecaster (\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.

</details>
