<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 24]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.LG](#cs.LG) [Total: 56]
- [eess.SY](#eess.SY) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems](https://arxiv.org/abs/2511.10704)
*Samih Fadli*

Main category: cs.AI

TL;DR: 论文提出了一种类似于热力学第二定律的‘第二定律’，用于描述无约束人工智能的伦理熵增长现象，并通过理论证明和仿真验证了持续对齐工作的必要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了量化无约束人工智能系统中伦理熵的自发增长问题，并将其转化为类似于热力学中的控制问题，从而为高级自主系统的稳定性和安全性提供理论基础。

Method: 方法包括定义伦理熵及其数学表达式，证明其随时间增长的规律，并通过仿真模拟验证理论。具体给出了临界稳定性边界的数学表达，并基于梯度优化器进行了实验验证。

Result: 结果显示，未经对齐工作的人工智能系统伦理熵显著增加，而通过适当的正则化（对齐工作）可以保持系统的稳定性。

Conclusion: 结论表明，人工智能对齐问题可以类比为持续的‘热力学控制’，为维护高级自主系统的稳定性和安全性提供了定量框架。

Abstract: We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -Σ p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.

</details>


### [2] [Picking a Representative Set of Solutions in Multiobjective Optimization: Axioms, Algorithms, and Experiments](https://arxiv.org/abs/2511.10716)
*Niclas Boehmer,Maximilian T. Wittmann*

Main category: cs.AI

TL;DR: 该论文研究了多目标决策中的帕累托剪枝问题，并提出了一种新质量度量方法——定向覆盖。


<details>
  <summary>Details</summary>
Motivation: 在多目标决策问题中，决策者需要从帕累托最优解集中选择最具代表性的子集，以减少认知负担。现有质量度量方法存在一些不直观行为，因此需要改进。

Method: 通过多赢家投票框架对现有质量度量进行公理分析，并提出定向覆盖作为新度量方法。同时，分析了不同质量度量的计算复杂度。

Result: 实验证明，质量度量的选择对解决方案集的特征有决定性影响，定向覆盖在多种设置下表现优越。

Conclusion: 定向覆盖是一种高效且高质量的帕累托剪枝度量方法，能够为多目标决策提供更优解决方案。

Abstract: Many real-world decision-making problems involve optimizing multiple objectives simultaneously, rendering the selection of the most preferred solution a non-trivial problem: All Pareto optimal solutions are viable candidates, and it is typically up to a decision maker to select one for implementation based on their subjective preferences. To reduce the cognitive load on the decision maker, previous work has introduced the Pareto pruning problem, where the goal is to compute a fixed-size subset of Pareto optimal solutions that best represent the full set, as evaluated by a given quality measure. Reframing Pareto pruning as a multiwinner voting problem, we conduct an axiomatic analysis of existing quality measures, uncovering several unintuitive behaviors. Motivated by these findings, we introduce a new measure, directed coverage. We also analyze the computational complexity of optimizing various quality measures, identifying previously unknown boundaries between tractable and intractable cases depending on the number and structure of the objectives. Finally, we present an experimental evaluation, demonstrating that the choice of quality measure has a decisive impact on the characteristics of the selected set of solutions and that our proposed measure performs competitively or even favorably across a range of settings.

</details>


### [3] [Structure-Aware Encodings of Argumentation Properties for Clique-width](https://arxiv.org/abs/2511.10767)
*Yasir Mahmood,Markus Hecher,Johanna Groven,Johannes K. Fichte*

Main category: cs.AI

TL;DR: 该论文研究了图的参数（如树宽和团宽）在计算复杂性中的应用，特别是通过紧凑编码到(Q)SAT中，并以抽象论证为例分析了团宽的编码能力。


<details>
  <summary>Details</summary>
Motivation: 现代SAT求解器在小树宽的实例上高效运行，但团宽作为更通用的图参数，其编码能力研究较少。论文旨在通过抽象论证框架探索团宽的编码潜力。

Method: 设计了从论证问题到(Q)SAT的新规约方法，称为有向分解引导（DDG）规约，这些规约线性保留了团宽。

Result: 为所有论证语义（包括计数）建立了新的结果，并证明DDG规约的开销在合理假设下无法显著改进。

Conclusion: 论文成功验证了利用团宽进行高效编码的潜力，并为未来研究提供了基础。

Abstract: Structural measures of graphs, such as treewidth, are central tools in computational complexity resulting in efficient algorithms when exploiting the parameter. It is even known that modern SAT solvers work efficiently on instances of small treewidth. Since these solvers are widely applied, research interests in compact encodings into (Q)SAT for solving and to understand encoding limitations. Even more general is the graph parameter clique-width, which unlike treewidth can be small for dense graphs. Although algorithms are available for clique-width, little is known about encodings. We initiate the quest to understand encoding capabilities with clique-width by considering abstract argumentation, which is a robust framework for reasoning with conflicting arguments. It is based on directed graphs and asks for computationally challenging properties, making it a natural candidate to study computational properties. We design novel reductions from argumentation problems to (Q)SAT. Our reductions linearly preserve the clique-width, resulting in directed decomposition-guided (DDG) reductions. We establish novel results for all argumentation semantics, including counting. Notably, the overhead caused by our DDG reductions cannot be significantly improved under reasonable assumptions.

</details>


### [4] [Potential Outcome Rankings for Counterfactual Decision Making](https://arxiv.org/abs/2511.10776)
*Yuta Kawakami,Jin Tian*

Main category: cs.AI

TL;DR: 论文探讨了在不确定性下基于因果推理的反事实决策，引入了两种新指标（PoR和PoB）以改进决策规则，并提供了理论支持和实证验证。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化决策者在面对不确定性时的反事实决策过程，通过量化潜在结果的排序概率和最优化概率来辅助选择最佳行动。

Method: 提出PoR和PoB两种新指标，建立其识别定理和边界条件，开发估计方法，并通过数值实验和真实数据验证其有效性。

Result: 理论分析证明了PoR和PoB的可行性，实证结果显示估计方法在小样本和实际应用中表现稳健。

Conclusion: 新指标为个体化反事实决策提供了实用工具，未来方向包括拓展指标的应用场景和改进估计方法。

Abstract: Counterfactual decision-making in the face of uncertainty involves selecting the optimal action from several alternatives using causal reasoning. Decision-makers often rank expected potential outcomes (or their corresponding utility and desirability) to compare the preferences of candidate actions. In this paper, we study new counterfactual decision-making rules by introducing two new metrics: the probabilities of potential outcome ranking (PoR) and the probability of achieving the best potential outcome (PoB). PoR reveals the most probable ranking of potential outcomes for an individual, and PoB indicates the action most likely to yield the top-ranked outcome for an individual. We then establish identification theorems and derive bounds for these metrics, and present estimation methods. Finally, we perform numerical experiments to illustrate the finite-sample properties of the estimators and demonstrate their application to a real-world dataset.

</details>


### [5] [From Efficiency to Adaptivity: A Deeper Look at Adaptive Reasoning in Large Language Models](https://arxiv.org/abs/2511.10788)
*Chao Wu,Baoheng Li,Mingchen Gao,Zhenyi Wang*

Main category: cs.AI

TL;DR: 该论文通过“适应性”视角重新审视大语言模型的推理能力，提出了一个系统分类法，将现有方法分为基于训练和无训练方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在推理时采用统一的策略，忽视了任务复杂性差异，导致资源浪费或失败。论文旨在通过适应性推理解决这一问题。

Method: 论文首先形式化了三类推理范式（演绎、归纳、溯因）及其算法实现，其次是提出了适应性推理的控制增强策略优化问题，并提出了分类法对现有方法进行系统整理。

Result: 提出了一个框架，明确了实践中实现适应性推理的不同机制，实现了对不同策略的系统比较。

Conclusion: 论文总结了适应性推理的关键贡献，并指出了自我评估、元推理和与人类对齐的推理控制等未来挑战。

Abstract: Recent advances in large language models (LLMs) have made reasoning a central benchmark for evaluating intelligence. While prior surveys focus on efficiency by examining how to shorten reasoning chains or reduce computation, this view overlooks a fundamental challenge: current LLMs apply uniform reasoning strategies regardless of task complexity, generating long traces for trivial problems while failing to extend reasoning for difficult tasks. This survey reframes reasoning through the lens of {adaptivity}: the capability to allocate reasoning effort based on input characteristics such as difficulty and uncertainty. We make three contributions. First, we formalize deductive, inductive, and abductive reasoning within the LLM context, connecting these classical cognitive paradigms with their algorithmic realizations. Second, we formalize adaptive reasoning as a control-augmented policy optimization problem balancing task performance with computational cost, distinguishing learned policies from inference-time control mechanisms. Third, we propose a systematic taxonomy organizing existing methods into training-based approaches that internalize adaptivity through reinforcement learning, supervised fine-tuning, and learned controllers, and training-free approaches that achieve adaptivity through prompt conditioning, feedback-driven halting, and modular composition. This framework clarifies how different mechanisms realize adaptive reasoning in practice and enables systematic comparison across diverse strategies. We conclude by identifying open challenges in self-evaluation, meta-reasoning, and human-aligned reasoning control.

</details>


### [6] [HyperComplEx: Adaptive Multi-Space Knowledge Graph Embeddings](https://arxiv.org/abs/2511.10842)
*Jugal Gajjar,Kaustik Ranaware,Kamalasankari Subramaniakuppusamy,Vaibhav Gandhi*

Main category: cs.AI

TL;DR: HyperComplEx是一个混合嵌入框架，通过动态选择最佳几何空间来改进知识图谱嵌入方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法在建模多样关系类型时存在局限性，需要一种适应性更强的方法。

Method: 提出HyperComplEx框架，结合双曲、复杂和欧几里得空间，通过注意力机制动态选择最优几何空间。

Result: 在多个数据集上显著优于现有基线方法，特别是在10M论文数据集上达到0.612 MRR，性能提升4.8%。

Conclusion: HyperComplEx是一个高效且可扩展的知识图谱嵌入框架，适用于大规模复杂关系建模。

Abstract: Knowledge graphs have emerged as fundamental structures for representing complex relational data across scientific and enterprise domains. However, existing embedding methods face critical limitations when modeling diverse relationship types at scale: Euclidean models struggle with hierarchies, vector space models cannot capture asymmetry, and hyperbolic models fail on symmetric relations. We propose HyperComplEx, a hybrid embedding framework that adaptively combines hyperbolic, complex, and Euclidean spaces via learned attention mechanisms. A relation-specific space weighting strategy dynamically selects optimal geometries for each relation type, while a multi-space consistency loss ensures coherent predictions across spaces. We evaluate HyperComplEx on computer science research knowledge graphs ranging from 1K papers (~25K triples) to 10M papers (~45M triples), demonstrating consistent improvements over state-of-the-art baselines including TransE, RotatE, DistMult, ComplEx, SEPA, and UltraE. Additional tests on standard benchmarks confirm significantly higher results than all baselines. On the 10M-paper dataset, HyperComplEx achieves 0.612 MRR, a 4.8% relative gain over the best baseline, while maintaining efficient training, achieving 85 ms inference per triple. The model scales near-linearly with graph size through adaptive dimension allocation. We release our implementation and dataset family to facilitate reproducible research in scalable knowledge graph embeddings.

</details>


### [7] [Advanced Tool for Traffic Crash Analysis: An AI-Driven Multi-Agent Approach to Pre-Crash Reconstruction](https://arxiv.org/abs/2511.10853)
*Gerui Xu,Boyou Chen,Huizhong Guo,Dave LeBlanc,Ananna Ahmed,Zhaonan Sun,Shan Bao*

Main category: cs.AI

TL;DR: 论文开发了一个多智能体AI框架，用于从碎片化的碰撞数据中重建碰撞前场景和推断车辆行为。该框架结合了重建和推理两阶段，通过处理多种数据形式（文本报告、表格数据、视觉图表）和模糊的EDR记录，实现了高精度的碰撞分析和推理，准确度超越人工。


<details>
  <summary>Details</summary>
Motivation: 传统的交通事故重建依赖人工专家，对不完整或异构数据的分析结果往往不一致。为提高分析的一致性和准确性，研究开发了多智能体AI框架，以克服数据碎片化和模糊性的挑战。

Method: 研究采用两阶段协作框架：第一阶段从多模态输入生成自然语言的重建报告；第二阶段结合时间性事件数据记录器（EDR）进行深度推理。实验基于277起后端碰撞数据和39起复杂案例，验证了框架的性能。

Result: 在39起复杂案例中，框架表现完美，准确识别了相关EDR事件并区分了撞击与被撞击车辆，准确度达到100%，超过了人工研究人员92%的准确度。即使数据不完整或有误，系统仍保持稳健。

Conclusion: 该研究证明了AI在异构碰撞数据处理中的优越能力，提供了前所未有的精确性和鲁棒性，为事故重建和行为分析开辟了新途径。

Abstract: Traffic collision reconstruction traditionally relies on human expertise, often yielding inconsistent results when analyzing incomplete multimodal data. This study develops a multi-agent AI framework that reconstructs pre-crash scenarios and infers vehicle behaviors from fragmented collision data. We present a two-phase collaborative framework combining reconstruction and reasoning phases. The system processes 277 rear-end lead vehicle deceleration (LVD) collisions from the Crash Investigation Sampling System, integrating textual crash reports, structured tabular data, and visual scene diagrams. Phase I generates natural-language crash reconstructions from multimodal inputs. Phase II performs in-depth crash reasoning by combining these reconstructions with temporal Event Data Recorder (EDR).For validation, we applied it to all LVD cases, focusing on a subset of 39 complex crashes where multiple EDR records per collision introduced ambiguity (e.g., due to missing or conflicting data).The evaluation of the 39 LVD crash cases revealed our framework achieved perfect accuracy across all test cases, successfully identifying both the most relevant EDR event and correctly distinguishing striking versus struck vehicles, surpassing the 92% accuracy achieved by human researchers on the same challenging dataset. The system maintained robust performance even when processing incomplete data, including missing or erroneous EDR records and ambiguous scene diagrams. This study demonstrates superior AI capabilities in processing heterogeneous collision data, providing unprecedented precision in reconstructing impact dynamics and characterizing pre-crash behaviors.

</details>


### [8] [LLM enhanced graph inference for long-term disease progression modelling](https://arxiv.org/abs/2511.10890)
*Tiantian He,An Zhao,Elinor Thompson,Anna Schroder,Ahmed Abdulaal,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.AI

TL;DR: 该论文提出了一种利用大语言模型（LLMs）作为专家指导的新框架，用于从非规则采样的纵向患者数据中学习神经退行性疾病的进展，同时优化长期疾病轨迹和生物约束图结构。


<details>
  <summary>Details</summary>
Motivation: 研究脑区之间生物标志物在神经退行性疾病中的相互作用对于揭示疾病进展机制至关重要。现有方法过于简化了脑连接的复杂性，且数据驱动的方法存在可识别性问题。

Method: 论文引入了一种结合LLMs的新框架，利用LLMs合成多模态关系并整合多种疾病驱动机制，优化疾病轨迹和图结构的学习。

Result: 通过使用阿尔茨海默病队列的tau-PET成像数据，该方法在预测准确性和可解释性上优于传统方法，并揭示了超出传统连接性测量的疾病驱动因素。

Conclusion: 该框架为神经退行性疾病的病理传播研究提供了一种更准确和可解释的方法，同时扩展了对疾病驱动机制的理解。

Abstract: Understanding the interactions between biomarkers among brain regions during neurodegenerative disease is essential for unravelling the mechanisms underlying disease progression. For example, pathophysiological models of Alzheimer's Disease (AD) typically describe how variables, such as regional levels of toxic proteins, interact spatiotemporally within a dynamical system driven by an underlying biological substrate, often based on brain connectivity. However, current methods grossly oversimplify the complex relationship between brain connectivity by assuming a single-modality brain connectome as the disease-spreading substrate. This leads to inaccurate predictions of pathology spread, especially during the long-term progression period. Meanhwile, other methods of learning such a graph in a purely data-driven way face the identifiability issue due to lack of proper constraint. We thus present a novel framework that uses Large Language Models (LLMs) as expert guides on the interaction of regional variables to enhance learning of disease progression from irregularly sampled longitudinal patient data. By leveraging LLMs' ability to synthesize multi-modal relationships and incorporate diverse disease-driving mechanisms, our method simultaneously optimizes 1) the construction of long-term disease trajectories from individual-level observations and 2) the biologically-constrained graph structure that captures interactions among brain regions with better identifiability. We demonstrate the new approach by estimating the pathology propagation using tau-PET imaging data from an Alzheimer's disease cohort. The new framework demonstrates superior prediction accuracy and interpretability compared to traditional approaches while revealing additional disease-driving factors beyond conventional connectivity measures.

</details>


### [9] [Multi-Agent Legal Verifier Systems for Data Transfer Planning](https://arxiv.org/abs/2511.10925)
*Ha-Thanh Nguyen,Wachara Fungwacharakorn,Ken Satoh*

Main category: cs.AI

TL;DR: 论文提出了一种多智能体法律验证器，通过分解合规性检查任务来提高AI在法律合规性验证中的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在严格的隐私法规（如日本《个人信息保护法》）下，AI驱动的数据传输规划中的法律合规性变得至关重要。

Method: 设计了多智能体系统，包括法规解释、业务背景评估和风险评估的专门智能体，并通过结构化协议协调工作。

Result: 在200个《个人信息保护法》修订案例数据集上，系统达到72%的准确率，比单智能体基线提高21个百分点，特别是在明确合规案例中达到90%的准确率。

Conclusion: 研究表明，领域专业化和协调推理能显著提升法律AI性能，为可信赖和可解释的自动化合规验证提供了可扩展的框架。

Abstract: Legal compliance in AI-driven data transfer planning is becoming increasingly critical under stringent privacy regulations such as the Japanese Act on the Protection of Personal Information (APPI). We propose a multi-agent legal verifier that decomposes compliance checking into specialized agents for statutory interpretation, business context evaluation, and risk assessment, coordinated through a structured synthesis protocol. Evaluated on a stratified dataset of 200 Amended APPI Article 16 cases with clearly defined ground truth labels and multiple performance metrics, the system achieves 72% accuracy, which is 21 percentage points higher than a single-agent baseline, including 90% accuracy on clear compliance cases (vs. 16% for the baseline) while maintaining perfect detection of clear violations. While challenges remain in ambiguous scenarios, these results show that domain specialization and coordinated reasoning can meaningfully improve legal AI performance, providing a scalable and regulation-aware framework for trustworthy and interpretable automated compliance verification.

</details>


### [10] [Requirements for Aligned, Dynamic Resolution of Conflicts in Operational Constraints](https://arxiv.org/abs/2511.10952)
*Steven J. Jones,Robert E. Wray,John E. Laird*

Main category: cs.AI

TL;DR: AI系统在复杂环境中需要评估和选择符合人类期望的行动方案，尽管训练受限。本文研究其决策所需的知识类型和方法。


<details>
  <summary>Details</summary>
Motivation: 在未知或未完全定义的场景中，AI系统需要评估多组行动方案，且可能无完全符合约束的选择。因此，研究如何使其决策符合人类期望和价值观。

Method: 结合分析和实证案例研究，探讨AI系统如何整合规范性、实用性和情境性知识以选择和执行更符合期望的行动方案。

Result: 提出了AI系统决策所需的多种知识类型，包括规范性、实用性和情境性理解，以提高其在复杂环境中的适应性。

Conclusion: 为AI系统设计更鲁棒且符合人类期望的决策机制，需整合多类知识，以应对复杂多变的现实环境挑战。

Abstract: Deployed, autonomous AI systems must often evaluate multiple plausible courses of action (extended sequences of behavior) in novel or under-specified contexts. Despite extensive training, these systems will inevitably encounter scenarios where no available course of action fully satisfies all operational constraints (e.g., operating procedures, rules, laws, norms, and goals). To achieve goals in accordance with human expectations and values, agents must go beyond their trained policies and instead construct, evaluate, and justify candidate courses of action. These processes require contextual "knowledge" that may lie outside prior (policy) training. This paper characterizes requirements for agent decision making in these contexts. It also identifies the types of knowledge agents require to make decisions robust to agent goals and aligned with human expectations. Drawing on both analysis and empirical case studies, we examine how agents need to integrate normative, pragmatic, and situational understanding to select and then to pursue more aligned courses of action in complex, real-world environments.

</details>


### [11] [Faster Symmetry Breaking Constraints for Abstract Structures](https://arxiv.org/abs/2511.11029)
*Özgür Akgün,Mun See Chang,Ian P. Gent,Christopher Jefferson*

Main category: cs.AI

TL;DR: 提出了一种新的不完全对称性破坏方法，通过更好地利用抽象结构的表示来提高效率，并展示了在不可区分对象对称性处理上的优越性能。


<details>
  <summary>Details</summary>
Motivation: 在约束编程中，抽象结构的对称性破坏通常产生大量复杂约束且性能较差，因此需要一种更高效的方法。

Method: 通过利用抽象结构的表示方式，开发了一种新的不完全对称性破坏方法。

Result: 该方法在处理不可区分对象的对称性时，比现有方法更快速。

Conclusion: 新方法在对称性破坏中表现出更高的效率，尤其适用于抽象结构。

Abstract: In constraint programming and related paradigms, a modeller specifies their problem in a modelling language for a solver to search and return its solution(s). Using high-level modelling languages such as Essence, a modeller may express their problems in terms of abstract structures. These are structures not natively supported by the solvers, and so they have to be transformed into or represented as other structures before solving. For example, nested sets are abstract structures, and they can be represented as matrices in constraint solvers. Many problems contain symmetries and one very common and highly successful technique used in constraint programming is to "break" symmetries, to avoid searching for symmetric solutions. This can speed up the solving process by many orders of magnitude. Most of these symmetry-breaking techniques involve placing some kind of ordering for the variables of the problem, and picking a particular member under the symmetries, usually the smallest. Unfortunately, applying this technique to abstract variables produces a very large number of complex constraints that perform poorly in practice. In this paper, we demonstrate a new incomplete method of breaking the symmetries of abstract structures by better exploiting their representations. We apply the method in breaking the symmetries arising from indistinguishable objects, a commonly occurring type of symmetry, and show that our method is faster than the previous methods proposed in (Akgün et al. 2025).

</details>


### [12] [Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?](https://arxiv.org/abs/2511.11040)
*Qian Zhang,Yan Zheng,Jinyi Liu,Hebin Liang,Lanjun Wang*

Main category: cs.AI

TL;DR: 研究发现，在Multi-Agent Debate（MAD）中，角色分配策略对性能有显著影响，提出了一种名为'Truth Last'的新策略，可提升推理任务性能22%。针对实际应用中未知真相的问题，提出了Multi-Agent Debate Consistency（MADC）策略，通过一致性评估优化机制，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然多智能体辩论（MAD）展现了提升推理能力的潜力，但角色分配策略的作用尚未充分探索。本研究旨在填补这一空白，探索角色分配对MAD性能的影响。

Method: 提出了两种策略：1. 'Truth Last'角色分配策略，通过特定角色分配显著提升性能；2. Multi-Agent Debate Consistency（MADC）策略，通过一致性模拟和优化机制解决未知真相问题。实验覆盖了9种LLM模型。

Result: 'Truth Last'策略在推理任务中提升性能达22%。MADC策略在多种LLM模型上表现优异，有效克服了MAD的性能瓶颈。

Conclusion: 角色分配策略是影响MAD性能的关键因素之一。MADC为LLM智能体扩展提供了重要改进路径，具有广泛的应用潜力。

Abstract: Recent studies on LLM agent scaling have highlighted the potential of Multi-Agent Debate (MAD) to enhance reasoning abilities. However, the critical aspect of role allocation strategies remains underexplored. In this study, we demonstrate that allocating roles with differing viewpoints to specific positions significantly impacts MAD's performance in reasoning tasks. Specifically, we find a novel role allocation strategy, "Truth Last", which can improve MAD performance by up to 22% in reasoning tasks. To address the issue of unknown truth in practical applications, we propose the Multi-Agent Debate Consistency (MADC) strategy, which systematically simulates and optimizes its core mechanisms. MADC incorporates path consistency to assess agreement among independent roles, simulating the role with the highest consistency score as the truth. We validated MADC across a range of LLMs (9 models), including the DeepSeek-R1 Distilled Models, on challenging reasoning tasks. MADC consistently demonstrated advanced performance, effectively overcoming MAD's performance bottlenecks and providing a crucial pathway for further improvements in LLM agent scaling.

</details>


### [13] [Autonomous Vehicle Path Planning by Searching With Differentiable Simulation](https://arxiv.org/abs/2511.11043)
*Asen Nachkov,Jan-Nico Zaech,Danda Pani Paudel,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 论文提出了一种基于可微分模拟器的搜索框架DSS，用于自动驾驶中的精确规划和路径优化，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，通过规划避免碰撞和应对复杂交通场景至关重要，但学习策略、状态预测和评估所需组件时存在挑战。

Method: 提出DSS框架，利用可微分模拟器Waymax作为状态预测器和评估器，结合梯度下降优化动作序列。

Result: 实验表明，DSS在跟踪和路径规划准确性上优于序列预测、模仿学习、无模型RL等方法。

Conclusion: DSS通过结合规划梯度和随机搜索，显著提升了自动驾驶中的规划性能。

Abstract: Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.

</details>


### [14] [Satisficing and Optimal Generalised Planning via Goal Regression (Extended Version)](https://arxiv.org/abs/2511.11095)
*Dillon Z. Chen,Till Hofmann,Toryn Q. Klassen,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: 该论文提出了一种新的广义规划方法，通过从训练问题中提取最优计划并生成条件-动作规则，显著优于现有广义规划器。


<details>
  <summary>Details</summary>
Motivation: 广义规划的目标是合成能够解决一系列相关规划问题的程序。现有方法在某些方面效率不足，因此需要更简单且有效的方法。

Method: 为每个训练问题按目标原子顺序计算最优计划，进行目标回归，并将其提升为一阶条件-动作规则，形成广义计划。

Result: 实验表明，该方法在合成成本、规划覆盖率和解决方案质量上均显著优于当前先进的广义规划器。

Conclusion: 该方法不仅能够高效生成广义计划，还可用于剪枝搜索空间，为广义规划领域提供了新的解决方案。

Abstract: Generalised planning (GP) refers to the task of synthesising programs that solve families of related planning problems. We introduce a novel, yet simple method for GP: given a set of training problems, for each problem, compute an optimal plan for each goal atom in some order, perform goal regression on the resulting plans, and lift the corresponding outputs to obtain a set of first-order $\textit{Condition} \rightarrow \textit{Actions}$ rules. The rules collectively constitute a generalised plan that can be executed as is or alternatively be used to prune the planning search space. We formalise and prove the conditions under which our method is guaranteed to learn valid generalised plans and state space pruning axioms for search. Experiments demonstrate significant improvements over state-of-the-art (generalised) planners with respect to the 3 metrics of synthesis cost, planning coverage, and solution quality on various classical and numeric planning domains.

</details>


### [15] [GGBench: A Geometric Generative Reasoning Benchmark for Unified Multimodal Models](https://arxiv.org/abs/2511.11134)
*Jingxuan Wei,Caijun Jia,Xi Bai,Xinglong Xu,Siyuan Li,Linzhuang Sun,Bihui Yu,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.AI

TL;DR: 论文提出GGBench基准，用于评估统一多模态模型在几何生成推理中的能力，填补了现有评估方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注判别式理解或无约束图像生成，无法衡量生成式推理的综合认知过程，因此需要新的评估方法。

Method: 通过几何构造作为理想测试平台，结合语言理解和精确视觉生成，设计了GGBench基准。

Result: GGBench提供了一个系统化的框架，评估模型的理解、推理和主动构造解决方案的能力。

Conclusion: GGBench为下一代智能系统设置了更严格的标准，推动了多模态模型在生成推理领域的发展。

Abstract: The advent of Unified Multimodal Models (UMMs) signals a paradigm shift in artificial intelligence, moving from passive perception to active, cross-modal generation. Despite their unprecedented ability to synthesize information, a critical gap persists in evaluation: existing benchmarks primarily assess discriminative understanding or unconstrained image generation separately, failing to measure the integrated cognitive process of generative reasoning. To bridge this gap, we propose that geometric construction provides an ideal testbed as it inherently demands a fusion of language comprehension and precise visual generation. We introduce GGBench, a benchmark designed specifically to evaluate geometric generative reasoning. It provides a comprehensive framework for systematically diagnosing a model's ability to not only understand and reason but to actively construct a solution, thereby setting a more rigorous standard for the next generation of intelligent systems. Project website: https://opendatalab-raiser.github.io/GGBench/.

</details>


### [16] [STaR: Towards Cognitive Table Reasoning via Slow-Thinking Large Language Models](https://arxiv.org/abs/2511.11233)
*Huajian Zhang,Mingyue Cheng,Yucong Luo,Xiaoyu Tao*

Main category: cs.AI

TL;DR: 论文提出STaR框架，通过改进LLMs的表格推理能力，模拟人类深度思考和不确定性感知推理，显著提升性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在表格推理中存在深度思考不足和推理不稳定问题，限制了其可靠性。

Method: STaR框架采用两阶段难度感知强化学习（DRL），逐步学习从简单到复杂的查询，并在推理时量化不确定性。

Result: STaR在基准测试中表现优异，推理稳定性增强，且对域外数据具有强泛化能力。

Conclusion: STaR为LLMs的表格推理提供了一种可靠且受认知启发的解决方案。

Abstract: Table reasoning with the large language models (LLMs) is a fundamental path toward building intelligent systems that can understand and analyze over structured data. While recent progress has shown promising results, they still suffer from two key limitations: (i) the reasoning processes lack the depth and iterative refinement characteristic of human cognition; and (ii) the reasoning processes exhibit instability, which compromises their reliability in downstream applications. In this work, we present STaR (slow-thinking for table reasoning), a new framework achieving cognitive table reasoning, in which LLMs are equipped with slow-thinking capabilities by explicitly modeling step-by-step thinking and uncertainty-aware inference. During training, STaR employs two-stage difficulty-aware reinforcement learning (DRL), progressively learning from simple to complex queries under a composite reward. During inference, STaR performs trajectory-level uncertainty quantification by integrating token-level confidence and answer consistency, enabling selection of more credible reasoning paths. Extensive experiments on benchmarks demonstrate that STaR achieves superior performance and enhanced reasoning stability. Moreover, strong generalization over out-of-domain datasets further demonstrates STaR's potential as a reliable and cognitively inspired solution for table reasoning with LLMs.

</details>


### [17] [A Workflow for Full Traceability of AI Decisions](https://arxiv.org/abs/2511.11275)
*Julius Wenzel,Syeda Umaima Alam,Andreas Schmidt,Hanwei Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: 为解决AI系统决策过程缺乏透明性导致的责任追溯问题，本文提出了一种可验证的、防篡改的AI决策追踪工作流。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统决策过程缺乏文档记录，导致责任链难以追溯，可能引发法律风险。

Method: 通过强制记录训练和推理过程中的所有组件，构建了一个可运行的防篡改、可验证的追踪工作流，并扩展了DBOM概念。

Result: 成功开发了一个用于区分有毒和可食用蘑菇的应用程序，验证了工作流的有效性。

Conclusion: 本文提出的工作流为AI决策提供了透明性和可追溯性，为解决责任链问题提供了实用方案。

Abstract: An ever increasing number of high-stake decisions are made or assisted by automated systems employing brittle artificial intelligence technology. There is a substantial risk that some of these decision induce harm to people, by infringing their well-being or their fundamental human rights. The state-of-the-art in AI systems makes little effort with respect to appropriate documentation of the decision process. This obstructs the ability to trace what went into a decision, which in turn is a prerequisite to any attempt of reconstructing a responsibility chain. Specifically, such traceability is linked to a documentation that will stand up in court when determining the cause of some AI-based decision that inadvertently or intentionally violates the law.
  This paper takes a radical, yet practical, approach to this problem, by enforcing the documentation of each and every component that goes into the training or inference of an automated decision. As such, it presents the first running workflow supporting the generation of tamper-proof, verifiable and exhaustive traces of AI decisions. In doing so, we expand the DBOM concept into an effective running workflow leveraging confidential computing technology. We demonstrate the inner workings of the workflow in the development of an app to tell poisonous and edible mushrooms apart, meant as a playful example of high-stake decision support.

</details>


### [18] [Can You Tell the Difference? Contrastive Explanations for ABox Entailments](https://arxiv.org/abs/2511.11281)
*Patrick Koopmann,Yasir Mahmood,Axel-Cyrille Ngonga Ngomo,Balram Tiwari*

Main category: cs.AI

TL;DR: 该论文提出了对比ABox解释的概念，用于回答‘为什么a是C的实例而b不是？’等问题。传统方法孤立地解释正蕴含和缺失蕴含，而对比解释同时考虑两者，关注a和b之间的共性与差异。论文针对描述逻辑本体的ABox推理，定义了对比解释，分析了不同变体在不同最优标准下的计算复杂性，并实现了一种计算对比解释的方法，在真实知识库上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 为了解决‘为什么a是C的实例而b不是’这类问题，传统方法只能分别解释正蕴含和缺失蕴含，缺乏对两者之间关系的关注。

Method: 论文提出了对比ABox解释的概念，分析了其在描述逻辑本体ABox推理中的计算复杂性，涵盖轻量级和更表达性的描述逻辑。

Result: 实现了一种计算对比解释的方法，并在真实知识库生成的测试问题上进行了评估。

Conclusion: 对比解释能够更全面地回答实例分类的差异问题，为知识库推理提供了更丰富的解释工具。

Abstract: We introduce the notion of contrastive ABox explanations to answer questions of the type "Why is a an instance of C, but b is not?". While there are various approaches for explaining positive entailments (why is C(a) entailed by the knowledge base) as well as missing entailments (why is C(b) not entailed) in isolation, contrastive explanations consider both at the same time, which allows them to focus on the relevant commonalities and differences between a and b. We develop an appropriate notion of contrastive explanations for the special case of ABox reasoning with description logic ontologies, and analyze the computational complexity for different variants under different optimality criteria, considering lightweight as well as more expressive description logics. We implemented a first method for computing one variant of contrastive explanations, and evaluated it on generated problems for realistic knowledge bases.

</details>


### [19] [RLSLM: A Hybrid Reinforcement Learning Framework Aligning Rule-Based Social Locomotion Model with Human Social Norms](https://arxiv.org/abs/2511.11323)
*Yitian Kou,Yihe Gu,Chen Zhou,DanDan Zhu,Shuguang Kuai*

Main category: cs.AI

TL;DR: RLSLM是一种结合规则与数据驱动的混合强化学习框架，用于实现社会感知导航，同时优化机械能与社会舒适度，提升用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决社会感知导航中规则方法缺乏通用性和数据驱动方法效率低、不透明的问题。

Method: 结合基于行为的规则模型与强化学习框架，生成方向敏感的社交舒适场来衡量人类舒适度。

Result: 实验表明RLSLM在用户体验上优于现有规则模型，且在解释性上优于传统数据驱动方法。

Conclusion: 研究提出了一种可扩展的方法，有效整合认知科学与机器学习，实现现实世界中的社会导航。

Abstract: Navigating human-populated environments without causing discomfort is a critical capability for socially-aware agents. While rule-based approaches offer interpretability through predefined psychological principles, they often lack generalizability and flexibility. Conversely, data-driven methods can learn complex behaviors from large-scale datasets, but are typically inefficient, opaque, and difficult to align with human intuitions. To bridge this gap, we propose RLSLM, a hybrid Reinforcement Learning framework that integrates a rule-based Social Locomotion Model, grounded in empirical behavioral experiments, into the reward function of a reinforcement learning framework. The social locomotion model generates an orientation-sensitive social comfort field that quantifies human comfort across space, enabling socially aligned navigation policies with minimal training. RLSLM then jointly optimizes mechanical energy and social comfort, allowing agents to avoid intrusions into personal or group space. A human-agent interaction experiment using an immersive VR-based setup demonstrates that RLSLM outperforms state-of-the-art rule-based models in user experience. Ablation and sensitivity analyses further show the model's significantly improved interpretability over conventional data-driven methods. This work presents a scalable, human-centered methodology that effectively integrates cognitive science and machine learning for real-world social navigation.

</details>


### [20] [KarmaTS: A Universal Simulation Platform for Multivariate Time Series with Functional Causal Dynamics](https://arxiv.org/abs/2511.11357)
*Haixin Li,Yanke Li,Diego Paez-Granados*

Main category: cs.AI

TL;DR: KarmaTS是一个交互式框架，用于构建基于滞后索引的可执行时空因果图模型，旨在模拟多变量时间序列（MTS），解决生理数据访问受限的问题。


<details>
  <summary>Details</summary>
Motivation: 由于生理数据获取受限，KarmaTS旨在生成具有已知因果动态的合成MTS，并结合专家知识增强真实数据集。

Method: 通过结合专家知识和算法提议，KarmaTS构建了离散时间结构因果过程（DSCP），支持模拟和因果干预。

Result: KarmaTS能够处理混合变量类型、同时性和滞后边缘，以及模块化边缘功能，支持灵活的验证和因果发现算法基准测试。

Conclusion: KarmaTS通过专家指导的模拟，为因果发现算法的验证和基准测试提供了灵活的工具。

Abstract: We introduce KarmaTS, an interactive framework for constructing lag-indexed, executable spatiotemporal causal graphical models for multivariate time series (MTS) simulation. Motivated by the challenge of access-restricted physiological data, KarmaTS generates synthetic MTS with known causal dynamics and augments real-world datasets with expert knowledge. The system constructs a discrete-time structural causal process (DSCP) by combining expert knowledge and algorithmic proposals in a mixed-initiative, human-in-the-loop workflow. The resulting DSCP supports simulation and causal interventions, including those under user-specified distribution shifts. KarmaTS handles mixed variable types, contemporaneous and lagged edges, and modular edge functionals ranging from parameterizable templates to neural network models. Together, these features enable flexible validation and benchmarking of causal discovery algorithms through expert-informed simulation.

</details>


### [21] [MarsRL: Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism](https://arxiv.org/abs/2511.11373)
*Shulin Liu,Dong Du,Tao Yang,Yang Li,Boyu Qiu*

Main category: cs.AI

TL;DR: 论文提出了MarsRL，一种新型强化学习框架，通过多智能体管道并行优化解决开源模型中推理深度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在单次推理中的输出长度限制了推理深度，多智能体系统虽然有效，但在开源模型中表现不佳。

Method: 提出MarsRL框架，采用智能体专用奖励机制和管道并行训练，优化系统内所有智能体。

Result: 在Qwen3-30B-A3B-Thinking-2507上，AIME2025准确率从86.5%提升至93.3%，BeyondAIME从64.9%提升至73.8%。

Conclusion: MarsRL能显著提升多智能体推理系统的性能，并扩展其在多样化推理任务中的适用性。

Abstract: Recent progress in large language models (LLMs) has been propelled by reinforcement learning with verifiable rewards (RLVR) and test-time scaling. However, the limited output length of LLMs constrains the depth of reasoning attainable in a single inference process. Multi-agent reasoning systems offer a promising alternative by employing multiple agents including Solver, Verifier, and Corrector, to iteratively refine solutions. While effective in closed-source models like Gemini 2.5 Pro, they struggle to generalize to open-source models due to insufficient critic and correction capabilities. To address this, we propose MarsRL, a novel reinforcement learning framework with agentic pipeline parallelism, designed to jointly optimize all agents in the system. MarsRL introduces agent-specific reward mechanisms to mitigate reward noise and employs pipeline-inspired training to enhance efficiency in handling long trajectories. Applied to Qwen3-30B-A3B-Thinking-2507, MarsRL improves AIME2025 accuracy from 86.5% to 93.3% and BeyondAIME from 64.9% to 73.8%, even surpassing Qwen3-235B-A22B-Thinking-2507. These findings highlight the potential of MarsRL to advance multi-agent reasoning systems and broaden their applicability across diverse reasoning tasks.

</details>


### [22] [Robust and Efficient Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.11393)
*Zejiao Liu,Yi Li,Jiali Wang,Junqi Tu,Yitian Hong,Fangfei Li,Yang Liu,Toshiharu Sugawara,Yang Tang*

Main category: cs.AI

TL;DR: 这篇论文综述了多智能体强化学习（MARL）在实际约束下（如扰动、延迟、带宽限制）的鲁棒高效通信策略的研究进展，并探讨了三个应用场景，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法通常假设通信是即时、可靠且无限带宽的，而实际应用中这些条件难以满足，因此需要研究更鲁棒和高效的通信策略。

Method: 系统回顾了在消息扰动、传输延迟和带宽限制等实际约束下的MARL通信策略研究，并聚焦于三个具体应用场景进行探讨。

Result: 总结了当前的研究进展，指出了低延迟可靠性、带宽密集数据共享和通信隐私权衡等核心挑战。

Conclusion: 提出了一种统一的方法，通过共同设计通信、学习和鲁棒性来缩小理论模型与实际应用之间的差距，并指明了未来的研究方向。

Abstract: Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.

</details>


### [23] [CURENet: Combining Unified Representations for Efficient Chronic Disease Prediction](https://arxiv.org/abs/2511.11423)
*Cong-Tinh Dao,Nguyen Minh Thao Phan,Jun-En Ding,Chenwei Wu,David Restrepo,Dongsheng Luo,Fanyi Zhao,Chun-Chieh Liao,Wen-Chih Peng,Chi-Te Wang,Pei-Fu Chen,Ling Chen,Xinglong Ju,Feng Liu,Fang-Ming Hung*

Main category: cs.AI

TL;DR: CURENet是一种多模态模型，整合临床笔记、实验室测试和时间序列数据，通过LLMs和编码器捕获复杂交互，提升慢性病预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有预测模型未能充分利用EHR多模态数据的交互和时间模式，影响临床决策。

Method: 利用大型语言模型处理临床文本和实验室测试，使用编码器处理纵向时间序列数据。

Result: 在公开和私人数据集上，对前10种慢性病的多标签预测准确率超过94%。

Conclusion: 多模态EHR整合可显著改进临床决策和患者预后。

Abstract: Electronic health records (EHRs) are designed to synthesize diverse data types, including unstructured clinical notes, structured lab tests, and time-series visit data. Physicians draw on these multimodal and temporal sources of EHR data to form a comprehensive view of a patient's health, which is crucial for informed therapeutic decision-making. Yet, most predictive models fail to fully capture the interactions, redundancies, and temporal patterns across multiple data modalities, often focusing on a single data type or overlooking these complexities. In this paper, we present CURENet, a multimodal model (Combining Unified Representations for Efficient chronic disease prediction) that integrates unstructured clinical notes, lab tests, and patients' time-series data by utilizing large language models (LLMs) for clinical text processing and textual lab tests, as well as transformer encoders for longitudinal sequential visits. CURENet has been capable of capturing the intricate interaction between different forms of clinical data and creating a more reliable predictive model for chronic illnesses. We evaluated CURENet using the public MIMIC-III and private FEMH datasets, where it achieved over 94\% accuracy in predicting the top 10 chronic conditions in a multi-label framework. Our findings highlight the potential of multimodal EHR integration to enhance clinical decision-making and improve patient outcomes.

</details>


### [24] [Experience-Guided Adaptation of Inference-Time Reasoning Strategies](https://arxiv.org/abs/2511.11519)
*Adam Stein,Matthew Trager,Benjamin Bowman,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: EGuR是一种动态生成个性化解决策略的AI系统，通过实时积累经验优化效果并降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI系统在推理时无法灵活调整参数或策略的问题。

Method: 基于LLM的元策略动态生成策略，包含生成候选策略和整合执行反馈两部分。

Result: 在多个基准测试中，EGuR性能提升高达14%，计算成本降低111倍。

Conclusion: EGuR通过动态策略生成和优化，显著提升了AI系统的适应性和效率。

Abstract: Enabling agentic AI systems to adapt their problem-solving approaches based on post-training interactions remains a fundamental challenge. While systems that update and maintain a memory at inference time have been proposed, existing designs only steer the system by modifying textual input to a language model or agent, which means that they cannot change sampling parameters, remove tools, modify system prompts, or switch between agentic and workflow paradigms. On the other hand, systems that adapt more flexibly require offline optimization and remain static once deployed. We present Experience-Guided Reasoner (EGuR), which generates tailored strategies -- complete computational procedures involving LLM calls, tools, sampling parameters, and control logic -- dynamically at inference time based on accumulated experience. We achieve this using an LLM-based meta-strategy -- a strategy that outputs strategies -- enabling adaptation of all strategy components (prompts, sampling parameters, tool configurations, and control logic). EGuR operates through two components: a Guide generates multiple candidate strategies conditioned on the current problem and structured memory of past experiences, while a Consolidator integrates execution feedback to improve future strategy generation. This produces complete, ready-to-run strategies optimized for each problem, which can be cached, retrieved, and executed as needed without wasting resources. Across five challenging benchmarks (AIME 2025, 3-SAT, and three Big Bench Extra Hard tasks), EGuR achieves up to 14% accuracy improvements over the strongest baselines while reducing computational costs by up to 111x, with both metrics improving as the system gains experience.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [25] [Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues](https://arxiv.org/abs/2511.10762)
*Nikolaos Tsagkas,Andreas Sochopoulos,Duolikun Danier,Sethu Vijayakumar,Alexandros Kouris,Oisin Mac Aodha,Chris Xiaoxuan Lu*

Main category: cs.RO

TL;DR: 论文提出了一种名为Attentive Feature Aggregation (AFA)的轻量级可训练池化机制，用于提升视觉运动策略在视觉干扰下的鲁棒性，无需昂贵的数据增强或PVR微调。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉表示（PVRs）虽然强大，但可能包含与任务无关的场景信息，导致训练出的视觉运动策略在面对视觉干扰时缺乏鲁棒性。作者希望通过特征池化解决这一问题。

Method: 提出Attentive Feature Aggregation (AFA)，通过学习任务相关视觉线索的注意力机制，忽略无关信息，从而提升策略的鲁棒性。

Result: 实验表明，使用AFA训练的视觉运动策略在视觉干扰环境中显著优于标准池化方法，且无需额外的数据增强或PVR微调。

Conclusion: 忽略无关视觉信息是提升视觉运动策略鲁棒性和泛化能力的关键步骤。

Abstract: The adoption of pre-trained visual representations (PVRs), leveraging features from large-scale vision models, has become a popular paradigm for training visuomotor policies. However, these powerful representations can encode a broad range of task-irrelevant scene information, making the resulting trained policies vulnerable to out-of-domain visual changes and distractors. In this work we address visuomotor policy feature pooling as a solution to the observed lack of robustness in perturbed scenes. We achieve this via Attentive Feature Aggregation (AFA), a lightweight, trainable pooling mechanism that learns to naturally attend to task-relevant visual cues, ignoring even semantically rich scene distractors. Through extensive experiments in both simulation and the real world, we demonstrate that policies trained with AFA significantly outperform standard pooling approaches in the presence of visual perturbations, without requiring expensive dataset augmentation or fine-tuning of the PVR. Our findings show that ignoring extraneous visual information is a crucial step towards deploying robust and generalisable visuomotor policies. Project Page: tsagkas.github.io/afa

</details>


### [26] [From Framework to Reliable Practice: End-User Perspectives on Social Robots in Public Spaces](https://arxiv.org/abs/2511.10770)
*Samson Oruma,Ricardo Colomo-Palacios,Vasileios Gkioulos*

Main category: cs.RO

TL;DR: 论文探讨了社会机器人在公共环境中的接受度，基于ARI机器人在大学接待员角色中的试点部署，结合SecuRoPS框架评估其安全性、隐私、可用性和透明度，结果显示正面反馈，但也指出了可访问性和互动性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着社会机器人进入公共环境，其接受度不仅依赖于技术可靠性，还与伦理完整性、可访问性和用户信任相关。本研究旨在通过实际部署评估这些问题。

Method: 使用ARI机器人作为大学接待员，基于SecuRoPS框架进行设计和部署，通过35名参与者反馈评估安全、隐私、可用性和透明度。

Result: 参与者对物理安全性、数据保护和伦理行为整体持正面态度，但强调了可访问性和互动性方面的不足。

Conclusion: 研究展示了伦理和安全设计框架的实际应用，并通过公开模板支持研究的可重复性和普及，为开发可信赖的社会机器人提供参考。

Abstract: As social robots increasingly enter public environments, their acceptance depends not only on technical reliability but also on ethical integrity, accessibility, and user trust. This paper reports on a pilot deployment of an ARI social robot functioning as a university receptionist, designed in alignment with the SecuRoPS framework for secure and ethical social robot deployment. Thirty-five students and staff interacted with the robot and provided structured feedback on safety, privacy, usability, accessibility, and transparency. The results show generally positive perceptions of physical safety, data protection, and ethical behavior, while also highlighting challenges related to accessibility, inclusiveness, and dynamic interaction. Beyond the empirical findings, the study demonstrates how theoretical frameworks for ethical and secure design can be implemented in real-world contexts through end-user evaluation. It also provides a public GitHub repository containing reusable templates for ARI robot applications to support reproducibility and lower the entry barrier for new researchers. By combining user perspectives with practical technical resources, this work contributes to ongoing discussions in AI and society and supports the development of trustworthy, inclusive, and ethically responsible social robots for public spaces.

</details>


### [27] [$\rm{A}^{\rm{SAR}}$: $\varepsilon$-Optimal Graph Search for Minimum Expected-Detection-Time Paths with Path Budget Constraints for Search and Rescue](https://arxiv.org/abs/2511.10792)
*Eric Mugford,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 这篇论文提出了一种名为$m{A}^{m{SAR}}$的$\varepsilon$-最优搜索算法，用于优化搜救（SAR）任务中的搜索规划。


<details>
  <summary>Details</summary>
Motivation: 在搜救任务中，由于信息不确定、观察者不完美以及搜索区域大，最优搜索可能提高成功率。现有的随机优化方法缺乏对解质量的正式保证，因此需要一种能提供保证的算法。

Method: 作者提出$m{A}^{m{SAR}}$，通过计算启发式来限定搜索空间，并使用图搜索方法找到在用户指定因子$\varepsilon$内最优的解。

Result: 算法在模拟测试中比现有方法更快地找到更好的解，并在实际试验中（加拿大安大略湖）仅用150秒定位到漂移的人偶。

Conclusion: $m{A}^{m{SAR}}$为SAR任务提供了一种高效且具有正式最优性保证的解决方案。

Abstract: Searches are conducted to find missing persons and/or objects given uncertain information, imperfect observers and large search areas in Search and Rescue (SAR). In many scenarios, such as Maritime SAR, expected survival times are short and optimal search could increase the likelihood of success. This optimization problem is complex for nontrivial problems given its probabilistic nature.
  Stochastic optimization methods search large problems by nondeterministically sampling the space to reduce the effective size of the problem. This has been used in SAR planning to search otherwise intractably large problems but the stochastic nature provides no formal guarantees on the quality of solutions found in finite time.
  This paper instead presents $\rm{A}^{\rm{SAR}}$, an $\varepsilon$-optimal search algorithm for SAR planning. It calculates a heuristic to bound the search space and uses graph-search methods to find solutions that are formally guaranteed to be within a user-specified factor, $\varepsilon$, of the optimal solution. It finds better solutions faster than existing optimization approaches in operational simulations. It is also demonstrated with a real-world field trial on Lake Ontario, Canada, where it was used to locate a drifting manikin in only 150s.

</details>


### [28] [An Investigation into Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios](https://arxiv.org/abs/2511.10816)
*William Harris,Lucas Yager,Syler Sylvester,Elizabeth Peiros,Micheal C. Yip*

Main category: cs.RO

TL;DR: 这篇论文提出了一种新型可动态伸缩的机器人腿设计，用于搜救机器人，兼顾地形适应性和高力输出能力。


<details>
  <summary>Details</summary>
Motivation: 当前搜救机器人领域缺乏既能快速适应地形又能输出高力的平台。腿式机器人虽地形适应性强，但通常无法实现高力输出。

Method: 采用动态可伸缩的五杆连杆设计，通过几何变换在高度优势和力量优势配置之间切换。通过测试平台评估不同连杆几何和操作模式下的性能。

Result: 实验和分析表明，这种变形腿在步长、力输出和稳定性方面表现良好，为搜救机器人提供了新思路。

Conclusion: 该设计为搜救机器人同时实现快速地形导航和高效救援任务提供了可行方案。

Abstract: Search and rescue (SAR) robots are required to quickly traverse terrain and perform high-force rescue tasks, necessitating both terrain adaptability and controlled high-force output. Few platforms exist today for SAR, and fewer still have the ability to cover both tasks of terrain adaptability and high-force output when performing extraction. While legged robots offer significant ability to traverse uneven terrain, they typically are unable to incorporate mechanisms that provide variable high-force outputs, unlike traditional wheel-based drive trains. This work introduces a novel concept for a dynamically extensible and retractable robot leg. Leveraging a dynamically extensible and retractable five-bar linkage design, it allows for mechanically switching between height-advantaged and force-advantaged configurations via a geometric transformation. A testbed evaluated leg performance across linkage geometries and operating modes, with empirical and analytical analyses conducted on stride length, force output, and stability. The results demonstrate that the morphing leg offers a promising path toward SAR robots that can both navigate terrain quickly and perform rescue tasks effectively.

</details>


### [29] [MIGHTY: Hermite Spline-based Efficient Trajectory Planning](https://arxiv.org/abs/2511.10822)
*Kota Kondo,Yuwei Wu,Vijay Kumar,Jonathan P. How*

Main category: cs.RO

TL;DR: MIGHTY是一种基于Hermite样条的轨迹规划器，能够在连续搜索空间中进行时空优化，显著降低计算时间和旅行时间。


<details>
  <summary>Details</summary>
Motivation: 现有硬约束轨迹规划器需要大量计算资源，而软约束方法虽然计算更快，但有空间和时间优化解耦或搜索空间受限的问题，MIGHTY旨在解决这些局限性。

Method: MIGHTY基于Hermite样条，能够在连续搜索空间中进行时空优化，避免解耦或限制搜索空间。

Result: 在仿真中，MIGHTY相比现有方法减少9.3%的计算时间和13.1%的旅行时间，且成功率达100%。在实际硬件测试中，它能在静态杂乱环境和动态障碍物下完成高速和长时间飞行。

Conclusion: MIGHTY通过连续搜索空间的时空优化，显著提升了轨迹规划的效率与性能。

Abstract: Hard-constraint trajectory planners often rely on commercial solvers and demand substantial computational resources. Existing soft-constraint methods achieve faster computation, but either (1) decouple spatial and temporal optimization or (2) restrict the search space. To overcome these limitations, we introduce MIGHTY, a Hermite spline-based planner that performs spatiotemporal optimization while fully leveraging the continuous search space of a spline. In simulation, MIGHTY achieves a 9.3% reduction in computation time and a 13.1% reduction in travel time over state-of-the-art baselines, with a 100% success rate. In hardware, MIGHTY completes multiple high-speed flights up to 6.7 m/s in a cluttered static environment and long-duration flights with dynamically added obstacles.

</details>


### [30] [Decentralized Swarm Control via SO(3) Embeddings for 3D Trajectories](https://arxiv.org/abs/2511.10858)
*Dimitria Silveria,Kleber Cabral,Peter Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的分散式方法，实现了多智能体系统中的涌现行为，且仅需最小化的信息共享。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展现有工作，通过基于李群的几何嵌入生成更广泛的周期性轨迹，同时减少对速度输入的依赖，提高系统的稳定性和适应性。

Method: 采用李群SO(3)作为几何嵌入的基础，设计了一种新的相位控制器以确保智能体均匀分布，并辅以正式的稳定性证明。

Result: 模拟和实验结果表明，该方法能够适应复杂的底层动力学和干扰，生成稳定的周期性轨迹。

Conclusion: 该方法在多智能体系统中展现出高效性和适应性，为未来研究提供了新的工具和方向。

Abstract: This paper presents a novel decentralized approach for achieving emergent behavior in multi-agent systems with minimal information sharing. Based on prior work in simple orbits, our method produces a broad class of stable, periodic trajectories by stabilizing the system around a Lie group-based geometric embedding. Employing the Lie group SO(3), we generate a wider range of periodic curves than existing quaternion-based methods. Furthermore, we exploit SO(3) properties to eliminate the need for velocity inputs, allowing agents to receive only position inputs. We also propose a novel phase controller that ensures uniform agent separation, along with a formal stability proof. Validation through simulations and experiments showcases the method's adaptability to complex low-level dynamics and disturbances.

</details>


### [31] [WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot](https://arxiv.org/abs/2511.10864)
*Jose Vasquez,Xuping Zhang*

Main category: cs.RO

TL;DR: WetExplorer是一种用于湿地温室气体（GHG）采样的自主机器人，通过自动化工作流程、高精度定位和深度学习感知，解决了传统人工采样效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 量化湿地的温室气体排放对气候建模和生态恢复评估至关重要，但传统人工采样费时费力，亟需一种自动化解决方案。

Method: WetExplorer机器人整合了低地面压力移动系统、厘米级精度采样装置、双RTK传感器融合、障碍物避障规划和深度学习感知技术，实现了全自动化采样。

Result: 室外试验验证了定位误差均值1.71厘米，视觉模块的物体姿态估计精度为7毫米（平移）和3度（旋转）；室内试验显示运动规划系统可将采样室定位到70毫米的全局误差范围内，无需人为干预。

Conclusion: WetExplorer能够实现高频、多站点的温室气体采样，为湿地长时间密集数据采集提供了有效工具。

Abstract: Quantifying greenhouse-gases (GHG) in wetlands is critical for climate modeling and restoration assessment, yet manual sampling is labor-intensive, and time demanding. We present WetExplorer, an autonomous tracked robot that automates the full GHG-sampling workflow. The robot system integrates low-ground-pressure locomotion, centimeter-accurate lift placement, dual-RTK sensor fusion, obstacle avoidance planning, and deep-learning perception in a containerized ROS2 stack. Outdoor trials verified that the sensor-fusion stack maintains a mean localization error of 1.71 cm, the vision module estimates object pose with 7 mm translational and 3° rotational accuracy, while indoor trials demonstrated that the full motion-planning pipeline positions the sampling chamber within a global tolerance of 70 mm while avoiding obstacles, all without human intervention. By eliminating the manual bottleneck, WetExplorer enables high-frequency, multi-site GHG measurements and opens the door for dense, long-duration datasets in saturated wetland terrain.

</details>


### [32] [Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation](https://arxiv.org/abs/2511.10874)
*Yorai Shaoul,Zhe Chen,Mohamed Naveed Gul Mohamed,Federico Pecora,Maxim Likhachev,Jiaoyang Li*

Main category: cs.RO

TL;DR: 该论文提出了一种用于协作多机器人、多物体非抓取式操纵的统一框架，结合了流匹配生成技术和匿名多机器人运动规划，以解决复杂环境中的机器人协调问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多样化物体和长时程任务时表现不佳，本文旨在通过集成生成模型和运动规划，提升机器人在复杂环境中的协作能力。

Method: 提出了一种结合流匹配生成模型和新型运动规划器的框架，生成接触形态和操纵轨迹，并支持机器人协调和对象级规划。

Result: 在模拟环境中验证，该方法在运动规划和操纵任务上均优于基线方法，展现了生成协同设计和集成规划的优势。

Conclusion: 该框架为复杂多机器人、多物体协作任务提供了一种有效的解决方案，代码和演示见项目网站。

Abstract: Coordinating a team of robots to reposition multiple objects in cluttered environments requires reasoning jointly about where robots should establish contact, how to manipulate objects once contact is made, and how to navigate safely and efficiently at scale. Prior approaches typically fall into two extremes -- either learning the entire task or relying on privileged information and hand-designed planners -- both of which struggle to handle diverse objects in long-horizon tasks. To address these challenges, we present a unified framework for collaborative multi-robot, multi-object non-prehensile manipulation that integrates flow-matching co-generation with anonymous multi-robot motion planning. Within this framework, a generative model co-generates contact formations and manipulation trajectories from visual observations, while a novel motion planner conveys robots at scale. Crucially, the same planner also supports coordination at the object level, assigning manipulated objects to larger target structures and thereby unifying robot- and object-level reasoning within a single algorithmic framework. Experiments in challenging simulated environments demonstrate that our approach outperforms baselines in both motion planning and manipulation tasks, highlighting the benefits of generative co-design and integrated planning for scaling collaborative manipulation to complex multi-agent, multi-object settings. Visit gco-paper.github.io for code and demonstrations.

</details>


### [33] [Terradynamics and design of tip-extending robotic anchors](https://arxiv.org/abs/2511.10901)
*Deniz Kerimoglu,Nicholas D. Naclerio,Sean Chu,Andrew Krohn,Vineet Kupunaram,Alexander Schepelmann,Daniel I. Goldman,Elliot W. Hawkes*

Main category: cs.RO

TL;DR: 论文研究了一种受树根启发的锚定机制，并提出设计轻量级软体机器人锚具的见解，实现在难进入区域的高效锚定。


<details>
  <summary>Details</summary>
Motivation: 传统桩基锚定需要较大的插入力，而提取阻力较小，不适用于难以进入或外星场地。树根插入机制则相反，激发了研究灵感。

Method: 研究尖端延伸锚定与传统桩基的土壤动力学，提出设计准则并开发原型。

Result: 设计出的300克软体机器人锚具，能以小于自重的力插入松散火星土壤模拟物，锚定力达120 N，锚定重量比为40:1。

Conclusion: 尖端延伸锚定机制提供了一种高效、轻量的解决方案，适用于极端环境。

Abstract: Most engineered pilings require substantially more force to be driven into the ground than they can resist during extraction. This requires relatively heavy equipment for insertion, which is problematic for anchoring in hard-to-access sites, including in extraterrestrial locations. In contrast, for tree roots, the external reaction force required to extract is much greater than required to insert--little more than the weight of the seed initiates insertion. This is partly due to the mechanism by which roots insert into the ground: tip extension. Proof-of-concept robotic prototypes have shown the benefits of using this mechanism, but a rigorous understanding of the underlying granular mechanics and how they inform the design of a robotic anchor is lacking. Here, we study the terradynamics of tip-extending anchors compared to traditional piling-like intruders, develop a set of design insights, and apply these to create a deployable robotic anchor. Specifically, we identify that to increase an anchor's ratio of extraction force to insertion force, it should: (i) extend beyond a critical depth; (ii) include hair-like protrusions; (iii) extend near-vertically, and (iv) incorporate multiple smaller anchors rather than a single large anchor. Synthesizing these insights, we developed a lightweight, soft robotic, root-inspired anchoring device that inserts into the ground with a reaction force less than its weight. We demonstrate that the 300 g device can deploy a series of temperature sensors 45 cm deep into loose Martian regolith simulant while anchoring with an average of 120 N, resulting in an anchoring-to-weight ratio of 40:1.

</details>


### [34] [Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment](https://arxiv.org/abs/2511.10987)
*Wenbin Bai,Qiyu Chen,Xiangbo Lin,Jianwen Li,Quancheng Li,Hejiang Pan,Yi Sun*

Main category: cs.RO

TL;DR: 该论文提出了一种手无关的操作转移系统，通过人类手部操作视频生成高质量的灵巧操作轨迹，解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 由于多指机器人手硬件平台收集操作数据困难且扩展性有限，导致数据稀缺，阻碍了数据驱动的灵巧操作策略学习研究。

Method: 设计了渐进式转移框架，包括基于运动学匹配的初级控制信号、动作空间重缩放和拇指引导初始化的残差策略训练，以及保留操作语义的腕部控制轨迹计算。

Result: 实验表明，该系统能自动生成平滑且语义正确的灵巧手操作，平均转移成功率达73%，具有高效性和强泛化性。

Conclusion: 该系统为收集机器人灵巧操作数据提供了一种易于实现和扩展的方法，显著提升了数据驱动的灵巧操作学习效率。

Abstract: The inherent difficulty and limited scalability of collecting manipulation data using multi-fingered robot hand hardware platforms have resulted in severe data scarcity, impeding research on data-driven dexterous manipulation policy learning. To address this challenge, we present a hand-agnostic manipulation transfer system. It efficiently converts human hand manipulation sequences from demonstration videos into high-quality dexterous manipulation trajectories without requirements of massive training data. To tackle the multi-dimensional disparities between human hands and dexterous hands, as well as the challenges posed by high-degree-of-freedom coordinated control of dexterous hands, we design a progressive transfer framework: first, we establish primary control signals for dexterous hands based on kinematic matching; subsequently, we train residual policies with action space rescaling and thumb-guided initialization to dynamically optimize contact interactions under unified rewards; finally, we compute wrist control trajectories with the objective of preserving operational semantics. Using only human hand manipulation videos, our system automatically configures system parameters for different tasks, balancing kinematic matching and dynamic optimization across dexterous hands, object categories, and tasks. Extensive experimental results demonstrate that our framework can automatically generate smooth and semantically correct dexterous hand manipulation that faithfully reproduces human intentions, achieving high efficiency and strong generalizability with an average transfer success rate of 73%, providing an easily implementable and scalable method for collecting robot dexterous manipulation data.

</details>


### [35] [Dynamic Reconfiguration of Robotic Swarms: Coordination and Control for Precise Shape Formation](https://arxiv.org/abs/2511.10989)
*Prab Prasertying,Paulo Garcia,Warisa Sritriratanarak*

Main category: cs.RO

TL;DR: 论文提出了一种用于机器人群体协调运动的算法，通过几何建模和物理控制技术实现配置间的无缝转换。


<details>
  <summary>Details</summary>
Motivation: 机器人群体运动中，个体机器人的路径规划和协调是一个复杂问题，尤其是考虑物理系统的误差和控制动态性时。论文旨在解决这一开放性问题。

Method: 提出了一种算法，利用几何建模并将其映射到物理域，结合控制、定位和地图构建技术实现路径规划和运动协调。

Result: 算法能够实现机器人群体配置间的无缝过渡，为复杂分布式行为提供了可能性。

Conclusion: 该研究为机器人群体应用开辟了新途径，支持更复杂的分布式行为表现。

Abstract: Coordination of movement and configuration in robotic swarms is a challenging endeavor. Deciding when and where each individual robot must move is a computationally complex problem. The challenge is further exacerbated by difficulties inherent to physical systems, such as measurement error and control dynamics. Thus, how to best determine the optimal path for each robot, when moving from one configuration to another, and how to best perform such determination and effect corresponding motion remains an open problem. In this paper, we show an algorithm for such coordination of robotic swarms. Our methods allow seamless transition from one configuration to another, leveraging geometric formulations that are mapped to the physical domain through appropriate control, localization, and mapping techniques. This paves the way for novel applications of robotic swarms by enabling more sophisticated distributed behaviors.

</details>


### [36] [Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation](https://arxiv.org/abs/2511.11011)
*Zhiwei Zhang,Hui Zhang,Xieyuanli Chen,Kaihong Huang,Chenghao Shi,Huimin Lu*

Main category: cs.RO

TL;DR: 提出了一种轻量级潜在空间导航世界模型（LS-NWM），通过完全在潜在空间中进行训练和操作，显著提升了计算效率，同时提高了导航性能。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖于精确的定位和地图，而现有的世界模型虽提供了新视角，但存在计算成本高的问题。

Method: 通过预测未来潜在状态并在紧凑表示中进行路径规划和决策，结合自回归多帧预测策略捕捉长时空依赖关系。

Result: 相比基线方法，训练时间减少约3.2倍，规划时间减少约447倍，同时导航成功率（SR）提升35%，路径长度效率（SPL）提升11%。

Conclusion: 该方法在计算效率和导航性能上均优于现有方法，验证了潜在空间模型的优势。

Abstract: Traditional navigation methods rely heavily on accurate localization and mapping. In contrast, world models that capture environmental dynamics in latent space have opened up new perspectives for navigation tasks, enabling systems to move beyond traditional multi-module pipelines. However, world model often suffers from high computational costs in both training and inference. To address this, we propose LS-NWM - a lightweight latent space navigation world model that is trained and operates entirely in latent space, compared to the state-of-the-art baseline, our method reduces training time by approximately 3.2x and planning time by about 447x,while further improving navigation performance with a 35% higher SR and an 11% higher SPL. The key idea is that accurate pixel-wise environmental prediction is unnecessary for navigation. Instead, the model predicts future latent states based on current observational features and action inputs, then performs path planning and decision-making within this compact representation, significantly improving computational efficiency. By incorporating an autoregressive multi-frame prediction strategy during training, the model effectively captures long-term spatiotemporal dependencies, thereby enhancing navigation performance in complex scenarios. Experimental results demonstrate that our method achieves state-of-the-art navigation performance while maintaining a substantial efficiency advantage over existing approaches.

</details>


### [37] [Miniature Testbed for Validating Multi-Agent Cooperative Autonomous Driving](https://arxiv.org/abs/2511.11022)
*Hyunchul Bae,Eunjae Lee,Jehyeop Han,Minhee Kang,Jaehyeon Kim,Junggeun Seo,Minkyun Noh,Heejin Ahn*

Main category: cs.RO

TL;DR: 论文介绍了一个1:15比例的迷你测试平台CIVAT，用于验证协作自动驾驶，填补了现有测试平台缺乏智能基础设施的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的测试平台缺乏配备感知、边缘计算和通信能力的智能基础设施，因此设计了CIVAT以支持协作自动驾驶的验证。

Method: 设计并实现了一个包括比例城市地图、自动驾驶车辆和智能基础设施的测试平台，通过Wi-Fi和ROS2框架实现V2V和V2I通信。

Result: 通过基础设施感知和交叉口管理实验验证了系统的有效性。

Conclusion: CIVAT测试平台为协作自动驾驶的研究和开发提供了有效的验证工具。

Abstract: Cooperative autonomous driving, which extends vehicle autonomy by enabling real-time collaboration between vehicles and smart roadside infrastructure, remains a challenging yet essential problem. However, none of the existing testbeds employ smart infrastructure equipped with sensing, edge computing, and communication capabilities. To address this gap, we design and implement a 1:15-scale miniature testbed, CIVAT, for validating cooperative autonomous driving, consisting of a scaled urban map, autonomous vehicles with onboard sensors, and smart infrastructure. The proposed testbed integrates V2V and V2I communication with the publish-subscribe pattern through a shared Wi-Fi and ROS2 framework, enabling information exchange between vehicles and infrastructure to realize cooperative driving functionality. As a case study, we validate the system through infrastructure-based perception and intersection management experiments.

</details>


### [38] [Simulating an Autonomous System in CARLA using ROS 2](https://arxiv.org/abs/2511.11310)
*Joseph Abdo,Aditya Shibu,Moaiz Saeed,Abdul Maajid Aga,Apsara Sivaprazad,Mohamed Al-Musleh*

Main category: cs.RO

TL;DR: 论文提出了一种用于自主赛车比赛的软件堆栈设计方法，在CARLA模拟器中实现，目标是在FS-AI 2025比赛中取得竞争力。使用了多种传感器和ROS 2系统进行实现和验证。


<details>
  <summary>Details</summary>
Motivation: 自主赛车是验证感知、规划和控制在高速及不确定性下的理想场景，尤其是针对FS-AI 2025比赛的需求。

Method: 通过360° LiDAR、立体相机、GNSS和IMU传感器结合ROS 2，设计并验证了赛道边界检测和轨迹优化算法，考虑了车辆动力学和模拟环境因素。

Result: 系统能够可靠检测35米远的赛道标志物，并在CARLA模拟器上成功验证了完整的自主堆栈。

Conclusion: 该方法为实际硬件移植提供了可行性，并通过模拟测试展示了其潜力。

Abstract: Autonomous racing offers a rigorous setting to stress test perception, planning, and control under high speed and uncertainty. This paper proposes an approach to design and evaluate a software stack for an autonomous race car in CARLA: Car Learning to Act simulator, targeting competitive driving performance in the Formula Student UK Driverless (FS-AI) 2025 competition. By utilizing a 360° light detection and ranging (LiDAR), stereo camera, global navigation satellite system (GNSS), and inertial measurement unit (IMU) sensor via ROS 2 (Robot Operating System), the system reliably detects the cones marking the track boundaries at distances of up to 35 m. Optimized trajectories are computed considering vehicle dynamics and simulated environmental factors such as visibility and lighting to navigate the track efficiently. The complete autonomous stack is implemented in ROS 2 and validated extensively in CARLA on a dedicated vehicle (ADS-DV) before being ported to the actual hardware, which includes the Jetson AGX Orin 64GB, ZED2i Stereo Camera, Robosense Helios 16P LiDAR, and CHCNAV Inertial Navigation System (INS).

</details>


### [39] [Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning](https://arxiv.org/abs/2511.11218)
*Chenhao Liu,Leyun Jiang,Yibo Wang,Kairan Yao,Jinchen Fu,Xiaoyu Ren*

Main category: cs.RO

TL;DR: 摘要提出了基于强化学习的训练流程，用于开发人形机器人羽毛球的全身控制器，实现对动态环境的高效应对。


<details>
  <summary>Details</summary>
Motivation: 现实世界是动态的，现有的准静态交互方法无法应对多样化的环境条件。研究旨在通过强化学习实现人形机器人在动态交互场景中的精确控制。

Method: 采用三阶段课程训练：先学习步法，再生成精确的球拍挥动，最后任务导向的优化。同时引入了扩展卡尔曼滤波器（EKF）预测羽毛球轨迹，并提出了无需预测的变体。

Result: 仿真中，两个机器人连续击球21次；现实测试中，击球速度达到10 m/s，平均返回落点距离3.5米。

Conclusion: 研究表明，人形机器人能够执行高动态且精确的羽毛球击球，并可推广至其他动态任务领域。

Abstract: Humanoid robots have demonstrated strong capability for interacting with deterministic scenes across locomotion, manipulation, and more challenging loco-manipulation tasks. Yet the real world is dynamic, quasi-static interactions are insufficient to cope with the various environmental conditions. As a step toward more dynamic interaction scenario, we present a reinforcement-learning-based training pipeline that produces a unified whole-body controller for humanoid badminton, enabling coordinated lower-body footwork and upper-body striking without any motion priors or expert demonstrations. Training follows a three-stage curriculum: first footwork acquisition, then precision-guided racket swing generation, and finally task-focused refinement, yielding motions in which both legs and arms serve the hitting objective. For deployment, we incorporate an Extended Kalman Filter (EKF) to estimate and predict shuttlecock trajectories for target striking. We also introduce a prediction-free variant that dispenses with EKF and explicit trajectory prediction. To validate the framework, we conduct five sets of experiment in both simulation and the real world. In simulation, two robots sustain a rally of 21 consecutive hits. Moreover, the prediction-free variant achieves successful hits with comparable performance relative to the target-known policy. In real-world tests, both the prediction and controller module exhibit high accuracy, and on-court hitting achieves an outgoing shuttle speed up to 10 m/s with a mean return landing distance of 3.5 m. These experiment results show that our humanoid robot can deliver highly dynamic while precise goal striking in badminton, and can be adapted to more dynamism critical domains.

</details>


### [40] [Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects](https://arxiv.org/abs/2511.11223)
*Sverre Herland,Amit Parag,Elling Ruud Øye,Fangyi Zhang,Fouad Makiyeh,Aleksander Lillienskiold,Abhaya Pal Singh,Edward H. Adelson,Francois Chaumette,Alexandre Krupa,Peter Corke,Ekrem Misimi*

Main category: cs.RO

TL;DR: Sashimi-Bot是一种自主多机器人系统，专注于高级操作和切割，尤其是三文鱼刺身的处理，解决变形体积物体的挑战。


<details>
  <summary>Details</summary>
Motivation: 变形体积物体（如三文鱼鱼腩）在操作中存在柔韧性、脆弱性和形状多样性等挑战，需要开发新方法以实现精确操作。

Method: 结合深度强化学习、手持工具形状操作、视觉和触觉反馈，实现三文鱼鱼腩的直线化、切割和切片拾取。

Result: 系统成功实现了对变形体积物体的精确操作和切割，展示了其在复杂环境下的鲁棒性。

Conclusion: 该研究为变形体积物体的机器人操作提供了重要里程碑，具有广泛的实际应用潜力。

Abstract: Advanced robotic manipulation of deformable, volumetric objects remains one of the greatest challenges due to their pliancy, frailness, variability, and uncertainties during interaction. Motivated by these challenges, this article introduces Sashimi-Bot, an autonomous multi-robotic system for advanced manipulation and cutting, specifically the preparation of sashimi. The objects that we manipulate, salmon loins, are natural in origin and vary in size and shape, they are limp and deformable with poorly characterized elastoplastic parameters, while also being slippery and hard to hold. The three robots straighten the loin; grasp and hold the knife; cut with the knife in a slicing motion while cooperatively stabilizing the loin during cutting; and pick up the thin slices from the cutting board or knife blade. Our system combines deep reinforcement learning with in-hand tool shape manipulation, in-hand tool cutting, and feedback of visual and tactile information to achieve robustness to the variabilities inherent in this task. This work represents a milestone in robotic manipulation of deformable, volumetric objects that may inspire and enable a wide range of other real-world applications.

</details>


### [41] [Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2511.11298)
*Yihao Zhang,Yuankai Qi,Xi Zheng*

Main category: cs.RO

TL;DR: 该论文对四种VLA模型（ACT、OpenVLA-OFT、RDT-1B和π₀）在模拟和真实机器人平台上的表现进行了实证评估，提出了标准化评估框架，发现π₀在分布外场景中适应性最强，而ACT在分布内场景中最稳定。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为实现通用机器人操作的VLA模型提供系统性评估和跨模型比较，填补该领域缺乏实证研究的空白。

Method: 通过标准化评估框架，从准确性、效率和适应性三个维度对四种VLA模型进行了模拟和真实机器人平台上的测试。

Result: 结果表明π₀在分布外场景中表现最佳，ACT在分布内稳定性最高；同时揭示了计算需求、数据扩展行为及常见失败模式的差异。

Conclusion: 结论指出了不同VLA架构在精准性、泛化性和部署成本上的权衡，为实际机器人任务中的模型选择提供了实用建议。

Abstract: Foundation models applied in robotics, particularly \textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \textbf{empirical experiences} from benchmarking four representative VLAs -- \textbf{ACT}, \textbf{OpenVLA--OFT}, \textbf{RDT-1B}, and \boldmath{$π_0$} -- across four manipulation tasks conducted in both simulation and on the \textbf{ALOHA Mobile} platform. We establish a \textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \textit{accuracy and efficiency} (success rate and time-to-success), (2) \textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \textit{language instruction-following accuracy}. Through this process, we observe that \boldmath{$π_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.

</details>


### [42] [A Comparative Evaluation of Prominent Methods in Autonomous Vehicle Certification](https://arxiv.org/abs/2511.11484)
*Mustafa Erdem Kırmızıgül,Hasan Feyzi Doğruyol,Haluk Bayram*

Main category: cs.RO

TL;DR: 本文比较分析了自动驾驶汽车认证过程中的主要方法，并提出了认证流程的框架，明确了阶段、参与方及应用领域。


<details>
  <summary>Details</summary>
Motivation: 为零愿景政策下自动驾驶汽车的安全认证提供方法论支持，解决当前认证方法和标准不明确的问题。

Method: 对认证过程中的主要方法进行比较评估，开发认证流程管道，明确各阶段、参与方及应用领域。

Result: 提出了一种系统的认证流程框架，为自动驾驶汽车的安全认证提供了清晰的方法和步骤。

Conclusion: 研究为自动驾驶汽车的认证提供了方法论和流程支持，有助于实现零愿景目标。

Abstract: The "Vision Zero" policy, introduced by the Swedish Parliament in 1997, aims to eliminate fatalities and serious injuries resulting from traffic accidents. To achieve this goal, the use of self-driving vehicles in traffic is envisioned and a roadmap for the certification of self-driving vehicles is aimed to be determined. However, it is still unclear how the basic safety requirements that autonomous vehicles must meet will be verified and certified, and which methods will be used. This paper focuses on the comparative evaluation of the prominent methods planned to be used in the certification process of autonomous vehicles. It examines the prominent methods used in the certification process, develops a pipeline for the certification process of autonomous vehicles, and determines the stages, actors, and areas where the addressed methods can be applied.

</details>


### [43] [Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities](https://arxiv.org/abs/2511.11512)
*Yiyun Zhou,Mingjing Xu,Jingwei Shi,Quanjiang Li,Jingyuan Chen*

Main category: cs.RO

TL;DR: TLV-CoRe是一种基于CLIP的触觉-语言-视觉协同表征学习方法，通过统一触觉特征和增强多模态交互，显著提升了传感器的无关表征学习和跨模态对齐。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器缺乏标准化，导致冗余特征阻碍跨传感器泛化，且多模态中间通信未充分整合，因此提出TLV-CoRe以解决这些问题。

Method: 引入传感器感知调制器统一不同传感器的触觉特征，采用触觉无关解耦学习分离无关特征，并通过统一桥接适配器增强共享表征空间内的三模态交互。

Result: 实验结果表明，TLV-CoRep50大大提升了传感器的无关表征学习和跨模态对齐。

Conclusion: TLV-CoRe为多模态触觉表征提供了新方向，通过标准化和增强交互改善了触觉-语言-视觉的协同表征。

Abstract: Tactile sensing offers rich and complementary information to vision and language, enabling robots to perceive fine-grained object properties. However, existing tactile sensors lack standardization, leading to redundant features that hinder cross-sensor generalization. Moreover, existing methods fail to fully integrate the intermediate communication among tactile, language, and vision modalities. To address this, we propose TLV-CoRe, a CLIP-based Tactile-Language-Vision Collaborative Representation learning method. TLV-CoRe introduces a Sensor-Aware Modulator to unify tactile features across different sensors and employs tactile-irrelevant decoupled learning to disentangle irrelevant tactile features. Additionally, a Unified Bridging Adapter is introduced to enhance tri-modal interaction within the shared representation space. To fairly evaluate the effectiveness of tactile models, we further propose the RSS evaluation framework, focusing on Robustness, Synergy, and Stability across different methods. Experimental results demonstrate that TLV-CoRe significantly improves sensor-agnostic representation learning and cross-modal alignment, offering a new direction for multimodal tactile representation.

</details>


### [44] [Scalable Coverage Trajectory Synthesis on GPUs as Statistical Inference](https://arxiv.org/abs/2511.11514)
*Max M. Sun,Jueun Kwon,Todd Murphey*

Main category: cs.RO

TL;DR: 提出一种基于流匹配统计推断的覆盖运动规划方法，通过解耦轨迹梯度生成与非线性系统控制的合成，显著提升并行计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在计算效率和并行化方面存在局限性，无法满足覆盖运动规划的需求。

Method: 将覆盖运动规划问题转化为流匹配视角下的统计推断问题，解耦轨迹梯度生成与非线性系统控制合成。

Result: 该方法在计算效率上显著优于基于路径点追踪的传统方法，尤其适用于GPU并行计算。

Conclusion: 该统计推断框架为覆盖运动规划提供了高效且可扩展的解决方案。

Abstract: Coverage motion planning is essential to a wide range of robotic tasks. Unlike conventional motion planning problems, which reason over temporal sequences of states, coverage motion planning requires reasoning over the spatial distribution of entire trajectories, making standard motion planning methods limited in computational efficiency and less amenable to modern parallelization frameworks. In this work, we formulate the coverage motion planning problem as a statistical inference problem from the perspective of flow matching, a generative modeling technique that has gained significant attention in recent years. The proposed formulation unifies commonly used statistical discrepancy measures, such as Kullback-Leibler divergence and Sinkhorn divergence, with a standard linear quadratic regulator problem. More importantly, it decouples the generation of trajectory gradients for coverage from the synthesis of control under nonlinear system dynamics, enabling significant acceleration through parallelization on modern computational architectures, particularly Graphics Processing Units (GPUs). This paper focuses on the advantages of this formulation in terms of scalability through parallelization, highlighting its computational benefits compared to conventional methods based on waypoint tracking.

</details>


### [45] [Scalable Policy Evaluation with Video World Models](https://arxiv.org/abs/2511.11520)
*Wei-Cheng Tseng,Jinwei Gu,Qinsheng Zhang,Hanzi Mao,Ming-Yu Liu,Florian Shkurti,Lin Yen-Chen*

Main category: cs.RO

TL;DR: 该论文探讨了利用动作条件视频生成模型作为评估机器人操作策略的可扩展方法，避免了昂贵的真实世界测试。


<details>
  <summary>Details</summary>
Motivation: 评估通用机器人操作策略在现实世界中既昂贵又耗时，且存在安全风险。传统的仿真方法需要大量工程努力且存在模拟与现实的差距。

Method: 将动作条件集成到预训练的视频生成模型中，利用互联网规模的视频数据，无需大量配对视频-动作数据的收集。

Result: 实验表明，该模型在策略排名和预测策略值与实际值相关性等多种指标上表现良好，无需真实世界交互即可评估策略。

Conclusion: 动作条件视频生成模型为机器人操作策略的评估提供了一种有前景的可扩展方法，显著减少了真实测试的需求。

Abstract: Training generalist policies for robotic manipulation has shown great promise, as they enable language-conditioned, multi-task behaviors across diverse scenarios. However, evaluating these policies remains difficult because real-world testing is expensive, time-consuming, and labor-intensive. It also requires frequent environment resets and carries safety risks when deploying unproven policies on physical robots. Manually creating and populating simulation environments with assets for robotic manipulation has not addressed these issues, primarily due to the significant engineering effort required and the often substantial sim-to-real gap, both in terms of physics and rendering. In this paper, we explore the use of action-conditional video generation models as a scalable way to learn world models for policy evaluation. We demonstrate how to incorporate action conditioning into existing pre-trained video generation models. This allows leveraging internet-scale in-the-wild online videos during the pre-training stage, and alleviates the need for a large dataset of paired video-action data, which is expensive to collect for robotic manipulation. Our paper examines the effect of dataset diversity, pre-trained weight and common failure cases for the proposed evaluation pipeline.Our experiments demonstrate that, across various metrics, including policy ranking and the correlation between actual policy values and predicted policy values, these models offer a promising approach for evaluating policies without requiring real-world interactions.

</details>


### [46] [Terrain Costmap Generation via Scaled Preference Conditioning](https://arxiv.org/abs/2511.11529)
*Luisa Mao,Garret Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: SPACER是一种新的方法，结合合成数据训练和快速测试时适应能力，生成高质量的地形成本地图，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决现有方法无法同时实现泛化到新地形和快速测试时适应的问题。

Method: 利用合成数据训练，并通过用户指定的偏好上下文快速调整成本地图。

Result: 在多种环境中，SPACER在全局路径规划中表现最佳，遗憾值最低。

Conclusion: SPACER在生成地形成本地图方面优于其他方法，具有泛化和适应能力的双重优势。

Abstract: Successful autonomous robot navigation in off-road domains requires the ability to generate high-quality terrain costmaps that are able to both generalize well over a wide variety of terrains and rapidly adapt relative costs at test time to meet mission-specific needs. Existing approaches for costmap generation allow for either rapid test-time adaptation of relative costs (e.g., semantic segmentation methods) or generalization to new terrain types (e.g., representation learning methods), but not both. In this work, we present scaled preference conditioned all-terrain costmap generation (SPACER), a novel approach for generating terrain costmaps that leverages synthetic data during training in order to generalize well to new terrains, and allows for rapid test-time adaptation of relative costs by conditioning on a user-specified scaled preference context. Using large-scale aerial maps, we provide empirical evidence that SPACER outperforms other approaches at generating costmaps for terrain navigation, with the lowest measured regret across varied preferences in five of seven environments for global path planning.

</details>


### [47] [Volumetric Ergodic Control](https://arxiv.org/abs/2511.11533)
*Jueun Kwon,Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 论文提出了一种新的体积状态表示的遍历控制方法，优化空间覆盖，提高了覆盖效率并保持了实时控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有遍历控制方法将机器人建模为无体积的点，而实际机器人通过其体积与环境交互。

Method: 引入了一种新的体积状态表示的遍历控制方法，支持任意基于采样的体积模型。

Result: 在搜索和操作任务中，新方法的覆盖效率提高了一倍以上，任务完成率保持100%，优于标准方法。

Conclusion: 新方法在实际机器人机械擦除任务中表现出色，验证了其有效性。

Abstract: Ergodic control synthesizes optimal coverage behaviors over spatial distributions for nonlinear systems. However, existing formulations model the robot as a non-volumetric point, but in practice a robot interacts with the environment through its body and sensors with physical volume. In this work, we introduce a new ergodic control formulation that optimizes spatial coverage using a volumetric state representation. Our method preserves the asymptotic coverage guarantees of ergodic control, adds minimal computational overhead for real-time control, and supports arbitrary sample-based volumetric models. We evaluate our method across search and manipulation tasks -- with multiple robot dynamics and end-effector geometries or sensor models -- and show that it improves coverage efficiency by more than a factor of two while maintaining a 100% task completion rate across all experiments, outperforming the standard ergodic control method. Finally, we demonstrate the effectiveness of our method on a robot arm performing mechanical erasing tasks.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [48] [LT-Soups: Bridging Head and Tail Classes via Subsampled Model Soups](https://arxiv.org/abs/2511.10683)
*Masih Aminbeidokhti,Subhankar Roy,Eric Granger,Elisa Ricci,Marco Pedersoli*

Main category: cs.LG

TL;DR: 论文分析了参数高效微调（PEFT）方法在长尾分布数据集上的表现，并提出了一种两阶段模型集成框架LT-Soups以改善性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据集通常呈现长尾分布，现有PEFT方法虽能保持尾部类别的性能，但会牺牲头部类别的准确性。论文旨在研究这种权衡并提出改进方案。

Method: 通过控制实验研究不同不平衡比例和头尾比例的影响，并提出LT-Soups框架，分两个阶段：第一阶段对平衡子集微调并平均模型以减少头部类别偏差；第二阶段仅在完整数据集上微调分类器以恢复头部类别准确性。

Result: 实验表明，LT-Soups在多种长尾场景下优于PEFT和传统模型集成方法。

Conclusion: LT-Soups能够有效平衡头部和尾部类别的准确性，适用于不同不平衡比例的数据集。

Abstract: Real-world datasets typically exhibit long-tailed (LT) distributions, where a few head classes dominate and many tail classes are severely underrepresented. While recent work shows that parameter-efficient fine-tuning (PEFT) methods like LoRA and AdaptFormer preserve tail-class performance on foundation models such as CLIP, we find that they do so at the cost of head-class accuracy. We identify the head-tail ratio, the proportion of head to tail classes, as a crucial but overlooked factor influencing this trade-off. Through controlled experiments on CIFAR100 with varying imbalance ratio ($ρ$) and head-tail ratio ($η$), we show that PEFT excels in tail-heavy scenarios but degrades in more balanced and head-heavy distributions. To overcome these limitations, we propose LT-Soups, a two-stage model soups framework designed to generalize across diverse LT regimes. In the first stage, LT-Soups averages models fine-tuned on balanced subsets to reduce head-class bias; in the second, it fine-tunes only the classifier on the full dataset to restore head-class accuracy. Experiments across six benchmark datasets show that LT-Soups achieves superior trade-offs compared to both PEFT and traditional model soups across a wide range of imbalance regimes.

</details>


### [49] [Differentiable Sparse Identification of Lagrangian Dynamics](https://arxiv.org/abs/2511.10706)
*Zitong Zhang,Hao Sun*

Main category: cs.LG

TL;DR: 论文提出了一种新的可微分稀疏识别框架，通过三次B样条逼近等方法，提高了从噪声数据中提取物理规律的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的控制方程发现是非线性动力学中的基本挑战，现有方法在复杂机械系统中对噪声敏感且难以处理有理函数。拉格朗日形式主义提供了更简洁的系统动力学表示，但现有方法受测量噪声和数据限制影响较大。

Method: 论文提出了三个关键贡献：1）首次将三次B样条逼近集成到拉格朗日系统识别中；2）利用已知物理约束构建鲁棒的方程发现机制；3）基于B样条基函数的递归导数计算方案，降低噪声敏感性。

Result: 该方法在复杂机械系统中表现出优越性能，能更准确可靠地从噪声数据中提取物理定律。

Conclusion: 通过新框架，拉格朗日系统识别在噪声环境下的鲁棒性和准确性显著提高，为复杂非线性动力学系统的建模提供了更可靠的工具。

Abstract: Data-driven discovery of governing equations from data remains a fundamental challenge in nonlinear dynamics. Although sparse regression techniques have advanced system identification, they struggle with rational functions and noise sensitivity in complex mechanical systems. The Lagrangian formalism offers a promising alternative, as it typically avoids rational expressions and provides a more concise representation of system dynamics. However, existing Lagrangian identification methods are significantly affected by measurement noise and limited data availability. This paper presents a novel differentiable sparse identification framework that addresses these limitations through three key contributions: (1) the first integration of cubic B-Spline approximation into Lagrangian system identification, enabling accurate representation of complex nonlinearities, (2) a robust equation discovery mechanism that effectively utilizes measurements while incorporating known physical constraints, (3) a recursive derivative computation scheme based on B-spline basis functions, effectively constraining higher-order derivatives and reducing noise sensitivity on second-order dynamical systems. The proposed method demonstrates superior performance and enables more accurate and reliable extraction of physical laws from noisy data, particularly in complex mechanical systems compared to baseline methods.

</details>


### [50] [Bias-Restrained Prefix Representation Finetuning for Mathematical Reasoning](https://arxiv.org/abs/2511.10707)
*Sirui Liang,Pengfei Cao,Jian Zhao,Cong Huang,Jun Zhao,Kang Liu*

Main category: cs.LG

TL;DR: BREP ReFT通过优化初始推理前缀生成、干预早期推理阶段以防止错误累积，并约束干预向量幅度，显著提升了数学推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决ReFT在数学推理任务中性能下降的问题，本研究揭示了ReFT在早期推理阶段生成无效前缀和干扰数值编码的根源。

Method: BREP ReFT通过截断训练数据优化初始前缀生成，干预早期推理阶段防止错误累积，并约束干预向量幅度以保护数值编码。

Result: 实验表明，BREP ReFT在数学推理任务上优于标准ReFT和基于权重的PEFT方法，具有更高的效率和泛化能力。

Conclusion: BREP ReFT为提升数学推理任务的性能提供了一种高效且鲁棒的方法。

Abstract: Parameter-Efficient finetuning (PEFT) enhances model performance on downstream tasks by updating a minimal subset of parameters. Representation finetuning (ReFT) methods further improve efficiency by freezing model weights and optimizing internal representations with fewer parameters than PEFT, outperforming PEFT on several tasks. However, ReFT exhibits a significant performance decline on mathematical reasoning tasks. To address this problem, the paper demonstrates that ReFT's poor performance on mathematical tasks primarily stems from its struggle to generate effective reasoning prefixes during the early inference phase. Moreover, ReFT disturbs the numerical encoding and the error accumulats during the CoT stage. Based on these observations, this paper proposes Bias-REstrained Prefix Representation FineTuning (BREP ReFT), which enhances ReFT's mathematical reasoning capability by truncating training data to optimize the generation of initial reasoning prefixes, intervening on the early inference stage to prevent error accumulation, and constraining the intervention vectors' magnitude to avoid disturbing numerical encoding. Extensive experiments across diverse model architectures demonstrate BREP's superior effectiveness, efficiency, and robust generalization capability, outperforming both standard ReFT and weight-based PEFT methods on the task of mathematical reasoning. The source code is available at https://github.com/LiangThree/BREP.

</details>


### [51] [Towards Uncertainty Quantification in Generative Model Learning](https://arxiv.org/abs/2511.10710)
*Giorgio Morales,Frederic Jurie,Jalal Fadili*

Main category: cs.LG

TL;DR: 本文探讨了生成模型学习中不确定性量化的必要性，提出了包括基于集成精度-召回曲线的研究方法，并通过合成数据集验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成模型在不同领域的应用日益广泛，但其可靠性问题尚未得到充分研究。现有评估方法主要关注学习分布与目标分布的接近程度，而忽略了这些测量中的不确定性。

Method: 通过集成精度-召回曲线等方法，量化生成模型学习中的不确定性，并在合成数据集上进行初步实验验证。

Result: 实验结果表明，聚合精度-召回曲线能有效捕捉模型逼近的不确定性，从而对不同架构的模型进行系统比较。

Conclusion: 本文为生成模型学习中的不确定性量化问题提供了新的研究方向和初步验证，为未来研究奠定了基础。

Abstract: While generative models have become increasingly prevalent across various domains, fundamental concerns regarding their reliability persist. A crucial yet understudied aspect of these models is the uncertainty quantification surrounding their distribution approximation capabilities. Current evaluation methodologies focus predominantly on measuring the closeness between the learned and the target distributions, neglecting the inherent uncertainty in these measurements. In this position paper, we formalize the problem of uncertainty quantification in generative model learning. We discuss potential research directions, including the use of ensemble-based precision-recall curves. Our preliminary experiments on synthetic datasets demonstrate the effectiveness of aggregated precision-recall curves in capturing model approximation uncertainty, enabling systematic comparison among different model architectures based on their uncertainty characteristics.

</details>


### [52] [Movement-Specific Analysis for FIM Score Classification Using Spatio-Temporal Deep Learning](https://arxiv.org/abs/2511.10713)
*Jun Masaki,Ariaki Higashi,Naoko Shinagawa,Kazuhiko Hirata,Yuichi Kurita,Akira Furui*

Main category: cs.LG

TL;DR: 提出了自动FIM评分估计方法，通过深度学习架构结合ST-GCN、BiLSTM和注意力机制分析简单运动来预测患者日常生活活动独立性。


<details>
  <summary>Details</summary>
Motivation: 传统FIM评估对患者和医疗专业人员负担重，需要更高效的方法。

Method: 采用ST-GCN、BiLSTM和注意力机制的深度学习架构，分析简单运动的时空特征。

Result: 模型能区分完全独立和需要辅助的患者，平衡准确率为70.09-78.79%。

Conclusion: 方法有效减少了FIM评估负担，并为特定FIM评分提供了可靠的预测依据。

Abstract: The functional independence measure (FIM) is widely used to evaluate patients' physical independence in activities of daily living. However, traditional FIM assessment imposes a significant burden on both patients and healthcare professionals. To address this challenge, we propose an automated FIM score estimation method that utilizes simple exercises different from the designated FIM assessment actions. Our approach employs a deep neural network architecture integrating a spatial-temporal graph convolutional network (ST-GCN), bidirectional long short-term memory (BiLSTM), and an attention mechanism to estimate FIM motor item scores. The model effectively captures long-term temporal dependencies and identifies key body-joint contributions through learned attention weights. We evaluated our method in a study of 277 rehabilitation patients, focusing on FIM transfer and locomotion items. Our approach successfully distinguishes between completely independent patients and those requiring assistance, achieving balanced accuracies of 70.09-78.79 % across different FIM items. Additionally, our analysis reveals specific movement patterns that serve as reliable predictors for particular FIM evaluation items.

</details>


### [53] [Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions](https://arxiv.org/abs/2511.10809)
*Jiazhou Liang,Hassan Khurram,Scott Sanner*

Main category: cs.LG

TL;DR: 论文摘要介绍了两种改进线性预测聚类（LPC）全局优化效率的新方法，通过利用可分离性的理论特性，显著提升了计算效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有贪婪优化方法在非可分离场景下效果不佳，而混合整数规划（MIP）方法虽能保证全局最优但计算效率低。本文旨在解决这些问题。

Method: 论文提出了两种新方法：基于可分离性的近似优化和将LPC转化为二次伪布尔优化（QPBO）问题，以减少计算复杂性。

Result: 在合成和实际数据集上的实验表明，新方法在回归误差和可扩展性方面优于贪婪优化和传统MIP方法。

Conclusion: 新方法在保持全局优化优势的同时显著提升了计算效率，适用于广泛的LPC应用场景。

Abstract: Linear Predictive Clustering (LPC) partitions samples based on shared linear relationships between feature and target variables, with numerous applications including marketing, medicine, and education. Greedy optimization methods, commonly used for LPC, alternate between clustering and linear regression but lack global optimality. While effective for separable clusters, they struggle in non-separable settings where clusters overlap in feature space. In an alternative constrained optimization paradigm, Bertsimas and Shioda (2007) formulated LPC as a Mixed-Integer Program (MIP), ensuring global optimality regardless of separability but suffering from poor scalability. This work builds on the constrained optimization paradigm to introduce two novel approaches that improve the efficiency of global optimization for LPC. By leveraging key theoretical properties of separability, we derive near-optimal approximations with provable error bounds, significantly reducing the MIP formulation's complexity and improving scalability. Additionally, we can further approximate LPC as a Quadratic Pseudo-Boolean Optimization (QPBO) problem, achieving substantial computational improvements in some settings. Comparative analyses on synthetic and real-world datasets demonstrate that our methods consistently achieve near-optimal solutions with substantially lower regression errors than greedy optimization while exhibiting superior scalability over existing MIP formulations.

</details>


### [54] [Transformers know more than they can tell -- Learning the Collatz sequence](https://arxiv.org/abs/2511.10811)
*François Charton,Ashvni Narayanan*

Main category: cs.LG

TL;DR: 研究使用Transformer预测Collatz序列的长步骤，发现模型在不同进制下的准确率差异显著，且学习过程中遵循共同的模式，反映了数学性质。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer模型在复杂算术函数（如Collatz序列）中的预测能力，并理解其学习机制和数学基础。

Method: 通过不同进制编码输入和输出，训练Transformer模型预测Collatz序列的长步骤，并分析其学习模式和失败案例。

Result: 模型在高进制（如24和32）下准确率高达99.7%，低进制（如11和3）下低至25%-37%。几乎所有错误均与循环长度估计相关。

Conclusion: 模型通过学习输入的分组（按模2^p分类）和循环长度来控制计算结构，表明该方法可为改进语言模型提供新思路。

Abstract: We investigate transformer prediction of long Collatz steps, a complex arithmetic function that maps odd integers to their distant successors in the Collatz sequence ( $u_{n+1}=u_n/2$ if $u_n$ is even, $u_{n+1}=(3u_n+1)/2$ if $u_n$ is odd). Model accuracy varies with the base used to encode input and output. It can be as high as $99.7\%$ for bases $24$ and $32$, and as low as $37$ and $25\%$ for bases $11$ and $3$. Yet, all models, no matter the base, follow a common learning pattern. As training proceeds, they learn a sequence of classes of inputs that share the same residual modulo $2^p$. Models achieve near-perfect accuracy on these classes, and less than $1\%$ for all other inputs. This maps to a mathematical property of Collatz sequences: the length of the loops involved in the computation of a long Collatz step can be deduced from the binary representation of its input. The learning pattern reflects the model learning to predict inputs associated with increasing loop lengths. An analysis of failure cases reveals that almost all model errors follow predictable patterns. Hallucination, a common feature of large language models, almost never happens. In over $90\%$ of failures, the model performs the correct calculation, but wrongly estimates loop lengths. Our observations give a full account of the algorithms learned by the models. They suggest that the difficulty of learning such complex arithmetic function lies in figuring the control structure of the computation -- the length of the loops. We believe that the approach outlined here, using mathematical problems as tools for understanding, explaining, and perhaps improving language models, can be applied to a broad range of problems and bear fruitful results.

</details>


### [55] [Towards Universal Neural Operators through Multiphysics Pretraining](https://arxiv.org/abs/2511.10829)
*Mikhail Masliaev,Dmitry Gusarov,Ilya Markov,Alexander Hvatov*

Main category: cs.LG

TL;DR: 论文研究了基于Transformer的神经算子在PDE问题中的迁移学习性能，展示了其在参数外推、新变量引入和多方程数据集迁移中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于神经算子在数据驱动的物理模拟中训练成本高，研究通过下游学习（预训练后微调）来改进这一问题，扩展了Transformer类神经算子的应用范围。

Method: 采用基于Transformer的神经算子，在多种PDE问题中进行评估，包括参数外推、新变量引入和多方程数据集迁移。

Result: 结果表明，先进的神经算子架构能够有效地在PDE问题间迁移知识。

Conclusion: 研究扩展了Transformer类神经算子在迁移学习中的应用潜力，为降低训练成本提供了有效途径。

Abstract: Although neural operators are widely used in data-driven physical simulations, their training remains computationally expensive. Recent advances address this issue via downstream learning, where a model pretrained on simpler problems is fine-tuned on more complex ones. In this research, we investigate transformer-based neural operators, which have previously been applied only to specific problems, in a more general transfer learning setting. We evaluate their performance across diverse PDE problems, including extrapolation to unseen parameters, incorporation of new variables, and transfer from multi-equation datasets. Our results demonstrate that advanced neural operator architectures can effectively transfer knowledge across PDE problems.

</details>


### [56] [Benchmarking Quantum Kernels Across Diverse and Complex Data](https://arxiv.org/abs/2511.10831)
*Yuhan Jiang,Matthew Otten*

Main category: cs.LG

TL;DR: 论文研究了量子核方法在真实世界高维数据上的性能优势，通过资源高效的变分量子核框架和参数缩放技术，在多种复杂数据集上验证了其优于经典核方法的表现。


<details>
  <summary>Details</summary>
Motivation: 探索量子核方法在真实世界高维数据上的实用潜力，填补现有研究在低维或合成数据上的局限。

Method: 提出了一种资源高效的变分量子核框架，并引入参数缩放技术以加速收敛，在八类复杂数据集上进行了全面测试。

Result: 量子核在多种真实世界数据集上表现优于经典核方法（如RBF核），证明了其在现实机器学习中的潜力。

Conclusion: 合理设计的量子核可以作为高性能工具，但需进一步研究以完全评估其实际量子优势。

Abstract: Quantum kernel methods are a promising branch of quantum machine learning, yet their practical advantage on diverse, high-dimensional, real-world data remains unverified. Current research has largely been limited to low-dimensional or synthetic datasets, preventing a thorough evaluation of their potential. To address this gap, we developed a variational quantum kernel framework utilizing resource-efficient ansätze for complex classification tasks and introduced a parameter scaling technique to accelerate convergence. We conducted a comprehensive benchmark of this framework on eight challenging, real world and high-dimensional datasets covering tabular, image, time series, and graph data. Our classically simulated results show that the proposed quantum kernel demonstrated a clear performance advantage over standard classical kernels, such as the radial basis function (RBF) kernel. This work demonstrates that properly designed quantum kernels can function as versatile, high-performance tools, laying a foundation for quantum-enhanced applications in real-world machine learning. Further research is needed to fully assess the practical quantum advantage.

</details>


### [57] [SURFACEBENCH: Can Self-Evolving LLMs Find the Equations of 3D Scientific Surfaces?](https://arxiv.org/abs/2511.10833)
*Sanchit Kabra,Shobhnik Kriplani,Parshin Shojaee,Chandan K. Reddy*

Main category: cs.LG

TL;DR: SurfaceBench是一个全面的符号曲面发现基准，包含183个任务，涵盖多种符号复杂性和表示形式，旨在解决现有符号回归方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有符号回归方法依赖于记忆公式或简化功能形式的局限性，并提供一个更科学、更全面的评估标准。

Method: 引入SurfaceBench基准，包含183个任务，覆盖15类符号复杂性，结合符号检查和几何感知指标（如Chamfer和Hausdorff距离）进行评估。

Result: 实验表明，现有最先进的方法在特定类别上可能成功，但在跨表示类型和曲面复杂性的泛化能力上表现不足。

Conclusion: SurfaceBench为符号推理与几何重建的结合提供了一个具有挑战性的测试平台，推动了组合泛化、数据驱动科学归纳和LLM几何感知推理的研究。

Abstract: Equation discovery from data is a core challenge in machine learning for science, requiring the recovery of concise symbolic expressions that govern complex physical and geometric phenomena. Recent approaches with large language models (LLMs) show promise in symbolic regression, but their success often hinges on memorized formulas or overly simplified functional forms. Existing benchmarks exacerbate this limitation: they focus on scalar functions, ignore domain grounding, and rely on brittle string-matching based metrics that fail to capture scientific equivalence. We introduce SurfaceBench, first comprehensive benchmark for symbolic surface discovery. SurfaceBench comprises 183 tasks across 15 categories of symbolic complexity, spanning explicit, implicit, and parametric equation representation forms. Each task includes ground-truth equations, variable semantics, and synthetically sampled three dimensional data. Unlike prior SR datasets, our tasks reflect surface-level structure, resist LLM memorization through novel symbolic compositions, and are grounded in scientific domains such as fluid dynamics, robotics, electromagnetics, and geometry. To evaluate equation discovery quality, we pair symbolic checks with geometry-aware metrics such as Chamfer and Hausdorff distances, capturing both algebraic fidelity and spatial reconstruction accuracy. Our experiments reveal that state-of-the-art frameworks, while occasionally successful on specific families, struggle to generalize across representation types and surface complexities. SurfaceBench thus establishes a challenging and diagnostic testbed that bridges symbolic reasoning with geometric reconstruction, enabling principled benchmarking of progress in compositional generalization, data-driven scientific induction, and geometry-aware reasoning with LLMs. We release the code here: https://github.com/Sanchit-404/surfacebench

</details>


### [58] [The Map of Misbelief: Tracing Intrinsic and Extrinsic Hallucinations Through Attention Patterns](https://arxiv.org/abs/2511.10837)
*Elyes Hajji,Aymen Bouguerra,Fabio Arnez*

Main category: cs.LG

TL;DR: 提出了一个区分外在和内在幻觉类别的评估框架，并提出了一种基于注意力的不确定性量化方法，改进了幻觉检测的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在安全关键领域应用广泛，但易产生幻觉。现有方法多为计算昂贵的采样策略，且未区分幻觉类型。

Method: 引入评估框架区分幻觉类型，利用注意力不确定性量化算法，并提出新颖的注意力聚合策略。

Result: 采样方法适用于检测外在幻觉，但对内在幻觉效果差；基于注意力聚合的方法更适合内在幻觉检测。

Conclusion: 注意力是量化模型不确定性的重要信号，为幻觉检测策略提供了新的方向。

Abstract: Large Language Models (LLMs) are increasingly deployed in safety-critical domains, yet remain susceptible to hallucinations. While prior works have proposed confidence representation methods for hallucination detection, most of these approaches rely on computationally expensive sampling strategies and often disregard the distinction between hallucination types. In this work, we introduce a principled evaluation framework that differentiates between extrinsic and intrinsic hallucination categories and evaluates detection performance across a suite of curated benchmarks. In addition, we leverage a recent attention-based uncertainty quantification algorithm and propose novel attention aggregation strategies that improve both interpretability and hallucination detection performance. Our experimental findings reveal that sampling-based methods like Semantic Entropy are effective for detecting extrinsic hallucinations but generally fail on intrinsic ones. In contrast, our method, which aggregates attention over input tokens, is better suited for intrinsic hallucinations. These insights provide new directions for aligning detection strategies with the nature of hallucination and highlight attention as a rich signal for quantifying model uncertainty.

</details>


### [59] [FlowPath: Learning Data-Driven Manifolds with Invertible Flows for Robust Irregularly-sampled Time Series Classification](https://arxiv.org/abs/2511.10841)
*YongKyung Oh,Dong-Young Lim,Sungil Kim*

Main category: cs.LG

TL;DR: 提出FlowPath方法，通过可逆神经流学习控制路径的几何形状，解决了传统插值方法在稀疏和不规则采样时间序列建模中的不足，显著提升了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理稀疏和不规则采样时间序列时，通常使用固定的插值方案，这会导致对底层数据流形的错误表示，尤其是在数据缺失率高的情况下。

Method: FlowPath利用可逆神经流学习控制路径的几何形状，构建连续且数据自适应的流形，并通过可逆性约束确保信息保留和良好行为变换。

Result: 在18个基准数据集和一个真实案例中，FlowPath在分类准确性上显著优于基于固定插值或非可逆架构的基线方法。

Conclusion: FlowPath不仅建模路径上的动态，还建模路径本身的几何形状，为从不规则时间序列中学习提供了稳健且通用的解决方案。

Abstract: Modeling continuous-time dynamics from sparse and irregularly-sampled time series remains a fundamental challenge. Neural controlled differential equations provide a principled framework for such tasks, yet their performance is highly sensitive to the choice of control path constructed from discrete observations. Existing methods commonly employ fixed interpolation schemes, which impose simplistic geometric assumptions that often misrepresent the underlying data manifold, particularly under high missingness. We propose FlowPath, a novel approach that learns the geometry of the control path via an invertible neural flow. Rather than merely connecting observations, FlowPath constructs a continuous and data-adaptive manifold, guided by invertibility constraints that enforce information-preserving and well-behaved transformations. This inductive bias distinguishes FlowPath from prior unconstrained learnable path models. Empirical evaluations on 18 benchmark datasets and a real-world case study demonstrate that FlowPath consistently achieves statistically significant improvements in classification accuracy over baselines using fixed interpolants or non-invertible architectures. These results highlight the importance of modeling not only the dynamics along the path but also the geometry of the path itself, offering a robust and generalizable solution for learning from irregular time series.

</details>


### [60] [Multistability of Self-Attention Dynamics in Transformers](https://arxiv.org/abs/2511.11553)
*Claudio Altafini*

Main category: cs.LG

TL;DR: 论文研究了自注意力机制在连续时间多主体模型中的动力学行为，将其与多主体版的Oja流联系起来，并分类了其平衡点的类型。


<details>
  <summary>Details</summary>
Motivation: 探索自注意力动力学在多主体模型中的行为及其与Oja流的关系，以理解其平衡点的性质和稳定性。

Method: 通过分析自注意力系统的动力学，将其与Oja流进行比较，并分类平衡点为共识、二分共识、聚类和多边形平衡点四类。

Result: 发现自注意力动态中存在多种渐进稳定的平衡点，其中前两类平衡点通常与值矩阵的特征向量对齐。

Conclusion: 自注意力动力学展示了丰富的平衡行为，且某些平衡点与值矩阵的特征向量密切相关，为理解其计算特性提供了新视角。

Abstract: In machine learning, a self-attention dynamics is a continuous-time multiagent-like model of the attention mechanisms of transformers. In this paper we show that such dynamics is related to a multiagent version of the Oja flow, a dynamical system that computes the principal eigenvector of a matrix corresponding for transformers to the value matrix. We classify the equilibria of the ``single-head'' self-attention system into four classes: consensus, bipartite consensus, clustering and polygonal equilibria. Multiple asymptotically stable equilibria from the first three classes often coexist in the self-attention dynamics. Interestingly, equilibria from the first two classes are always aligned with the eigenvectors of the value matrix, often but not exclusively with the principal eigenvector.

</details>


### [61] [Behaviour Policy Optimization: Provably Lower Variance Return Estimates for Off-Policy Reinforcement Learning](https://arxiv.org/abs/2511.10843)
*Alexander W. Goodall,Edwin Hamel-De le Court,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 论文提出利用行为策略收集离线数据以降低回报估计的方差，从而提高强化学习算法的样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于高方差的回报估计导致强化学习算法的样本效率和训练稳定性较差，作者希望通过设计良好的行为策略来解决这一问题。

Method: 通过扩展离线策略评估的新成果，将行为策略用于收集离线数据以降低方差，并将其应用于在线强化学习设置中。实验中对两种策略梯度方法进行了扩展。

Result: 实验表明，该方法在多样化的环境中表现出更好的样本效率和性能。

Conclusion: 利用行为策略收集离线数据可以显著降低回报估计的方差，从而提高强化学习的样本效率和性能。

Abstract: Many reinforcement learning algorithms, particularly those that rely on return estimates for policy improvement, can suffer from poor sample efficiency and training instability due to high-variance return estimates. In this paper we leverage new results from off-policy evaluation; it has recently been shown that well-designed behaviour policies can be used to collect off-policy data for provably lower variance return estimates. This result is surprising as it means collecting data on-policy is not variance optimal. We extend this key insight to the online reinforcement learning setting, where both policy evaluation and improvement are interleaved to learn optimal policies. Off-policy RL has been well studied (e.g., IMPALA), with correct and truncated importance weighted samples for de-biasing and managing variance appropriately. Generally these approaches are concerned with reconciling data collected from multiple workers in parallel, while the policy is updated asynchronously, mismatch between the workers and policy is corrected in a mathematically sound way. Here we consider only one worker - the behaviour policy, which is used to collect data for policy improvement, with provably lower variance return estimates. In our experiments we extend two policy-gradient methods with this regime, demonstrating better sample efficiency and performance over a diverse set of environments.

</details>


### [62] [STAMP: Spatial-Temporal Adapter with Multi-Head Pooling](https://arxiv.org/abs/2511.10848)
*Brad Shook,Abby Turner,Jieshi Chen,Michał Wiliński,Mononito Goswami,Jonathan Elmer,Artur Dubrawski*

Main category: cs.LG

TL;DR: 论文提出了一种名为STAMP的轻量级空间-时间适配器，利用通用时间序列基础模型（TSFMs）的单变量嵌入，隐式建模EEG数据的时空特性，并在多个临床任务数据集上实现了与最先进EEG专用基础模型（EEGFMs）相当的性能。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对EEG专用基础模型（EEGFMs）与通用时间序列基础模型（TSFMs）在EEG特定任务上的比较分析。为了利用通用TSFMs的能力并适应EEG数据的特性，作者提出了STAMP适配器。

Method: 引入了STAMP（Spatial-Temporal Adapter with Multi-Head Pooling），结合TSFMs的单变量嵌入，隐式建模EEG数据的空间-时间特性，并通过多头部池化提升性能。

Result: 在8个临床任务基准数据集上的实验表明，STAMP的性能与最先进的EEGFMs相当，同时具有轻量化和灵活性的优势。

Conclusion: STAMP为利用通用TSFMs处理EEG数据提供了高效且灵活的方法，扩展了TSFMs在脑电信号领域的应用潜力。

Abstract: Time series foundation models (TSFMs) pretrained on data from multiple domains have shown strong performance on diverse modeling tasks. Various efforts have been made to develop foundation models specific to electroencephalography (EEG) data, which records brain electrical activity as time series. However, no comparative analysis of EEG-specific foundation models (EEGFMs) versus general TSFMs has been performed on EEG-specific tasks. We introduce a novel Spatial-Temporal Adapter with Multi-Head Pooling (STAMP), which leverages univariate embeddings produced by a general TSFM, implicitly models spatial-temporal characteristics of EEG data, and achieves performance comparable to state-of-the-art EEGFMs. A comprehensive analysis is performed on 8 benchmark datasets of clinical tasks using EEG for classification, along with ablation studies. Our proposed adapter is lightweight in trainable parameters and flexible in the inputs it can accommodate, supporting easy modeling of EEG data using TSFMs.

</details>


### [63] [ExPairT-LLM: Exact Learning for LLM Code Selection by Pairwise Queries](https://arxiv.org/abs/2511.10855)
*Tom Yuviler,Dana Drachsler-Cohen*

Main category: cs.LG

TL;DR: ExPairT-LLM是一种精确学习算法，通过向LLM提出两种新型查询（成对成员关系和成对等价）来选择最佳程序，显著提高了代码生成的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有代码选择算法可能因误判非等价程序或依赖LLM的错误输出而失效，因此需要一种更可靠的方法来选择正确的程序。

Method: ExPairT-LLM提出两种新型查询（成对成员关系和成对等价），通过锦标赛方式选择程序，对LLM的某些错误具有鲁棒性。

Result: 在四个流行的代码数据集上，ExPairT-LLM的pass@1比现有最佳算法平均高13.0%，最高达27.1%，并将LLM复杂推理的pass@1提高了24.0%。

Conclusion: ExPairT-LLM通过简化查询和锦标赛机制，显著提升了代码选择的准确性和鲁棒性。

Abstract: Despite recent advances in LLMs, the task of code generation is still challenging. To cope, code selection algorithms select the best program from multiple programs generated by an LLM. However, existing algorithms can fail to identify the correct program, either because they can misidentify nonequivalent programs or because they rely on an LLM and assume it always correctly determines the output for every input. We present ExPairT-LLM, an exact learning algorithm for code selection that selects a program by posing to an LLM oracle two new types of queries: pairwise membership and pairwise equivalence. These queries are simpler for LLMs and enable ExPairT-LLM to identify the correct program through a tournament, which is robust to some LLM mistakes. We evaluate ExPairT-LLM on four popular code datasets. Its pass@1 (success rate) outperforms the state-of-the-art code selection algorithm on average by +13.0% and up to +27.1%. It also improves the pass@1 of LLMs performing complex reasoning by +24.0%.

</details>


### [64] [Private Zeroth-Order Optimization with Public Data](https://arxiv.org/abs/2511.10859)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 该论文提出了一种利用公开数据辅助的零阶差分隐私优化方法（PAZO），以降低计算和内存成本，同时在高度隐私保护的情况下实现更高的性能。


<details>
  <summary>Details</summary>
Motivation: 当前一阶差分隐私机器学习算法（如DP-SGD）存在计算和内存成本高的问题，而零阶方法虽能降低开销但性能较差。论文旨在利用公开数据提升零阶差分隐私算法的梯度近似能力。

Method: 提出PAZO框架，通过公开数据指导并改进零阶差分隐私优化器的梯度近似，减少开销，并提供理论分析支持。

Result: 实验表明，PAZO在视觉和文本任务中显著优于一阶基线方法（尤其在高隐私保护场景），同时实现了最高16倍的运行速度提升。

Conclusion: PAZO为差分隐私机器学习提供了一种高效且实用的解决方案，能够在保护隐私的同时显著提升性能。

Abstract: One of the major bottlenecks for deploying popular first-order differentially private (DP) machine learning algorithms (e.g., DP-SGD) lies in their high computation and memory cost, despite the existence of optimized implementations. Zeroth-order methods have promise in mitigating the overhead, as they leverage function evaluations to approximate the gradients, hence significantly easier to privatize. While recent works have explored zeroth-order approaches in both private and non-private settings, they still suffer from relatively low utilities compared with DP-SGD, and have only been evaluated in limited application domains. In this work, we propose to leverage public information to guide and improve gradient approximation of private zeroth-order algorithms. We explore a suite of public-data-assisted zeroth-order optimizers (PAZO) with minimal overhead. We provide theoretical analyses of the PAZO framework under an assumption of the similarity between public and private data. Empirically, we demonstrate that PAZO achieves superior privacy/utility tradeoffs across vision and text tasks in both pre-training and fine-tuning settings, outperforming the best first-order baselines (with public data) especially in highly private regimes, while offering up to $16\times$ runtime speedup.

</details>


### [65] [Go-UT-Bench: A Fine-Tuning Dataset for LLM-Based Unit Test Generation in Go](https://arxiv.org/abs/2511.10868)
*Yashshi Pipalani,Hritik Raj,Rajat Ghosh,Vaishnavi Bhargava,Debojyoti Dutta*

Main category: cs.LG

TL;DR: 论文提出了GO UT Bench，一个包含5264对代码和单元测试的基准数据集，用于解决代码LLM训练数据不平衡的问题，特别是在低资源语言如Golang中。微调后的模型在75%的任务中表现优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有的代码LLM训练数据不平衡，主要偏向开源代码，而低估了更广泛的软件工程任务（如单元测试生成）的重要性，尤其是在低资源语言中。

Method: 作者引入了GO UT Bench数据集，包含来自10个不同领域的Golang仓库的代码和单元测试对，并评估了其在两个LLM家族（混合专家和密集解码器）上的微调效果。

Result: 微调后的模型在超过75%的基准任务中表现优于基础模型。

Conclusion: GO UT Bench为解决代码LLM在低资源语言中训练数据不平衡的问题提供了有效的数据支持，并能显著提升模型在单元测试生成等任务中的表现。

Abstract: Training data imbalance poses a major challenge for code LLMs. Most available data heavily over represents raw opensource code while underrepresenting broader software engineering tasks, especially in low resource languages like Golang. As a result, models excel at code autocompletion but struggle with real world developer workflows such as unit test generation. To address this gap, we introduce GO UT Bench, a benchmark dataset of 5264 pairs of code and unit tests, drawn from 10 permissively licensed Golang repositories spanning diverse domain. We evaluate its effectiveness as a fine tuning dataset across two LLM families i.e. mixture of experts and dense decoders. Our results show that finetuned models outperform their base counterparts on more than 75% of benchmark tasks.

</details>


### [66] [Incorporating Spatial Information into Goal-Conditioned Hierarchical Reinforcement Learning via Graph Representations](https://arxiv.org/abs/2511.10872)
*Shuyuan Zhang,Zihan Wang,Xiao-Wen Chang,Doina Precup*

Main category: cs.LG

TL;DR: 论文提出了一种名为G4RL的方法，通过图编码器-解码器评估未见状态，解决了现有图导向分层强化学习中的样本效率低和子目标表示不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前图导向分层强化学习方法依赖于领域特定知识构建图，或动态生成图但信息传递不足，导致适用范围受限且性能不佳。

Method: 开发了一种图编码器-解码器，利用探索期间生成的状态图进行训练，并结合高低层内在奖励提升性能。

Result: 实验结果表明，G4RL方法在密集和稀疏奖励环境中显著提升了现有先进方法的性能，且计算成本较低。

Conclusion: G4RL方法扩展了现有图导向分层强化学习的适用性，并显著提升了性能，适用于对称和可逆转换的环境。

Abstract: The integration of graphs with Goal-conditioned Hierarchical Reinforcement Learning (GCHRL) has recently gained attention, as intermediate goals (subgoals) can be effectively sampled from graphs that naturally represent the overall task structure in most RL tasks. However, existing approaches typically rely on domain-specific knowledge to construct these graphs, limiting their applicability to new tasks. Other graph-based approaches create graphs dynamically during exploration but struggle to fully utilize them, because they have problems passing the information in the graphs to newly visited states. Additionally, current GCHRL methods face challenges such as sample inefficiency and poor subgoal representation. This paper proposes a solution to these issues by developing a graph encoder-decoder to evaluate unseen states. Our proposed method, Graph-Guided sub-Goal representation Generation RL (G4RL), can be incorporated into any existing GCHRL method when operating in environments with primarily symmetric and reversible transitions to enhance performance across this class of problems. We show that the graph encoder-decoder can be effectively implemented using a network trained on the state graph generated during exploration. Empirical results indicate that leveraging high and low-level intrinsic rewards from the graph encoder-decoder significantly enhances the performance of state-of-the-art GCHRL approaches with an extra small computational cost in dense and sparse reward environments.

</details>


### [67] [Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics](https://arxiv.org/abs/2511.10878)
*Shuhao Ma,Zeyi Huang,Yu Cao,Wesley Doorsamy,Chaoyang Shi,Jun Li,Zhi-Qiang Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息的深度学习框架（PI-MJCA-BiGRU），用于直接从运动学数据高效估计肌肉激活和力，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算成本高且缺乏高质量标注数据，因此需要一种更高效且无需依赖标注数据的解决方案。

Method: 使用了多关节交叉注意力模块（MJCA）和双向门控循环单元（BiGRU），结合物理信息损失函数，用于捕捉关节间协调性。

Result: 实验表明，该方法性能接近传统监督方法，MJCA模块显著提升了关节间协调建模能力。

Conclusion: PI-MJCA-BiGRU能够高效且生理一致地预测肌肉激活和力，为临床应用和设备控制提供了新思路。

Abstract: Time-efficient estimation of muscle activations and forces across multi-joint systems is critical for clinical assessment and assistive device control. However, conventional approaches are computationally expensive and lack a high-quality labeled dataset for multi-joint applications. To address these challenges, we propose a physics-informed deep learning framework that estimates muscle activations and forces directly from kinematics. The framework employs a novel Multi-Joint Cross-Attention (MJCA) module with Bidirectional Gated Recurrent Unit (BiGRU) layers to capture inter-joint coordination, enabling each joint to adaptively integrate motion information from others. By embedding multi-joint dynamics, inter-joint coupling, and external force interactions into the loss function, our Physics-Informed MJCA-BiGRU (PI-MJCA-BiGRU) delivers physiologically consistent predictions without labeled data while enabling time-efficient inference. Experimental validation on two datasets demonstrates that PI-MJCA-BiGRU achieves performance comparable to conventional supervised methods without requiring ground-truth labels, while the MJCA module significantly enhances inter-joint coordination modeling compared to other baseline architectures.

</details>


### [68] [Towards Federated Clustering: A Client-wise Private Graph Aggregation Framework](https://arxiv.org/abs/2511.10915)
*Guanxiong He,Jie Wang,Liaoyuan Tang,Zheng Wang,Rong Wang,Feiping Nie*

Main category: cs.LG

TL;DR: SPP-FGC是一种新型联邦聚类算法，通过本地结构图实现隐私保护和性能平衡，显著提升了聚类精度。


<details>
  <summary>Details</summary>
Motivation: 解决联邦聚类中性能与隐私的权衡问题，即传统方法在传输嵌入表示或共享聚类原型时会牺牲隐私或性能。

Method: 提出SPP-FGC算法，客户端构建本地结构图，服务器安全聚合对齐为全局图；分高效单轮（SPP-FGC）和迭代优化（SPP-FGC+）两种模式。

Result: 实验表明，聚类精度提升10%（NMI），同时保障隐私。

Conclusion: SPP-FGC在隐私保护和性能上均优于传统方法，为联邦聚类提供了新思路。

Abstract: Federated clustering addresses the critical challenge of extracting patterns from decentralized, unlabeled data. However, it is hampered by the flaw that current approaches are forced to accept a compromise between performance and privacy: \textit{transmitting embedding representations risks sensitive data leakage, while sharing only abstract cluster prototypes leads to diminished model accuracy}. To resolve this dilemma, we propose Structural Privacy-Preserving Federated Graph Clustering (SPP-FGC), a novel algorithm that innovatively leverages local structural graphs as the primary medium for privacy-preserving knowledge sharing, thus moving beyond the limitations of conventional techniques. Our framework operates on a clear client-server logic; on the client-side, each participant constructs a private structural graph that captures intrinsic data relationships, which the server then securely aggregates and aligns to form a comprehensive global graph from which a unified clustering structure is derived. The framework offers two distinct modes to suit different needs. SPP-FGC is designed as an efficient one-shot method that completes its task in a single communication round, ideal for rapid analysis. For more complex, unstructured data like images, SPP-FGC+ employs an iterative process where clients and the server collaboratively refine feature representations to achieve superior downstream performance. Extensive experiments demonstrate that our framework achieves state-of-the-art performance, improving clustering accuracy by up to 10\% (NMI) over federated baselines while maintaining provable privacy guarantees.

</details>


### [69] [GraphToxin: Reconstructing Full Unlearned Graphs from Graph Unlearning](https://arxiv.org/abs/2511.10936)
*Ying Song,Balaji Palanisamy*

Main category: cs.LG

TL;DR: 论文提出了GraphToxin，首个针对图遗忘的图重建攻击方法，通过曲率匹配模块实现精细化的未遗忘图恢复，揭示了图遗忘的严重隐私风险。


<details>
  <summary>Details</summary>
Motivation: 为了解决图遗忘技术可能因多方参与和残留数据而被攻击者利用的问题，揭示其潜在的安全漏洞。

Method: 提出GraphToxin攻击方法，包含曲率匹配模块，支持白盒和黑盒条件下的多节点删除，并设计评估框架。

Result: GraphToxin能成功恢复删除的节点信息和敏感内容，现有防御措施几乎无效，甚至可能增强攻击效果。

Conclusion: 论文强调了对更有效防御策略的迫切需求，并提出了系统性评估攻击性能的框架。

Abstract: Graph unlearning has emerged as a promising solution for complying with "the right to be forgotten" regulations by enabling the removal of sensitive information upon request. However, this solution is not foolproof. The involvement of multiple parties creates new attack surfaces, and residual traces of deleted data can still remain in the unlearned graph neural networks. These vulnerabilities can be exploited by attackers to recover the supposedly erased samples, thereby undermining the inherent functionality of graph unlearning. In this work, we propose GraphToxin, the first graph reconstruction attack against graph unlearning. Specifically, we introduce a novel curvature matching module to provide a fine-grained guidance for full unlearned graph recovery. We demonstrate that GraphToxin can successfully subvert the regulatory guarantees expected from graph unlearning - it can recover not only a deleted individual's information and personal links but also sensitive content from their connections, thereby posing substantially more detrimental threats. Furthermore, we extend GraphToxin to multiple node removals under both white-box and black-box setting. We highlight the necessity of a worst-case analysis and propose a comprehensive evaluation framework to systematically assess the attack performance under both random and worst-case node removals. This provides a more robust and realistic measure of the vulnerability of graph unlearning methods to graph reconstruction attacks. Our extensive experiments demonstrate the effectiveness and flexibility of GraphToxin. Notably, we show that existing defense mechanisms are largely ineffective against this attack and, in some cases, can even amplify its performance. Given the severe privacy risks posed by GraphToxin, our work underscores the urgent need for the development of more effective and robust defense strategies against this attack.

</details>


### [70] [Cascading Bandits With Feedback](https://arxiv.org/abs/2511.10938)
*R Sri Prakash,Nikhil Karamchandani,Sharayu Moharir*

Main category: cs.LG

TL;DR: 论文研究了边缘推理中的级联老虎机模型，分析了四种策略的遗憾性能，发现LCB和Thompson Sampling优于其他两种策略。


<details>
  <summary>Details</summary>
Motivation: 解决边缘推理中决策模型在不确定条件下的高效性问题。

Method: 分析并比较了Explore-then-Commit、Action Elimination、LCB和Thompson Sampling四种决策策略的遗憾表现。

Result: LCB和Thompson Sampling因其持续适应性，实现了O(1)的遗憾，优于其他策略。

Conclusion: 适应性强的策略（如LCB和Thompson Sampling）在边缘推理中表现更优。

Abstract: Motivated by the challenges of edge inference, we study a variant of the cascade bandit model in which each arm corresponds to an inference model with an associated accuracy and error probability. We analyse four decision-making policies-Explore-then-Commit, Action Elimination, Lower Confidence Bound (LCB), and Thompson Sampling-and provide sharp theoretical regret guarantees for each. Unlike in classical bandit settings, Explore-then-Commit and Action Elimination incur suboptimal regret because they commit to a fixed ordering after the exploration phase, limiting their ability to adapt. In contrast, LCB and Thompson Sampling continuously update their decisions based on observed feedback, achieving constant O(1) regret. Simulations corroborate these theoretical findings, highlighting the crucial role of adaptivity for efficient edge inference under uncertainty.

</details>


### [71] [From Parameter to Representation: A Closed-Form Approach for Controllable Model Merging](https://arxiv.org/abs/2511.10943)
*Jialin Wu,Jian Yang,Handing Wang,Jiajun Wen,Zhiyong Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种通过线性变换直接修正模型表示的方法，替代了传统的多目标离线优化，显著降低了计算成本并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 模型合并面临参数干扰和多任务性能平衡的挑战，现有方法计算复杂度高且扩展性差。

Method: 通过最优线性变换直接修正模型表示，提供封闭式解，避免了复杂的离线优化。

Result: 实验结果表明，该方法生成的模型具有更优的Pareto前沿和更高的偏好对齐精度，且计算成本大幅降低。

Conclusion: 该方法以线性复杂度实现了高效、可控的模型合并，为多任务模型生成提供了新思路。

Abstract: Model merging combines expert models for multitask performance but faces challenges from parameter interference. This has sparked recent interest in controllable model merging, giving users the ability to explicitly balance performance trade-offs. Existing approaches employ a compile-then-query paradigm, performing a costly offline multi-objective optimization to enable fast, preference-aware model generation. This offline stage typically involves iterative search or dedicated training, with complexity that grows exponentially with the number of tasks. To overcome these limitations, we shift the perspective from parameter-space optimization to a direct correction of the model's final representation. Our approach models this correction as an optimal linear transformation, yielding a closed-form solution that replaces the entire offline optimization process with a single-step, architecture-agnostic computation. This solution directly incorporates user preferences, allowing a Pareto-optimal model to be generated on-the-fly with complexity that scales linearly with the number of tasks. Experimental results show our method generates a superior Pareto front with more precise preference alignment and drastically reduced computational cost.

</details>


### [72] [How Data Quality Affects Machine Learning Models for Credit Risk Assessment](https://arxiv.org/abs/2511.10964)
*Andrea Maurino*

Main category: cs.LG

TL;DR: 研究了数据质量问题（如缺失值、噪声属性、异常值和标签错误）对信用风险评估机器学习模型预测准确性的影响，并通过实验评估了10种常见模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在信用风险评估中的广泛应用，数据质量对模型效果的潜在影响成为一个关键问题，需要系统性研究。

Method: 使用开源数据集，通过Pucktrick库引入受控的数据损坏，评估了10种常用模型（如随机森林、SVM和逻辑回归）的鲁棒性。

Result: 实验表明，模型的鲁棒性因数据损坏的性质和严重程度而存在显著差异。

Conclusion: 提出的方法和工具为从业者提升数据管道鲁棒性提供了支持，并为研究者提供了一个灵活的框架，推动以数据为中心的AI研究。

Abstract: Machine Learning (ML) models are being increasingly employed for credit risk evaluation, with their effectiveness largely hinging on the quality of the input data. In this paper we investigate the impact of several data quality issues, including missing values, noisy attributes, outliers, and label errors, on the predictive accuracy of the machine learning model used in credit risk assessment. Utilizing an open-source dataset, we introduce controlled data corruption using the Pucktrick library to assess the robustness of 10 frequently used models like Random Forest, SVM, and Logistic Regression and so on. Our experiments show significant differences in model robustness based on the nature and severity of the data degradation. Moreover, the proposed methodology and accompanying tools offer practical support for practitioners seeking to enhance data pipeline robustness, and provide researchers with a flexible framework for further experimentation in data-centric AI contexts.

</details>


### [73] [Unsupervised Robust Domain Adaptation: Paradigm, Theory and Algorithm](https://arxiv.org/abs/2511.11009)
*Fuxiang Huang,Xiaowei Fu,Shiyu Ye,Lina Ma,Wen Li,Xinbo Gao,David Zhang,Lei Zhang*

Main category: cs.LG

TL;DR: 该论文探讨了无监督领域自适应（UDA）中对抗攻击的鲁棒性问题，提出了URDA范式和理论，并设计了一种简单有效的算法DART。


<details>
  <summary>Details</summary>
Motivation: 现有UDA方法大多忽视对抗攻击的鲁棒性，而传统对抗训练（VAT）在UDA中效果不佳。论文旨在解决三个问题：VAT在UDA中失效的原因、攻击下的泛化边界理论如何演变，以及如何简单实现鲁棒训练。

Method: 提出URDA范式，揭示UDA+VAT的内在纠缠问题；设计DART算法，通过解耦蒸馏两步训练实现鲁棒性和可迁移性。

Result: 在四个基准数据集上的实验表明，DART在保持领域适应性的同时显著提升了对抗攻击下的鲁棒性。

Conclusion: 论文首次建立了URDA范式和理论，并通过DART验证了其有效性，为鲁棒领域自适应提供了新思路。

Abstract: Unsupervised domain adaptation (UDA) aims to transfer knowledge from a label-rich source domain to an unlabeled target domain by addressing domain shifts. Most UDA approaches emphasize transfer ability, but often overlook robustness against adversarial attacks. Although vanilla adversarial training (VAT) improves the robustness of deep neural networks, it has little effect on UDA. This paper focuses on answering three key questions: 1) Why does VAT, known for its defensive effectiveness, fail in the UDA paradigm? 2) What is the generalization bound theory under attacks and how does it evolve from classical UDA theory? 3) How can we implement a robustification training procedure without complex modifications? Specifically, we explore and reveal the inherent entanglement challenge in general UDA+VAT paradigm, and propose an unsupervised robust domain adaptation (URDA) paradigm. We further derive the generalization bound theory of the URDA paradigm so that it can resist adversarial noise and domain shift. To the best of our knowledge, this is the first time to establish the URDA paradigm and theory. We further introduce a simple, novel yet effective URDA algorithm called Disentangled Adversarial Robustness Training (DART), a two-step training procedure that ensures both transferability and robustness. DART first pre-trains an arbitrary UDA model, and then applies an instantaneous robustification post-training step via disentangled distillation.Experiments on four benchmark datasets with/without attacks show that DART effectively enhances robustness while maintaining domain adaptability, and validate the URDA paradigm and theory.

</details>


### [74] [Echoless Label-Based Pre-computation for Memory-Efficient Heterogeneous Graph Learning](https://arxiv.org/abs/2511.11081)
*Jun Hu,Shangheng Chen,Yufei He,Yuan Li,Bryan Hooi,Bingsheng He*

Main category: cs.LG

TL;DR: Echoless-LP提出了一种新的无回声标签预计算方法，通过分区聚焦的无回声传播（PFEP）消除训练标签泄漏问题，同时保持内存效率并与任何消息传递方法兼容。


<details>
  <summary>Details</summary>
Motivation: 传统的基于标签的预计算方法存在训练标签泄漏问题（回声效应），现有解决方案在大型图上内存效率低下或与高级消息传递方法不兼容。

Method: 提出Echoless-LP方法，采用PFEP技术，通过分区实现无回声传播；引入非对称分区方案（APS）和PostAdjust机制以缓解信息丢失和分布偏移。

Result: 在公开数据集上的实验表明，Echoless-LP在性能上优于基线方法，并保持了内存效率。

Conclusion: Echoless-LP为解决标签预计算中的回声效应提供了一种高效且通用的解决方案。

Abstract: Heterogeneous Graph Neural Networks (HGNNs) are widely used for deep learning on heterogeneous graphs. Typical end-to-end HGNNs require repetitive message passing during training, limiting efficiency for large-scale real-world graphs. Pre-computation-based HGNNs address this by performing message passing only once during preprocessing, collecting neighbor information into regular-shaped tensors, which enables efficient mini-batch training. Label-based pre-computation methods collect neighbors' label information but suffer from training label leakage, where a node's own label information propagates back to itself during multi-hop message passing - the echo effect. Existing mitigation strategies are memory-inefficient on large graphs or suffer from compatibility issues with advanced message passing methods. We propose Echoless Label-based Pre-computation (Echoless-LP), which eliminates training label leakage with Partition-Focused Echoless Propagation (PFEP). PFEP partitions target nodes and performs echoless propagation, where nodes in each partition collect label information only from neighbors in other partitions, avoiding echo while remaining memory-efficient and compatible with any message passing method. We also introduce an Asymmetric Partitioning Scheme (APS) and a PostAdjust mechanism to address information loss from partitioning and distributional shifts across partitions. Experiments on public datasets demonstrate that Echoless-LP achieves superior performance and maintains memory efficiency compared to baselines.

</details>


### [75] [SMART: A Surrogate Model for Predicting Application Runtime in Dragonfly Systems](https://arxiv.org/abs/2511.11111)
*Xin Wang,Pietro Lodi Rizzini,Sourav Medya,Zhiling Lan*

Main category: cs.LG

TL;DR: The paper proposes a hybrid simulation model for Dragonfly networks, combining GNNs and LLMs to predict runtime and reduce computational costs.


<details>
  <summary>Details</summary>
Motivation: Address workload interference in Dragonfly networks and reduce the computational expense of high-fidelity PDES.

Method: Develop a surrogate model (GNNs + LLMs) to capture spatial and temporal patterns from router data.

Result: The model outperforms existing baselines in accurate runtime prediction.

Conclusion: The hybrid simulation approach supports efficient analysis of Dragonfly networks.

Abstract: The Dragonfly network, with its high-radix and low-diameter structure, is a leading interconnect in high-performance computing. A major challenge is workload interference on shared network links. Parallel discrete event simulation (PDES) is commonly used to analyze workload interference. However, high-fidelity PDES is computationally expensive, making it impractical for large-scale or real-time scenarios. Hybrid simulation that incorporates data-driven surrogate models offers a promising alternative, especially for forecasting application runtime, a task complicated by the dynamic behavior of network traffic. We present \ourmodel, a surrogate model that combines graph neural networks (GNNs) and large language models (LLMs) to capture both spatial and temporal patterns from port level router data. \ourmodel outperforms existing statistical and machine learning baselines, enabling accurate runtime prediction and supporting efficient hybrid simulation of Dragonfly networks.

</details>


### [76] [Improving Continual Learning of Knowledge Graph Embeddings via Informed Initialization](https://arxiv.org/abs/2511.11118)
*Gerard Pons,Besim Bilalli,Anna Queralt*

Main category: cs.LG

TL;DR: 论文提出了一种新颖的知识图谱嵌入初始化策略，通过利用图谱模式和先前学习的嵌入来初始化新实体，提高了预测性能和知识保留。


<details>
  <summary>Details</summary>
Motivation: 解决知识图谱频繁更新时，嵌入初始化对最终嵌入质量和训练时间的影响，特别是在小规模频繁更新场景下。

Method: 利用图谱模式和已有嵌入为新实体生成初始表示，并根据实体类别优化初始化过程。

Result: 实验表明，该方法提升了嵌入的预测性能，加速了知识获取，减少了训练时间，并在多种嵌入模型中表现出普遍优势。

Conclusion: 该初始化策略能有效提升知识图谱嵌入的质量和效率，适用于多种学习模型。

Abstract: Many Knowledege Graphs (KGs) are frequently updated, forcing their Knowledge Graph Embeddings (KGEs) to adapt to these changes. To address this problem, continual learning techniques for KGEs incorporate embeddings for new entities while updating the old ones. One necessary step in these methods is the initialization of the embeddings, as an input to the KGE learning process, which can have an important impact in the accuracy of the final embeddings, as well as in the time required to train them. This is especially relevant for relatively small and frequent updates. We propose a novel informed embedding initialization strategy, which can be seamlessly integrated into existing continual learning methods for KGE, that enhances the acquisition of new knowledge while reducing catastrophic forgetting. Specifically, the KG schema and the previously learned embeddings are utilized to obtain initial representations for the new entities, based on the classes the entities belong to. Our extensive experimental analysis shows that the proposed initialization strategy improves the predictive performance of the resulting KGEs, while also enhancing knowledge retention. Furthermore, our approach accelerates knowledge acquisition, reducing the number of epochs, and therefore time, required to incrementally learn new embeddings. Finally, its benefits across various types of KGE learning models are demonstrated.

</details>


### [77] [Anomaly Detection in High-Dimensional Bank Account Balances via Robust Methods](https://arxiv.org/abs/2511.11143)
*Federico Maddanu,Tommaso Proietti,Riccardo Crupi*

Main category: cs.LG

TL;DR: 本文提出并评估了几种在高维数据集下计算高效的稳健统计方法，用于检测银行账户余额的异常点。


<details>
  <summary>Details</summary>
Motivation: 检测银行账户余额中的异常点对金融机构至关重要，可以帮助识别潜在欺诈或操作问题，但传统稳健统计方法在高维设置下效率低且计算成本高。

Method: 提出了几种具有高崩溃点和低计算时间的稳健统计方法，适用于中高维数据集。

Result: 实证评估表明，这些方法在260万条匿名用户银行账户余额的每日记录中表现良好。

Conclusion: 新方法在高维数据集下兼具高效性和稳健性，适用于实际金融数据分析。

Abstract: Detecting point anomalies in bank account balances is essential for financial institutions, as it enables the identification of potential fraud, operational issues, or other irregularities. Robust statistics is useful for flagging outliers and for providing estimates of the data distribution parameters that are not affected by contaminated observations. However, such a strategy is often less efficient and computationally expensive under high dimensional setting. In this paper, we propose and evaluate empirically several robust approaches that may be computationally efficient in medium and high dimensional datasets, with high breakdown points and low computational time. Our application deals with around 2.6 million daily records of anonymous users' bank account balances.

</details>


### [78] [Deep Learning for Short-Term Precipitation Prediction in Four Major Indian Cities: A ConvLSTM Approach with Explainable AI](https://arxiv.org/abs/2511.11152)
*Tanmay Ghosh,Shaurabh Anand,Rakesh Gomaji Nannewar,Nithin Nagaraj*

Main category: cs.LG

TL;DR: 提出了一种可解释的深度学习框架，用于短期降水预测，结合CNN-ConvLSTM架构，并在印度四个城市取得了低RMSE的预测效果，同时通过xAI方法分析了模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习降水预测模型多为黑箱，限制了实际应用。研究旨在提高模型透明度的同时保持准确性，以支持天气预测的实际需求。

Method: 使用混合Time-Distributed CNN-ConvLSTM架构，基于ERA5再分析数据进行训练，并根据不同城市优化卷积滤波器数量。

Result: 模型在四个城市的RMSE分别为：班加罗尔0.21 mm/天，孟买0.52 mm/天，德里0.48 mm/天，加尔各答1.80 mm/天。通过解释性分析方法揭示了城市特定的预测模式。

Conclusion: 研究表明，可解释AI（xAI）能够提供准确的降水预测并揭示模型行为，为多样化的城市环境提供了透明的降水模式分析。

Abstract: Deep learning models for precipitation forecasting often function as black boxes, limiting their adoption in real-world weather prediction. To enhance transparency while maintaining accuracy, we developed an interpretable deep learning framework for short-term precipitation prediction in four major Indian cities: Bengaluru, Mumbai, Delhi, and Kolkata, spanning diverse climate zones. We implemented a hybrid Time-Distributed CNN-ConvLSTM (Convolutional Neural Network-Long Short-Term Memory) architecture, trained on multi-decadal ERA5 reanalysis data. The architecture was optimized for each city with a different number of convolutional filters: Bengaluru (32), Mumbai and Delhi (64), and Kolkata (128). The models achieved root mean square error (RMSE) values of 0.21 mm/day (Bengaluru), 0.52 mm/day (Mumbai), 0.48 mm/day (Delhi), and 1.80 mm/day (Kolkata). Through interpretability analysis using permutation importance, Gradient-weighted Class Activation Mapping (Grad-CAM), temporal occlusion, and counterfactual perturbation, we identified distinct patterns in the model's behavior. The model relied on city-specific variables, with prediction horizons ranging from one day for Bengaluru to five days for Kolkata. This study demonstrates how explainable AI (xAI) can provide accurate forecasts and transparent insights into precipitation patterns in diverse urban environments.

</details>


### [79] [Power Ensemble Aggregation for Improved Extreme Event AI Prediction](https://arxiv.org/abs/2511.11170)
*Julien Collard,Pierre Gentine,Tian Zheng*

Main category: cs.LG

TL;DR: 论文提出使用机器学习和幂平均方法改进极端气候事件（如热浪）的预测，相比传统均值方法显著提升分类器性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决极端气候事件（尤其是热浪）预测的挑战，通过机器学习方法提升预测准确性。

Method: 将问题建模为分类任务，预测表面空气温度是否会在指定时间内超过局部q分位数；采用幂平均方法聚合集成预测。

Result: 通过幂平均聚合方法显著提升分类器性能，极端事件的预测准确性优于传统均值预测方法。

Conclusion: 幂平均聚合方法在极端气候预测中表现出色，尤其对更高分位数的极端事件预测效果更佳。

Abstract: This paper addresses the critical challenge of improving predictions of climate extreme events, specifically heat waves, using machine learning methods. Our work is framed as a classification problem in which we try to predict whether surface air temperature will exceed its q-th local quantile within a specified timeframe. Our key finding is that aggregating ensemble predictions using a power mean significantly enhances the classifier's performance. By making a machine-learning based weather forecasting model generative and applying this non-linear aggregation method, we achieve better accuracy in predicting extreme heat events than with the typical mean prediction from the same model. Our power aggregation method shows promise and adaptability, as its optimal performance varies with the quantile threshold chosen, demonstrating increased effectiveness for higher extremes prediction.

</details>


### [80] [On-line learning of dynamic systems: sparse regression meets Kalman filtering](https://arxiv.org/abs/2511.11178)
*Gianluigi Pillonetto,Akram Yazdani,Aleksandr Aravkin*

Main category: cs.LG

TL;DR: SKF算法结合Sindy和Kalman滤波器，实现实时学习时变非线性系统模型，并在复杂系统中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 学习数据中的控制方程对理解物理系统行为至关重要，但传统方法难以实时处理时变非线性系统。

Method: 提出Sindy Kalman Filter (SKF)，将未知参数作为状态变量，结合Sindy与Kalman滤波器，实现实时推断。

Result: SKF在参数漂移或切换的混沌Lorenz系统和真实飞行数据模型中表现优异，简化了参数估计。

Conclusion: SKF为实时识别非线性系统提供了有效工具，尤其在复杂时变场景中具有显著优势。

Abstract: Learning governing equations from data is central to understanding the behavior of physical systems across diverse scientific disciplines, including physics, biology, and engineering. The Sindy algorithm has proven effective in leveraging sparsity to identify concise models of nonlinear dynamical systems. In this paper, we extend sparsity-driven approaches to real-time learning by integrating a cornerstone algorithm from control theory -- the Kalman filter (KF). The resulting Sindy Kalman Filter (SKF) unifies both frameworks by treating unknown system parameters as state variables, enabling real-time inference of complex, time-varying nonlinear models unattainable by either method alone. Furthermore, SKF enhances KF parameter identification strategies, particularly via look-ahead error, significantly simplifying the estimation of sparsity levels, variance parameters, and switching instants. We validate SKF on a chaotic Lorenz system with drifting or switching parameters and demonstrate its effectiveness in the real-time identification of a sparse nonlinear aircraft model built from real flight data.

</details>


### [81] [LoRaCompass: Robust Reinforcement Learning to Efficiently Search for a LoRa Tag](https://arxiv.org/abs/2511.11190)
*Tianlang He,Zhongming Lin,Tianrui Jiang,S. -H. Gary Chan*

Main category: cs.LG

TL;DR: 论文提出了一种名为LoRaCompass的强化学习模型，用于在未知环境中高效定位周期性广播的LoRa标签，克服了现有方法在领域迁移和信号波动中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的方法在定位LoRa标签时容易受到领域迁移和信号波动的影响，导致决策错误和定位不准确。因此，作者旨在开发一种更鲁棒和高效的搜索方法。

Method: LoRaCompass通过空间感知特征提取器和策略蒸馏损失函数，从RSSI中学习鲁棒的空间表示，以最大化向标签靠近的概率，并引入基于上置信界的探索函数以提高定位信心。

Result: 在覆盖80km²的多样化未见环境中，LoRaCompass在定位标签时成功率达90%以上（比现有方法提高40%），且搜索路径长度与初始距离呈线性关系。

Conclusion: LoRaCompass在定位LoRa标签方面表现出高效性和鲁棒性，适用于地面和无人机辅助场景。

Abstract: The Long-Range (LoRa) protocol, known for its extensive range and low power, has increasingly been adopted in tags worn by mentally incapacitated persons (MIPs) and others at risk of going missing. We study the sequential decision-making process for a mobile sensor to locate a periodically broadcasting LoRa tag with the fewest moves (hops) in general, unknown environments, guided by the received signal strength indicator (RSSI). While existing methods leverage reinforcement learning for search, they remain vulnerable to domain shift and signal fluctuation, resulting in cascading decision errors that culminate in substantial localization inaccuracies. To bridge this gap, we propose LoRaCompass, a reinforcement learning model designed to achieve robust and efficient search for a LoRa tag. For exploitation under domain shift and signal fluctuation, LoRaCompass learns a robust spatial representation from RSSI to maximize the probability of moving closer to a tag, via a spatially-aware feature extractor and a policy distillation loss function. It further introduces an exploration function inspired by the upper confidence bound (UCB) that guides the sensor toward the tag with increasing confidence. We have validated LoRaCompass in ground-based and drone-assisted scenarios within diverse unseen environments covering an area of over 80km^2. It has demonstrated high success rate (>90%) in locating the tag within 100m proximity (a 40% improvement over existing methods) and high efficiency with a search path length (in hops) that scales linearly with the initial distance.

</details>


### [82] [When to Stop Federated Learning: Zero-Shot Generation of Synthetic Validation Data with Generative AI for Early Stopping](https://arxiv.org/abs/2511.11208)
*Youngjoon Lee,Hyukjoon Lee,Jinu Gong,Yang Cao,Joonhyuk Kang*

Main category: cs.LG

TL;DR: 提出了一种基于生成AI的零样本合成验证框架，用于优化联邦学习的训练效率，减少不必要的计算。


<details>
  <summary>Details</summary>
Motivation: 联邦学习通常需要预先设定训练轮数，可能导致计算资源浪费或未能及时停止无效训练。

Method: 通过生成AI构建零样本合成验证框架，动态监测模型性能并决定提前停止点。

Result: 在多标签胸部X射线分类任务中，训练轮数减少74%，准确率仅下降1%。

Conclusion: 该方法显著提高了联邦学习的效率，减少了不必要的计算成本。

Abstract: Federated Learning (FL) enables collaborative model training across decentralized devices while preserving data privacy. However, FL methods typically run for a predefined number of global rounds, often leading to unnecessary computation when optimal performance is reached earlier. In addition, training may continue even when the model fails to achieve meaningful performance. To address this inefficiency, we introduce a zero-shot synthetic validation framework that leverages generative AI to monitor model performance and determine early stopping points. Our approach adaptively stops training near the optimal round, thereby conserving computational resources and enabling rapid hyperparameter adjustments. Numerical results on multi-label chest X-ray classification demonstrate that our method reduces training rounds by up to 74% while maintaining accuracy within 1% of the optimal.

</details>


### [83] [A Best-of-Both-Worlds Proof for Tsallis-INF without Fenchel Conjugates](https://arxiv.org/abs/2511.11211)
*Wei-Cheng Lee,Francesco Orabona*

Main category: cs.LG

TL;DR: 本文简要推导了Tsallis-INF多臂老虎机算法的最佳世界保证，避免了共轭函数的使用，并简化了证明。


<details>
  <summary>Details</summary>
Motivation: 目标是提供一个更简洁的证明方法，以展示Tsallis-INF算法在随机和对抗性老虎机问题中的最优性能。

Method: 利用在线凸优化的现代工具，避免了共轭函数的使用，且未优化边界常数以简化证明。

Result: 成功展示了Tsallis-INF算法的通用性和最佳世界保证，提供了一个更轻量级的证明。

Conclusion: 该方法简化了原始证明，同时保持了算法的理论性能。

Abstract: In this short note, we present a simple derivation of the best-of-both-world guarantee for the Tsallis-INF multi-armed bandit algorithm from J. Zimmert and Y. Seldin. Tsallis-INF: An optimal algorithm for stochastic and adversarial bandits. Journal of Machine Learning Research, 22(28):1-49, 2021. URL https://jmlr.csail.mit.edu/papers/volume22/19-753/19-753.pdf. In particular, the proof uses modern tools from online convex optimization and avoid the use of conjugate functions. Also, we do not optimize the constants in the bounds in favor of a slimmer proof.

</details>


### [84] [Virtual Width Networks](https://arxiv.org/abs/2511.11238)
*Seed,Baisheng Li,Banggu Wu,Bole Ma,Bowen Xiao,Chaoyi Zhang,Cheng Li,Chengyi Wang,Chenyin Xu,Chi Zhang,Chong Hu,Daoguang Zan,Defa Zhu,Dongyu Xu,Du Li,Faming Wu,Fan Xia,Ge Zhang,Guang Shi,Haobin Chen,Hongyu Zhu,Hongzhi Huang,Huan Zhou,Huanzhang Dou,Jianhui Duan,Jianqiao Lu,Jianyu Jiang,Jiayi Xu,Jiecao Chen,Jin Chen,Jin Ma,Jing Su,Jingji Chen,Jun Wang,Jun Yuan,Juncai Liu,Jundong Zhou,Kai Hua,Kai Shen,Kai Xiang,Kaiyuan Chen,Kang Liu,Ke Shen,Liang Xiang,Lin Yan,Lishu Luo,Mengyao Zhang,Ming Ding,Mofan Zhang,Nianning Liang,Peng Li,Penghao Huang,Pengpeng Mu,Qi Huang,Qianli Ma,Qiyang Min,Qiying Yu,Renming Pang,Ru Zhang,Shen Yan,Shen Yan,Shixiong Zhao,Shuaishuai Cao,Shuang Wu,Siyan Chen,Siyu Li,Siyuan Qiao,Tao Sun,Tian Xin,Tiantian Fan,Ting Huang,Ting-Han Fan,Wei Jia,Wenqiang Zhang,Wenxuan Liu,Xiangzhong Wu,Xiaochen Zuo,Xiaoying Jia,Ximing Yang,Xin Liu,Xin Yu,Xingyan Bin,Xintong Hao,Xiongcai Luo,Xujing Li,Xun Zhou,Yanghua Peng,Yangrui Chen,Yi Lin,Yichong Leng,Yinghao Li,Yingshuan Song,Yiyuan Ma,Yong Shan,Yongan Xiang,Yonghui Wu,Yongtao Zhang,Yongzhen Yao,Yu Bao,Yuehang Yang,Yufeng Yuan,Yunshui Li,Yuqiao Xian,Yutao Zeng,Yuxuan Wang,Zehua Hong,Zehua Wang,Zengzhi Wang,Zeyu Yang,Zhengqiang Yin,Zhenyi Lu,Zhexi Zhang,Zhi Chen,Zhi Zhang,Zhiqi Lin,Zihao Huang,Zilin Xu,Ziyun Wei,Zuo Wang*

Main category: cs.LG

TL;DR: Virtual Width Networks (VWN) 通过解耦表示宽度与主干宽度，在不显著增加计算成本的情况下扩展表示空间，显著加速优化效果。


<details>
  <summary>Details</summary>
Motivation: 避免因增加隐藏层大小带来的二次成本，同时扩展表示空间以提升模型效率。

Method: 提出 VWN 框架，将表示宽度与主干宽度解耦，扩展嵌入空间的同时保持主干计算基本不变。

Result: 实验中，8 倍扩展使得单令牌预测优化加速 2 倍，双令牌预测加速 3 倍，并随着训练规模扩大效果更显著。

Conclusion: VWN 不仅令牌效率高，且规模越大效果越显著，同时揭示了虚拟宽度与损失减少之间的对数线性关系。

Abstract: We introduce Virtual Width Networks (VWN), a framework that delivers the benefits of wider representations without incurring the quadratic cost of increasing the hidden size. VWN decouples representational width from backbone width, expanding the embedding space while keeping backbone compute nearly constant. In our large-scale experiment, an 8-times expansion accelerates optimization by over 2 times for next-token and 3 times for next-2-token prediction. The advantage amplifies over training as both the loss gap grows and the convergence-speedup ratio increases, showing that VWN is not only token-efficient but also increasingly effective with scale. Moreover, we identify an approximately log-linear scaling relation between virtual width and loss reduction, offering an initial empirical basis and motivation for exploring virtual-width scaling as a new dimension of large-model efficiency.

</details>


### [85] [HealSplit: Towards Self-Healing through Adversarial Distillation in Split Federated Learning](https://arxiv.org/abs/2511.11240)
*Yuhan Xie,Chen Lyu*

Main category: cs.LG

TL;DR: HealSplit是一个针对Split Federated Learning的统一防御框架，通过拓扑感知检测模块、生成式恢复管道和对抗性多教师蒸馏框架，有效防御五种复杂的数据中毒攻击。


<details>
  <summary>Details</summary>
Motivation: Split Federated Learning在隐私保护的分布式学习中面临数据中毒攻击的威胁，传统防御方法效果有限，因此提出了专为SFL设计的统一防御框架HealSplit。

Method: HealSplit包括拓扑感知检测模块（通过图构建和拓扑异常评分识别中毒样本）、生成式恢复管道（合成并验证替代数据）和对抗性多教师蒸馏框架（结合语义和异常感知信号训练学生模型）。

Result: 在四个基准数据集上的实验表明，HealSplit在十种现有防御方法中表现最优，具有更强的鲁棒性和防御效果。

Conclusion: HealSplit为Split Federated Learning提供了一种高效的端到端防御方案，能够应对多种复杂攻击场景。

Abstract: Split Federated Learning (SFL) is an emerging paradigm for privacy-preserving distributed learning. However, it remains vulnerable to sophisticated data poisoning attacks targeting local features, labels, smashed data, and model weights. Existing defenses, primarily adapted from traditional Federated Learning (FL), are less effective under SFL due to limited access to complete model updates. This paper presents HealSplit, the first unified defense framework tailored for SFL, offering end-to-end detection and recovery against five sophisticated types of poisoning attacks. HealSplit comprises three key components: (1) a topology-aware detection module that constructs graphs over smashed data to identify poisoned samples via topological anomaly scoring (TAS); (2) a generative recovery pipeline that synthesizes semantically consistent substitutes for detected anomalies, validated by a consistency validation student; and (3) an adversarial multi-teacher distillation framework trains the student using semantic supervision from a Vanilla Teacher and anomaly-aware signals from an Anomaly-Influence Debiasing (AD) Teacher, guided by the alignment between topological and gradient-based interaction matrices. Extensive experiments on four benchmark datasets demonstrate that HealSplit consistently outperforms ten state-of-the-art defenses, achieving superior robustness and defense effectiveness across diverse attack scenarios.

</details>


### [86] [Retrofit: Continual Learning with Bounded Forgetting for Security Applications](https://arxiv.org/abs/2511.11439)
*Yiling He,Junchi Lei,Hongyu She,Shuo Shao,Xinran Zheng,Yiping Liu,Zhan Qin,Lorenzo Cavallaro*

Main category: cs.LG

TL;DR: RETROFIT是一种无需历史数据的持续学习方法，通过参数合并和动态仲裁机制，有效缓解遗忘问题，提升模型在安全场景中的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习方法在敏感数据环境下难以应用，且无法平衡新旧知识的整合。RETROFIT旨在解决这些挑战。

Method: 通过参数级合并和低秩稀疏更新，限制参数变化的子空间，动态仲裁旧新知识贡献。

Result: 在恶意软件检测和二进制摘要任务中，RETROFIT显著优于基线方法，并在新数据上超过上限。

Conclusion: RETROFIT为安全领域的持续学习提供了一种高效且无需历史数据的解决方案。

Abstract: Modern security analytics are increasingly powered by deep learning models, but their performance often degrades as threat landscapes evolve and data representations shift. While continual learning (CL) offers a promising paradigm to maintain model effectiveness, many approaches rely on full retraining or data replay, which are infeasible in data-sensitive environments. Moreover, existing methods remain inadequate for security-critical scenarios, facing two coupled challenges in knowledge transfer: preserving prior knowledge without old data and integrating new knowledge with minimal interference.
  We propose RETROFIT, a data retrospective-free continual learning method that achieves bounded forgetting for effective knowledge transfer. Our key idea is to consolidate previously trained and newly fine-tuned models, serving as teachers of old and new knowledge, through parameter-level merging that eliminates the need for historical data. To mitigate interference, we apply low-rank and sparse updates that confine parameter changes to independent subspaces, while a knowledge arbitration dynamically balances the teacher contributions guided by model confidence. Our evaluation on two representative applications demonstrates that RETROFIT consistently mitigates forgetting while maintaining adaptability. In malware detection under temporal drift, it substantially improves the retention score, from 20.2% to 38.6% over CL baselines, and exceeds the oracle upper bound on new data. In binary summarization across decompilation levels, where analyzing stripped binaries is especially challenging, RETROFIT achieves around twice the BLEU score of transfer learning used in prior work and surpasses all baselines in cross-representation generalization.

</details>


### [87] [Epistemic Error Decomposition for Multi-step Time Series Forecasting: Rethinking Bias-Variance in Recursive and Direct Strategies](https://arxiv.org/abs/2511.11461)
*Riku Green,Huw Day,Zahraa S. Abdallah,Telmo M. Silva Filho*

Main category: cs.LG

TL;DR: 论文重新审视了递归和直接策略在多步预测中的偏见-方差权衡观点，提出了分解误差的新框架，并通过实验验证了非线性模型下递归策略的优势。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为递归策略具有高偏见低方差，而直接策略则是低偏见高方差。作者挑战这一观点，希望通过误差分解更准确地理解两者的表现差异。

Method: 作者将多步预测误差分解为不可约噪声、结构近似差距和估计方差项，并通过理论分析和实验（使用多层感知机在ETTm1数据集上）验证。

Result: 研究发现，对于线性预测器，结构近似差距为零；而对于非线性预测器，递归策略可以提升模型表达能力。同时，递归策略的估计方差可用一步方差的放大因子描述。

Conclusion: 结果表明，选择递归或直接策略应基于模型非线性和噪声特性，而非传统偏见-方差直觉。论文提供了实践指导。

Abstract: Multi-step forecasting is often described through a simple rule of thumb: recursive strategies are said to have high bias and low variance, while direct strategies are said to have low bias and high variance. We revisit this belief by decomposing the expected multi-step forecast error into three parts: irreducible noise, a structural approximation gap, and an estimation-variance term. For linear predictors we show that the structural gap is identically zero for any dataset. For nonlinear predictors, however, the repeated composition used in recursion can increase model expressivity, making the structural gap depend on both the model and the data. We further show that the estimation variance of the recursive strategy at any horizon can be written as the one-step variance multiplied by a Jacobian-based amplification factor that measures how sensitive the composed predictor is to parameter error. This perspective explains when recursive forecasting may simultaneously have lower bias and higher variance than direct forecasting. Experiments with multilayer perceptrons on the ETTm1 dataset confirm these findings. The results offer practical guidance for choosing between recursive and direct strategies based on model nonlinearity and noise characteristics, rather than relying on traditional bias-variance intuition.

</details>


### [88] [Heterogeneous Attributed Graph Learning via Neighborhood-Aware Star Kernels](https://arxiv.org/abs/2511.11245)
*Hong Huang,Chengyu Yao,Haiming Chen,Hang Gao*

Main category: cs.LG

TL;DR: 提出一种基于邻域信息的图核方法NASK，通过结合Gower相似度和星形子结构提升对异构属性的处理能力，并证明其正定性。


<details>
  <summary>Details</summary>
Motivation: 现有图核方法难以同时捕捉异构属性和邻域信息，需提出一种高效处理这种复杂性的新方法。

Method: 用Gower相似度的指数变换联合建模数值和类别特征，并通过Weisfeiler-Lehman迭代增强星形子结构以整合多尺度邻域信息。

Result: 在11个属性和4个大规模真实图基准上的实验显示，NASK优于16种先进基线方法。

Conclusion: NASK是一种高效且性能优越的图核方法，适用于属性图学习。

Abstract: Attributed graphs, typically characterized by irregular topologies and a mix of numerical and categorical attributes, are ubiquitous in diverse domains such as social networks, bioinformatics, and cheminformatics. While graph kernels provide a principled framework for measuring graph similarity, existing kernel methods often struggle to simultaneously capture heterogeneous attribute semantics and neighborhood information in attributed graphs. In this work, we propose the Neighborhood-Aware Star Kernel (NASK), a novel graph kernel designed for attributed graph learning. NASK leverages an exponential transformation of the Gower similarity coefficient to jointly model numerical and categorical features efficiently, and employs star substructures enhanced by Weisfeiler-Lehman iterations to integrate multi-scale neighborhood structural information. We theoretically prove that NASK is positive definite, ensuring compatibility with kernel-based learning frameworks such as SVMs. Extensive experiments are conducted on eleven attributed and four large-scale real-world graph benchmarks. The results demonstrate that NASK consistently achieves superior performance over sixteen state-of-the-art baselines, including nine graph kernels and seven Graph Neural Networks.

</details>


### [89] [Toward Scalable Early Cancer Detection: Evaluating EHR-Based Predictive Models Against Traditional Screening Criteria](https://arxiv.org/abs/2511.11293)
*Jiheum Park,Chao Pang,Tristan Y. Lee,Jeong Yun Yang,Jacob Berkowitz,Alexander Z. Wei,Nicholas Tatonetti*

Main category: cs.LG

TL;DR: 电子健康记录（EHR）为基础的预测模型与传统风险因素相比，能够更有效地识别多种癌症的高风险人群，且性能更好。


<details>
  <summary>Details</summary>
Motivation: 当前癌症筛查指南覆盖的癌症类型有限且依赖传统风险因素，EHR模型可能提供更全面和准确的早期检测工具。

Method: 利用All of Us研究项目中865,000多名参与者的EHR、基因组和调查数据，系统评估EHR模型与传统风险因素在八种主要癌症中的表现。

Result: EHR模型的真实癌症病例检出率比传统因素高3-6倍，且先进的EHR基础模型进一步提升了26种癌症的预测性能。

Conclusion: EHR模型在癌症早期检测中具有临床潜力，能支持更精确和可扩展的筛查策略。

Abstract: Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful HER-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies.

</details>


### [90] [Fast and Expressive Multi-Token Prediction with Probabilistic Circuits](https://arxiv.org/abs/2511.11346)
*Andreas Grivas,Lorenzo Loconte,Emile van Krieken,Piotr Nawrot,Yu Zhao,Euan Wielewski,Pasquale Minervini,Edoardo Ponti,Antonio Vergari*

Main category: cs.LG

TL;DR: 本文提出了一种名为MTPC的框架，通过概率电路探索多令牌预测中的表达性和延迟之间的权衡，显著提高了生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有多令牌预测方法假设未来令牌独立，牺牲了表达性。本研究旨在解决这一问题，同时优化生成效率。

Method: MTPC利用概率电路编码未来令牌的联合分布，支持多种架构如混合模型和隐马尔可夫模型，并结合推测解码技术。

Result: 实验表明，MTPC显著提升生成速度，同时保持原验证模型的性能，并研究了表达性和延迟的最佳权衡。

Conclusion: MTPC框架在多令牌预测中实现了更好的表达性与延迟平衡，为字节级大语言模型提供了高效解决方案。

Abstract: Multi-token prediction (MTP) is a prominent strategy to significantly speed up generation in large language models (LLMs), including byte-level LLMs, which are tokeniser-free but prohibitively slow. However, existing MTP methods often sacrifice expressiveness by assuming independence between future tokens. In this work, we investigate the trade-off between expressiveness and latency in MTP within the framework of probabilistic circuits (PCs). Our framework, named MTPC, allows one to explore different ways to encode the joint distributions over future tokens by selecting different circuit architectures, generalising classical models such as (hierarchical) mixture models, hidden Markov models and tensor networks. We show the efficacy of MTPC by retrofitting existing byte-level LLMs, such as EvaByte. Our experiments show that, when combined with speculative decoding, MTPC significantly speeds up generation compared to MTP with independence assumptions, while guaranteeing to retain the performance of the original verifier LLM. We also rigorously study the optimal trade-off between expressiveness and latency when exploring the possible parameterisations of MTPC, such as PC architectures and partial layer sharing between the verifier and draft LLMs.

</details>


### [91] [Toward Multi-Fidelity Machine Learning Force Field for Cathode Materials](https://arxiv.org/abs/2511.11361)
*Guangyi Dong,Zhihui Wang*

Main category: cs.LG

TL;DR: 本文提出了一种多保真度机器学习力场框架，用于提高锂离子电池正极材料的力场训练数据效率，结合了低保真度非磁性和高保真度磁性数据集，成功应用于LMFP材料系统。


<details>
  <summary>Details</summary>
Motivation: 由于正极材料复杂的电子结构特性和高质量计算数据集的稀缺，机器学习力场（MLFFs）在锂离子电池正极材料的开发和应用中受到限制。

Method: 开发了一种多保真度机器学习力场框架，能够同时利用低保真度非磁性和高保真度磁性计算数据集进行训练。

Result: 在LMFP正极材料系统中的测试表明，该方法有效提高了力场训练的数据效率。

Conclusion: 该研究以较低的训练数据集成本实现了正极材料的高精度MLFF训练，为MLFFs在正极材料计算模拟中的应用提供了新视角。

Abstract: Machine learning force fields (MLFFs), which employ neural networks to map atomic structures to system energies, effectively combine the high accuracy of first-principles calculation with the computational efficiency of empirical force fields. They are widely used in computational materials simulations. However, the development and application of MLFFs for lithium-ion battery cathode materials remain relatively limited. This is primarily due to the complex electronic structure characteristics of cathode materials and the resulting scarcity of high-quality computational datasets available for force field training. In this work, we develop a multi-fidelity machine learning force field framework to enhance the data efficiency of computational results, which can simultaneously utilize both low-fidelity non-magnetic and high-fidelity magnetic computational datasets of cathode materials for training. Tests conducted on the lithium manganese iron phosphate (LMFP) cathode material system demonstrate the effectiveness of this multi-fidelity approach. This work helps to achieve high-accuracy MLFF training for cathode materials at a lower training dataset cost, and offers new perspectives for applying MLFFs to computational simulations of cathode materials.

</details>


### [92] [On-Device Fine-Tuning via Backprop-Free Zeroth-Order Optimization](https://arxiv.org/abs/2511.11362)
*Prabodh Katti,Sangwoo Park,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 论文研究了在边缘设备上高效微调模型的方法，通过零阶优化算法（MeZO）减少内存占用，支持更大模型的部署，但需要更长的训练时间。


<details>
  <summary>Details</summary>
Motivation: 边缘AI系统需在严格内存限制下适应不同任务，传统的反向传播方法因存储需求高限制了模型规模。

Method: 提出内存高效的零阶优化（MeZO），仅通过前向计算估计梯度，避免存储中间激活和优化器状态。

Result: 理论分析和实验表明，MeZO在内存受限时可部署更大模型，并保持准确性，但需增加训练时间。

Conclusion: MeZO是一种适用于内存受限边缘设备的高效微调方法，权衡了模型规模与训练时间。

Abstract: On-device fine-tuning is a critical capability for edge AI systems, which must support adaptation to different agentic tasks under stringent memory constraints. Conventional backpropagation (BP)-based training requires storing layer activations and optimizer states, a demand that can be only partially alleviated through checkpointing. In edge deployments in which the model weights must reside entirely in device memory, this overhead severely limits the maximum model size that can be deployed. Memory-efficient zeroth-order optimization (MeZO) alleviates this bottleneck by estimating gradients using forward evaluations alone, eliminating the need for storing intermediate activations or optimizer states. This enables significantly larger models to fit within on-chip memory, albeit at the cost of potentially longer fine-tuning wall-clock time. This paper first provides a theoretical estimate of the relative model sizes that can be accommodated under BP and MeZO training. We then numerically validate the analysis, demonstrating that MeZO exhibits accuracy advantages under on-device memory constraints, provided sufficient wall-clock time is available for fine-tuning.

</details>


### [93] [Multicalibration yields better matchings](https://arxiv.org/abs/2511.11413)
*Riccardo Colini Baldeschi,Simone Di Gregorio,Simone Fioravanti,Federico Fusco,Ido Guy,Daniel Haimovich,Stefano Leonardi,Fridolin Linder,Lorenzo Perini,Matteo Russo,Niek Tax*

Main category: cs.LG

TL;DR: 论文提出了一种基于多标定的方法，通过优化预测器在保护上下文集合上的无偏性，提升了在加权图中匹配问题的决策质量。


<details>
  <summary>Details</summary>
Motivation: 在实际场景中，预测器通常是不完美的，而基于贝叶斯最优预测器的标准决策规则可能表现不佳。本文旨在解决如何在这种不完美预测下优化匹配决策的问题。

Method: 引入多标定（multicalibration）概念，要求预测器在保护上下文集合上无偏。通过构造一个多标定的预测器，使其输出能够支持竞争性匹配决策。

Result: 研究表明，基于多标定预测器的匹配决策能够与原始预测器的最优决策规则竞争，并提供了样本复杂性界限。

Conclusion: 多标定是一种有效的方法，可以在不完美预测的情况下提高匹配决策的性能，为实际应用提供了理论支持。

Abstract: Consider the problem of finding the best matching in a weighted graph where we only have access to predictions of the actual stochastic weights, based on an underlying context. If the predictor is the Bayes optimal one, then computing the best matching based on the predicted weights is optimal. However, in practice, this perfect information scenario is not realistic. Given an imperfect predictor, a suboptimal decision rule may compensate for the induced error and thus outperform the standard optimal rule.
  In this paper, we propose multicalibration as a way to address this problem. This fairness notion requires a predictor to be unbiased on each element of a family of protected sets of contexts. Given a class of matching algorithms $\mathcal C$ and any predictor $γ$ of the edge-weights, we show how to construct a specific multicalibrated predictor $\hat γ$, with the following property. Picking the best matching based on the output of $\hat γ$ is competitive with the best decision rule in $\mathcal C$ applied onto the original predictor $γ$. We complement this result by providing sample complexity bounds.

</details>


### [94] [Differentiation Strategies for Acoustic Inverse Problems: Admittance Estimation and Shape Optimization](https://arxiv.org/abs/2511.11415)
*Nikolas Borrel-Jensen,Josiah Bjorgaard*

Main category: cs.LG

TL;DR: 论文提出了一种基于可微分编程的声学逆问题解决方法，应用于导纳估计和共振阻尼的形状优化，展现了高效和精确的特性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过现代可微分软件栈快速解决声学逆问题，无需手动推导伴随方程，提高优化效率。

Method: 使用JAX-FEM的自动微分（AD）进行导纳估计；结合JAX-FEM和PyTorch3D，通过AD和随机有限差分进行形状优化。

Result: 导纳估计达到3位数精度；形状优化在目标频率下实现48.1%的能量减少，计算效率提升30倍。

Conclusion: 现代可微分编程工具为物理逆问题的优化提供了高效、灵活的解决方案。

Abstract: We demonstrate a practical differentiable programming approach for acoustic inverse problems through two applications: admittance estimation and shape optimization for resonance damping. First, we show that JAX-FEM's automatic differentiation (AD) enables direct gradient-based estimation of complex boundary admittance from sparse pressure measurements, achieving 3-digit precision without requiring manual derivation of adjoint equations. Second, we apply randomized finite differences to acoustic shape optimization, combining JAX-FEM for forward simulation with PyTorch3D for mesh manipulation through AD. By separating physics-driven boundary optimization from geometry-driven interior mesh adaptation, we achieve 48.1% energy reduction at target frequencies with 30-fold fewer FEM solutions compared to standard finite difference on the full mesh. This work showcases how modern differentiable software stacks enable rapid prototyping of optimization workflows for physics-based inverse problems, with automatic differentiation for parameter estimation and a combination of finite differences and AD for geometric design.

</details>


### [95] [Low-Bit, High-Fidelity: Optimal Transport Quantization for Flow Matching](https://arxiv.org/abs/2511.11418)
*Dara Varam,Diaa A. Abuhani,Imran Zualkernan,Raghad AlDamani,Lujain Khalil*

Main category: cs.LG

TL;DR: OT-based post-training quantization for Flow Matching (FM) models preserves generation quality and latent space stability at 2-3 bits per parameter.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of high-precision parameter requirements in FM models to enable practical deployment.

Method: Use optimal transport (OT)-based quantization to minimize the 2-Wasserstein distance between quantized and original weights, comparing it with uniform, piecewise, and logarithmic schemes.

Result: OT-based quantization outperforms other methods, maintaining visual quality and stability even at low bit-widths (2-3 bits).

Conclusion: OT-based quantization is a principled and effective approach for compressing FM models, suitable for edge and embedded AI applications.

Abstract: Flow Matching (FM) generative models offer efficient simulation-free training and deterministic sampling, but their practical deployment is challenged by high-precision parameter requirements. We adapt optimal transport (OT)-based post-training quantization to FM models, minimizing the 2-Wasserstein distance between quantized and original weights, and systematically compare its effectiveness against uniform, piecewise, and logarithmic quantization schemes. Our theoretical analysis provides upper bounds on generative degradation under quantization, and empirical results across five benchmark datasets of varying complexity show that OT-based quantization preserves both visual generation quality and latent space stability down to 2-3 bits per parameter, where alternative methods fail. This establishes OT-based quantization as a principled, effective approach to compress FM generative models for edge and embedded AI applications.

</details>


### [96] [DiffPro: Joint Timestep and Layer-Wise Precision Optimization for Efficient Diffusion Inference](https://arxiv.org/abs/2511.11446)
*Farhana Amin,Sabiha Afroz,Kanchon Gharami,Mona Moghadampanah,Dimitrios S. Nikolopoulos*

Main category: cs.LG

TL;DR: DiffPro是一个后训练框架，旨在优化扩散模型的推断效率，通过联合调整时间步和每层精度，显著减少延迟和内存使用，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成高质量图像但推断成本高，主要由于大量的去噪步骤和矩阵运算。DiffPro旨在在不影响性能的前提下减少这些成本。

Method: DiffPro通过三个部分实现优化：基于流形感知的敏感度分配权重比特，动态激活量化以稳定不同时间步的激活，以及基于师生漂移的预算时间步选择器。

Result: 实验表明，DiffPro实现了6.25倍的模型压缩，减少了50%的时间步，推断速度提升2.8倍，同时保持Delta FID<=10的性能。

Conclusion: DiffPro将时间步减少和精度规划统一为一个可部署方案，为实时节能扩散推断提供了实用且高效的解决方案。

Abstract: Diffusion models produce high quality images but inference is costly due to many denoising steps and heavy matrix operations. We present DiffPro, a post-training, hardware-faithful framework that works with the exact integer kernels used in deployment and jointly tunes timesteps and per-layer precision in Diffusion Transformers (DiTs) to reduce latency and memory without any training. DiffPro combines three parts: a manifold-aware sensitivity metric to allocate weight bits, dynamic activation quantization to stabilize activations across timesteps, and a budgeted timestep selector guided by teacher-student drift. In experiments DiffPro achieves up to 6.25x model compression, fifty percent fewer timesteps, and 2.8x faster inference with Delta FID <= 10 on standard benchmarks, demonstrating practical efficiency gains. DiffPro unifies step reduction and precision planning into a single budgeted deployable plan for real-time energy-aware diffusion inference.

</details>


### [97] [FairReweighing: Density Estimation-Based Reweighing Framework for Improving Separation in Fair Regression](https://arxiv.org/abs/2511.11459)
*Xiaoyin Xi,Zhe Yu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于互信息的度量标准，用于评估AI软件中的公平性问题，并针对回归任务设计了一个公平性预处理算法FairReweighing。该方法在理论和实证上都表现出色。


<details>
  <summary>Details</summary>
Motivation: AI软件在公共部门和工业中的广泛应用引发了对其决策透明度和公平性的担忧。尽管已有许多针对二元分类任务的公平性研究，但回归任务中的公平性尚未被充分探索。本文旨在填补这一空白。

Method: 作者采用基于互信息的度量标准，并将其扩展到适用于分类和回归任务。受公平分类中的Reweighing算法启发，提出了基于密度估计的FairReweighing预处理算法，以确保模型的公平性。

Result: 理论分析表明，FairReweighing算法能在数据独立性假设下保证训练数据的公平性。实证结果在合成和真实数据上显示，该算法在提高公平性的同时保持了高准确率。

Conclusion: FairReweighing算法在回归任务中优于现有的公平性解决方案，为解决AI软件公平性问题提供了新的工具。

Abstract: There has been a prevalence of applying AI software in both high-stakes public-sector and industrial contexts. However, the lack of transparency has raised concerns about whether these data-informed AI software decisions secure fairness against people of all racial, gender, or age groups. Despite extensive research on emerging fairness-aware AI software, up to now most efforts to solve this issue have been dedicated to binary classification tasks. Fairness in regression is relatively underexplored. In this work, we adopted a mutual information-based metric to assess separation violations. The metric is also extended so that it can be directly applied to both classification and regression problems with both binary and continuous sensitive attributes. Inspired by the Reweighing algorithm in fair classification, we proposed a FairReweighing pre-processing algorithm based on density estimation to ensure that the learned model satisfies the separation criterion. Theoretically, we show that the proposed FairReweighing algorithm can guarantee separation in the training data under a data independence assumption. Empirically, on both synthetic and real-world data, we show that FairReweighing outperforms existing state-of-the-art regression fairness solutions in terms of improving separation while maintaining high accuracy.

</details>


### [98] [MoCap2Radar: A Spatiotemporal Transformer for Synthesizing Micro-Doppler Radar Signatures from Motion Capture](https://arxiv.org/abs/2511.11462)
*Kevin Chen,Kenneth W. Parker,Anish Arora*

Main category: cs.LG

TL;DR: 该研究提出了一种基于纯机器学习的Transformer模型，用于将MoCap数据转换为雷达频谱图，显著降低了计算需求，并展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过机器学习方法，利用丰富的MoCap数据合成雷达频谱图，以解决雷达数据稀缺问题，并提供比物理方法更高效的计算方案。

Method: 采用基于Transformer的窗口化序列到序列模型，同时捕捉MoCap标记的空间关系和帧间时间动态。

Result: 实验表明，该方法生成的雷达频谱图在视觉和定量上均合理，具有良好的泛化能力，还能学习到多部位运动与多普勒特征的转换能力。

Conclusion: 该方法展示了Transformer在时间序列信号处理中的潜力，尤其适用于边缘计算和物联网雷达，并可通过MoCap数据增强稀缺的雷达数据集。

Abstract: We present a pure machine learning process for synthesizing radar spectrograms from Motion-Capture (MoCap) data. We formulate MoCap-to-spectrogram translation as a windowed sequence-to-sequence task using a transformer-based model that jointly captures spatial relations among MoCap markers and temporal dynamics across frames. Real-world experiments show that the proposed approach produces visually and quantitatively plausible doppler radar spectrograms and achieves good generalizability. Ablation experiments show that the learned model includes both the ability to convert multi-part motion into doppler signatures and an understanding of the spatial relations between different parts of the human body.
  The result is an interesting example of using transformers for time-series signal processing. It is especially applicable to edge computing and Internet of Things (IoT) radars. It also suggests the ability to augment scarce radar datasets using more abundant MoCap data for training higher-level applications. Finally, it requires far less computation than physics-based methods for generating radar data.

</details>


### [99] [Quantifying and Improving Adaptivity in Conformal Prediction through Input Transformations](https://arxiv.org/abs/2511.11472)
*Sooyong Jang,Insup Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种新的分箱方法和两个度量指标，以更准确地评估一致性预测的适应性，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性预测适应性评估方法存在分箱不平衡问题，导致覆盖率和集合大小的估计不准确。

Method: 提出了一种利用输入变换按难度排序样本并结合均匀质量分箱的方法，并引入了两种新的度量指标。此外，还提出了一种新的适应性预测集合算法。

Result: 实验表明，新提出的度量指标与适应性更相关，且新算法在图像分类和医疗任务上优于现有方法。

Conclusion: 通过改进的分箱方法和新的度量指标，该方法提供了更准确的适应性评估，并在实际任务中表现优越。

Abstract: Conformal prediction constructs a set of labels instead of a single point prediction, while providing a probabilistic coverage guarantee. Beyond the coverage guarantee, adaptiveness to example difficulty is an important property. It means that the method should produce larger prediction sets for more difficult examples, and smaller ones for easier examples. Existing evaluation methods for adaptiveness typically analyze coverage rate violation or average set size across bins of examples grouped by difficulty. However, these approaches often suffer from imbalanced binning, which can lead to inaccurate estimates of coverage or set size. To address this issue, we propose a binning method that leverages input transformations to sort examples by difficulty, followed by uniform-mass binning. Building on this binning, we introduce two metrics to better evaluate adaptiveness. These metrics provide more reliable estimates of coverage rate violation and average set size due to balanced binning, leading to more accurate adaptivity assessment. Through experiments, we demonstrate that our proposed metric correlates more strongly with the desired adaptiveness property compared to existing ones. Furthermore, motivated by our findings, we propose a new adaptive prediction set algorithm that groups examples by estimated difficulty and applies group-conditional conformal prediction. This allows us to determine appropriate thresholds for each group. Experimental results on both (a) an Image Classification (ImageNet) (b) a medical task (visual acuity prediction) show that our method outperforms existing approaches according to the new metrics.

</details>


### [100] [Data-efficient U-Net for Segmentation of Carbide Microstructures in SEM Images of Steel Alloys](https://arxiv.org/abs/2511.11485)
*Alinda Ezgi Gerçek,Till Korten,Paul Chekhonin,Maleeha Hassan,Peter Steinbach*

Main category: cs.LG

TL;DR: 提出了一种基于轻量级U-Net的数据高效分割方法，仅需10张标注的扫描电镜图像即可实现高精度的碳化物分割。


<details>
  <summary>Details</summary>
Motivation: 了解反应堆压力容器钢的微观结构对预测其机械性能至关重要，但传统的阈值分割方法因碳化物与基体灰度重叠而效果不佳。

Method: 使用轻量级U-Net（30.7M参数）构建数据高效分割流程，仅需10张标注图像进行训练。

Result: 模型在Dice-Sørensen系数上达到0.98，显著优于传统冶金图像分析方法（0.85），且标注工作量减少了一个数量级。

Conclusion: 该方法为合金设计提供了快速自动化的碳化物量化工具，展示了数据高效深度学习在反应堆压力容器钢分析中的潜力。

Abstract: Understanding reactor-pressure-vessel steel microstructure is crucial for predicting mechanical properties, as carbide precipitates both strengthen the alloy and can initiate cracks. In scanning electron microscopy images, gray-value overlap between carbides and matrix makes simple thresholding ineffective. We present a data-efficient segmentation pipeline using a lightweight U-Net (30.7~M parameters) trained on just \textbf{10 annotated scanning electron microscopy images}. Despite limited data, our model achieves a \textbf{Dice-Sørensen coefficient of 0.98}, significantly outperforming the state-of-the-art in the field of metallurgy (classical image analysis: 0.85), while reducing annotation effort by one order of magnitude compared to the state-of-the-art data efficient segmentation model. This approach enables rapid, automated carbide quantification for alloy design and generalizes to other steel types, demonstrating the potential of data-efficient deep learning in reactor-pressure-vessel steel analysis.

</details>


### [101] [FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models](https://arxiv.org/abs/2511.11505)
*Yonatan Dukler,Guihong Li,Deval Shah,Vikram Appia,Emad Barsoum*

Main category: cs.LG

TL;DR: FarSkip-Collective是一种通过跳过模型中的连接来重叠计算与通信的技术，成功应用于16B至109B参数的大型模型，保持精度并提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决分布式环境中MoEs（混合专家模型）的通信阻塞问题，以提高运行效率。

Method: 修改模型架构以跳过连接，使计算与通信重叠，并通过自蒸馏等技术转换大型模型。

Result: 成功转换了16B至109B参数模型，精度与原版相当（如Llama 4 Scout平均精度差异<1%），同时提升了训练和推理速度。

Conclusion: FarSkip-Collective能有效减少通信开销，保持模型精度，适用于大规模模型的分布式部署。

Abstract: Blocking communication presents a major hurdle in running MoEs efficiently in distributed settings. To address this, we present FarSkip-Collective which modifies the architecture of modern models to enable overlapping of their computation with communication. Our approach modifies the architecture to skip connections in the model and it is unclear a priori whether the modified model architecture can remain as capable, especially for large state-of-the-art models and while modifying all of the model layers. We answer this question in the affirmative and fully convert a series of state-of-the-art models varying from 16B to 109B parameters to enable overlapping of their communication while achieving accuracy on par with their original open-source releases. For example, we convert Llama 4 Scout (109B) via self-distillation and achieve average accuracy within 1% of its instruction tuned release averaged across a wide range of downstream evaluations. In addition to demonstrating retained accuracy of the large modified models, we realize the benefits of FarSkip-Collective through optimized implementations that explicitly overlap communication with computation, accelerating both training and inference in existing frameworks.

</details>


### [102] [Generalizing Fair Clustering to Multiple Groups: Algorithms and Applications](https://arxiv.org/abs/2511.11539)
*Diptarka Chakraborty,Kushagra Chatterjee,Debarati Das,Tien-Long Nguyen*

Main category: cs.LG

TL;DR: 该研究扩展了最接近公平聚类问题的研究范围，从仅两组的限制扩展到任意数量的组，证明了问题的NP-hard性质，并提出高效的近似算法。同时，改进了公平相关性聚类和公平共识聚类的近似保证，填补了研究空白。


<details>
  <summary>Details</summary>
Motivation: 聚类任务中常因数据偏见导致对边缘化群体的不公平表示，现有研究仅针对两组情况，而实际数据涉及多组（如年龄、种族、性别等），亟需扩展到多组场景以提高公平性。

Method: 研究首先证明多组情况下的NP-hard问题，随后提出高效的近似算法处理多组数据，并利用这些算法改进公平相关性聚类和公平共识聚类的近似保证。

Result: 高效的多组近似算法解决了现有研究的局限，同时在公平相关性聚类和公平共识聚类问题上取得了更优的近似结果。

Conclusion: 该研究在多组公平聚类问题上取得了突破，填补了现有研究的空白，为实际应用提供了更高效的解决方案。

Abstract: Clustering is a fundamental task in machine learning and data analysis, but it frequently fails to provide fair representation for various marginalized communities defined by multiple protected attributes -- a shortcoming often caused by biases in the training data. As a result, there is a growing need to enhance the fairness of clustering outcomes, ideally by making minimal modifications, possibly as a post-processing step after conventional clustering. Recently, Chakraborty et al. [COLT'25] initiated the study of \emph{closest fair clustering}, though in a restricted scenario where data points belong to only two groups. In practice, however, data points are typically characterized by many groups, reflecting diverse protected attributes such as age, ethnicity, gender, etc.
  In this work, we generalize the study of the \emph{closest fair clustering} problem to settings with an arbitrary number (more than two) of groups. We begin by showing that the problem is NP-hard even when all groups are of equal size -- a stark contrast with the two-group case, for which an exact algorithm exists. Next, we propose near-linear time approximation algorithms that efficiently handle arbitrary-sized multiple groups, thereby answering an open question posed by Chakraborty et al. [COLT'25].
  Leveraging our closest fair clustering algorithms, we further achieve improved approximation guarantees for the \emph{fair correlation clustering} problem, advancing the state-of-the-art results established by Ahmadian et al. [AISTATS'20] and Ahmadi et al. [2020]. Additionally, we are the first to provide approximation algorithms for the \emph{fair consensus clustering} problem involving multiple (more than two) groups, thus addressing another open direction highlighted by Chakraborty et al. [COLT'25].

</details>


### [103] [Optimizing Mixture of Block Attention](https://arxiv.org/abs/2511.11571)
*Guangxuan Xiao,Junxian Guo,Kasra Mazaheri,Song Han*

Main category: cs.LG

TL;DR: MoBA是一种通过稀疏注意力机制高效处理长上下文的模块，但缺乏理论分析和高效GPU实现。本文通过统计模型分析其性能，提出改进方案并实现高效GPU实现FlashMoBA。


<details>
  <summary>Details</summary>
Motivation: 解决MoBA缺乏理论分析和高效GPU实现的问题，以推动其实际应用。

Method: 提出统计模型分析MoBA机制，识别改进方向（小分块尺寸和短卷积），并开发高效GPU内核FlashMoBA。

Result: 改进后的MoBA模型性能与密集注意力基线相当，FlashMoBA在小分块时比FlashAttention-2快14.7倍。

Conclusion: 结合理论分析和硬件优化，MoBA的性能和效率得到显著提升，为长上下文处理提供实用解决方案。

Abstract: Mixture of Block Attention (MoBA) (Lu et al., 2025) is a promising building block for efficiently processing long contexts in LLMs by enabling queries to sparsely attend to a small subset of key-value blocks, drastically reducing computational cost. However, the design principles governing MoBA's performance are poorly understood, and it lacks an efficient GPU implementation, hindering its practical adoption. In this paper, we first develop a statistical model to analyze MoBA's underlying mechanics. Our model reveals that performance critically depends on the router's ability to accurately distinguish relevant from irrelevant blocks based on query-key affinities. We derive a signal-to-noise ratio that formally connects architectural parameters to this retrieval accuracy. Guided by our analysis, we identify two key pathways for improvement: using smaller block sizes and applying a short convolution on keys to cluster relevant signals, which enhances routing accuracy. While theoretically better, small block sizes are inefficient on GPUs. To bridge this gap, we introduce FlashMoBA, a hardware-aware CUDA kernel that enables efficient MoBA execution even with the small block sizes our theory recommends. We validate our insights by training LLMs from scratch, showing that our improved MoBA models match the performance of dense attention baselines. FlashMoBA achieves up to 14.7x speedup over FlashAttention-2 for small blocks, making our theoretically-grounded improvements practical. Code is available at: https://github.com/mit-han-lab/flash-moba.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [104] [Privacy protection under the exposure of systems' prior information](https://arxiv.org/abs/2511.10771)
*Le Liu,Yu Kawano,Ming Cao*

Main category: eess.SY

TL;DR: 该论文提出了一种针对离散时间线性时不变系统的新隐私保护方法，特别针对对手拥有系统先验知识（如稳态）的场景。通过定制化的点最大泄漏（PML）隐私标准，分析了其性能，并与差分隐私和互信息隐私进行了比较。


<details>
  <summary>Details</summary>
Motivation: 由于系统状态可能涉及敏感信息，隐私保护至关重要。然而，当前在对手拥有系统先验知识（如稳态）的情况下，如何有效保护隐私仍是一个未解的问题。

Method: 采用点最大泄漏（PML）隐私标准，推导了其必要和充分条件，并设计了高效的设计流程。同时分析了PML与差分隐私、互信息隐私的关系，并从PML角度重新审视了卡尔曼滤波器。

Result: 论文推导了PML隐私的理论边界，并给出了一个分布式传感隐私保护的案例研究，展示了方法的有效性。

Conclusion: PML隐私标准为系统隐私保护提供了新的理论框架，尤其是在对手拥有先验知识的复杂场景下，为实际应用提供了可行的设计方法。

Abstract: For systems whose states implicate sensitive information, their privacy is of great concern. While notions like differential privacy have been successfully introduced to dynamical systems, it is still unclear how a system's privacy can be properly protected when facing the challenging yet frequently-encountered scenario where an adversary possesses prior knowledge, e.g., the steady state, of the system. This paper presents a new systematic approach to protect the privacy of a discrete-time linear time-invariant system against adversaries knowledgeable of the system's prior information. We employ a tailored \emph{pointwise maximal leakage (PML) privacy} criterion. PML characterizes the worst-case privacy performance, which is sharply different from that of the better-known mutual-information privacy. We derive necessary and sufficient conditions for PML privacy and construct tractable design procedures. Furthermore, our analysis leads to insight into how PML privacy, differential privacy, and mutual-information privacy are related. We then revisit Kalman filters from the perspective of PML privacy and derive a lower bound on the steady-state estimation-error covariance in terms of the PML parameters. Finally, the derived results are illustrated in a case study of privacy protection for distributed sensing in smart buildings.

</details>


### [105] [Retail electricity costs and emissions incentives are misaligned for commercial and industrial power consumers](https://arxiv.org/abs/2511.10775)
*Fletcher T. Chapin,Akshay K. Rao,Adhithyan Sakthivelu,Carson I. Tucker,Eres David,Casey S. Chen,Erin Musabandesu,Meagan S. Mauter*

Main category: eess.SY

TL;DR: 该论文研究了美国商业和工业用电增长的成本及碳排放影响，结合时空数据集分析了电价与排放激励的对齐情况，发现现有电价结构与经济及排放激励的广泛不一致性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在揭示美国商业和工业用电增长对成本及碳排放的影响，为电力消费者和公用事业公司提供透明数据支持。

Method: 通过时空数据集和时间序列近似方法，量化电价与排放激励的对齐情况，并比较需求响应计划和排放因子数据。

Result: 分析显示电价与碳排放激励之间存在显著的时空异质性，且现有电价结构导致经济与排放激励的广泛不一致性。

Conclusion: 研究强调选址对电力成本和碳排放的重要性，并指出现有电价结构可能阻碍电气化实现碳减排目标。

Abstract: Electrification is contributing to substantial growth in U.S. commercial and industrial loads, but the cost and Scope 2 carbon emission implications of this load growth are opaque for both power consumers and utilities. This work describes a unique spatiotemporally resolved data set of U.S. electricity costs and emissions and applies time series approximation methods to quantify the alignment of electricity cost and emission incentives for large commercial and industrial consumers. We present a comprehensive spatiotemporal dataset of U.S. price-based demand response (i.e., tariff) and incentive-based demand response (IBDR) programs, enabling direct comparison to previously published marginal emission factor (MEF), average emission factor (AEF), and day-ahead market (DAM) prices. We resolved the structural incompatibility and fragmentation of these datasets by developing time series approximations of discrete data and unifying geospatially heterogeneous datasets. Analysis of these datasets reveals significant spatial and temporal heterogeneity in cost and carbon emissions incentives for demand-side energy flexibility, underscoring the importance of site selection as a key factor influencing power costs and scope 2 emissions. Analysis also reveals broad misalignment of economic and emissions incentives under existing electricity tariff structures, meaning tariffs are incentivizing consumption of more carbon-intensive electricity, and highlighting potential barriers to electrification delivering carbon savings.

</details>


### [106] [Semantic Property Maps for Driving Applications](https://arxiv.org/abs/2511.10798)
*Marcus Greiff,Ray Zhang,Takeru Shirasawa,John Subosits*

Main category: eess.SY

TL;DR: 结合车辆信号和相机数据，通过贝叶斯矩匹配更新概率地图，在线生成车辆参数的空间地图以优化驾驶控制系统。


<details>
  <summary>Details</summary>
Motivation: 解决仅依赖瞬时车辆信号参数估计的局限性，提升驾驶控制系统的预测性能。

Method: 使用共轭先验构建地图表示，结合车辆信号和语义信息，通过贝叶斯矩匹配更新参数概率地图。

Result: 生成了一个在线适应的车辆参数空间地图，并为相关参数似然统计的空间平滑性提供了理论保证。

Conclusion: 该方法能够增强驾驶控制系统的性能，并具有理论上的可靠性。

Abstract: We consider the problem of estimating the parameters of a vehicle dynamics model for predictive control in driving applications. Instead of solely using the instantaneous parameters estimated from the vehicle signals, we combine this with cameras and update a probabilistic map with parameter estimates and semantic information using Bayesian moment matching. Key to this approach is the map representation, which is constructed with conjugate priors to the measurement likelihoods and defined in the same path coordinates as the vehicle controller, such that the map can be externalized to provide a local representation of the parameter likelihoods that vary in space. The result is a spatial map of vehicle parameters adapted online to enhance the driving control system. We provide theoretical guarantees on the smoothness of relevant parameter likelihood statistics as a function of space, which is critical for their use in predictive control.

</details>


### [107] [Tissue Activation Calculation in Dual-lead Deep Brain Stimulation](https://arxiv.org/abs/2511.10844)
*Anna Franziska Frigge,Alexander Medvedev*

Main category: eess.SY

TL;DR: 传统深部脑刺激（DBS）常用单侧模型独立计算，但在多电极近距离植入时可能低估或高估激活效果。


<details>
  <summary>Details</summary>
Motivation: 研究多电极DBS中电场交互对激活区域（VTA）的影响，避免独立计算导致的误差。

Method: 通过比较全局双电极模型与单电极近似方法，分析12例多发性硬化震颤患者的VTA差异。

Result: 单电极叠加法会低估或高估激活效果，近距离电极需考虑电场的复杂交互。

Conclusion: 多电极DBS需采用全局模型计算，避免独立生成VTA导致的误差，同样适用于强迫症患者研究。

Abstract: Deep Brain Stimulation (DBS) is a well-established neurosurgical treatment aiming at symptom alleviation in a range of neurological and psychiatric diseases. Computational models of DBS are widely used to investigate the effects of stimulation on neural tissue, to explore stimulation targets and sweetspots, and ultimately, to aid clinicians in the DBS programming by calculating the stimulation parameters. Commonly, DBS is performed bilaterally, i.e. with one lead in each brain hemisphere, where computational models are solved independently for one lead at a time. This paper treats scenarios where multiple DBS leads are implanted in close proximity to one another, resulting in interacting electrical fields and, therefore, potentially overlapping stimulation spreads. In particular, a global dual-lead model is compared to approximations derived from single-lead approaches in a cohort of twelve multiple sclerosis (MS) tremor patients. It is concluded that simple superposition of volumes of tissue activated (VTAs) underestimates activation, while superposition of electric fields or activating functions leads to overestimation. It is concluded that given close proximity of DBS leads, the VTA cannot be computed individually as stimulation fields exhibit significant and complex interaction. The approach is extended to modeling two obsessive compulsive disorder patients with medially placed leads, where similar VTA discrepancies as in the MS patient cohort are observed.

</details>


### [108] [Adaptive Digital Twin of Sheet Metal Forming via Proper Orthogonal Decomposition-Based Koopman Operator with Model Predictive Control](https://arxiv.org/abs/2511.10852)
*Yi-Ping Chen,Derick Suarez,Ying-Kuan Tsai,Vispi Karkaria,Guanzhong Hu,Zihan Chen,Ping Guo,Jian Cao,Wei Chen*

Main category: eess.SY

TL;DR: 论文提出了一种自适应数字孪生框架，结合降阶物理模型和数据驱动方法，实现非线性制造系统的实时控制和优化。


<details>
  <summary>Details</summary>
Motivation: 数字孪生技术在金属成形等复杂制造过程中面临耦合时空行为和非线性关系的挑战，尤其是缺乏自主规划成形策略的能力。

Method: 框架集成POD进行降维，结合Koopman算子在提升空间中线性化非线性系统，并通过RLS算法实时更新模型参数，利用MPC进行决策。

Result: 在机器人驱动的英语轮板材成形系统中，自适应数字孪生成功实现了目标形状控制，并捕捉了非稳态过程行为。

Conclusion: 该框架为非线性制造系统提供了一个通用、可解释且高效的自适应数字孪生方法，支持自主控制和优化。

Abstract: Digital Twin (DT) technologies are transforming manufacturing by enabling real-time prediction, monitoring, and control of complex processes. Yet, applying DT to deformation-based metal forming remains challenging because of the strongly coupled spatial-temporal behavior and the nonlinear relationship between toolpath and material response. For instance, sheet-metal forming by the English wheel, a highly flexible but artisan-dependent process, still lacks digital counterparts that can autonomously plan and adapt forming strategies. This study presents an adaptive DT framework that integrates Proper Orthogonal Decomposition (POD) for physics-aware dimensionality reduction with a Koopman operator for representing nonlinear system in a linear lifted space for the real-time decision-making via model predictive control (MPC). To accommodate evolving process conditions or material states, an online Recursive Least Squares (RLS) algorithm is introduced to update the operator coefficients in real time, enabling continuous adaptation of the DT model as new deformation data become available. The proposed framework is experimentally demonstrated on a robotic English Wheel sheet metal forming system, where deformation fields are measured and modeled under varying toolpaths. Results show that the adaptive DT is capable of controlling the forming process to achieve the given target shape by effectively capturing non-stationary process behaviors. Beyond this case study, the proposed framework establishes a generalizable approach for interpretable, adaptive, and computationally-efficient DT of nonlinear manufacturing systems, bridging reduced-order physics representations with data-driven adaptability to support autonomous process control and optimization.

</details>


### [109] [Convergence of Flow-Policy Gradient Learning for Linear Quadratic Regulator Problems](https://arxiv.org/abs/2511.11131)
*Farnaz Adib Yaghmaie,Arunava Naha*

Main category: eess.SY

TL;DR: Flow $Q$-learning integrates expert demonstrations into actor-critic learning, focusing on a 'one-step policy' network. This paper analyzes convergence and stability in linear quadratic problems under offline settings, supported by new theoretical formulations and simulations.


<details>
  <summary>Details</summary>
Motivation: The study aims to understand the convergence and stability of the 'one-step policy' in Flow $Q$-learning, particularly for linear quadratic problems, to enhance the reliability of integrating expert demonstrations into reinforcement learning frameworks.

Method: The authors propose a new formulation of the one-step policy loss based on the average expected cost and behavioral cloning loss, leveraging existing policy gradient theory to analyze convergence properties. Simulations on a linearized inverted pendulum validate the findings.

Result: The theoretical analysis and simulations demonstrate the convergence property and stability of the one-step policy, highlighting the effectiveness of the proposed formulation in offline settings.

Conclusion: The paper provides a robust theoretical foundation for the convergence and stability of the one-step policy in Flow $Q$-learning, validating the approach with practical simulations and paving the way for more reliable integration of expert demonstrations.

Abstract: Flow $Q$-learning has recently been introduced to integrate learning from expert demonstrations into an actor-critic structure. Central to this innovation is the ``the one-step policy'' network, which is optimized through a $Q$-function that is regularized with the behavioral cloning from expert trajectories, allowing learning more expressive policies using flow-based generative models. In this paper, we studied the convergence property and stabilizablity of the one-step policy during learning for linear quadratic problems under the offline settings. Our theoretical results are based on a new formulation of the one-step policy loss based on the average expected cost, and regularized with the behavioral cloning loss. Such a formulation allows us to tap into existing strong theoretical results from the policy gradient theorem to study the convergence properties of the one-step policy. We verify our theoretical finding with simulation results on a linearized inverted pendulum.

</details>


### [110] [Prognostics and Health Management in Polymer Electrolyte Fuel Cells: Current Trends, Challenges, and Future Directions](https://arxiv.org/abs/2511.11180)
*Farideh Abdollahi,Kourosh Malek,Thomas Kadyk,Nadiia Kulyk,Christophe Gerling,Michael H. Eikerling*

Main category: eess.SY

TL;DR: 本文回顾了聚合物电解质燃料电池（PEFC）的预测与健康管理（PHM）的最新进展，重点讨论了降解机制、建模方法及开放式挑战，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: PEFC的可靠性和寿命评估对实际应用至关重要，但目前缺乏将诊断和预测结果转化为实时系统响应的有效方法，需要进一步研究以解决这一挑战。

Method: 本文通过文献综述，分析了物理感知、数据驱动和混合建模方法在PEFC PHM中的应用，并探讨了当前的关键挑战。

Result: 尽管在诊断和剩余寿命估计方面取得了进展，但将PHM结果转化为可操作的策略仍具挑战性，未来需关注数据稀缺、传感器集成和跨学科研究等问题。

Conclusion: 未来的PHM系统需通过材料创新、人工智能和数字孪生等技术进一步改进，以确保PEFC在实际应用中的可行性。

Abstract: Prognostics and Health Management is crucial for the reliability and lifetime assessment of Polymer Electrolyte Fuel Cells (PEFCs). Here, we review the current advances on this topic, focusing mainly on key degradation mechanisms and methodologies such as physics-aware, data-driven, and hybrid modeling approaches. Key open challenges are analyzed, including the need for more accurate degradation modeling, effective management of multi-stack systems, and advancements in the currently underdeveloped action phase, in which diagnostic and prognostic insights are translated into real-time system responses, such as dynamic load derating, thermal-management adjustments, or automated maintenance triggers, to prevent failures and extend PEFC life. While notable strides have been made in recent years in diagnostics and remaining useful life estimation, it remains challenging to seamlessly integrate these insights into actionable strategies. Future directions highlight the need to address data scarcity and advance interdisciplinary research. Key focus areas include sensor integration, artificial intelligence, and digital twins. Additionally material innovations play a crucial role in bridging existing gaps. This work, therefore, intends to map the further development of Prognostics and Health Management systems toward ensuring the viability of PEFCs in practical applications.

</details>


### [111] [Numerical Discretization Schemes that Preserve Flatness](https://arxiv.org/abs/2511.11183)
*Ashutosh Jindal,Florentina Nicolau,David Martin Diego,Ravi Banavar*

Main category: eess.SY

TL;DR: 论文探讨了如何在离散化过程中保持差分平展性，并基于离散化映射构建了相关数值方案。


<details>
  <summary>Details</summary>
Motivation: 连续时间非线性系统的控制（如运动规划和轨迹跟踪）中，差分平展性很重要，但离散化通常不保持这一特性。论文旨在解决这一问题。

Method: 基于离散化映射的概念，构建了能保持平展性的数值方案。

Result: 提出了在离散化过程中保持差分平展性的有效方法。

Conclusion: 通过构造特定的数值方案，成功解决了离散化过程中平展性丢失的问题。

Abstract: Differential flatness serves as a powerful tool for controlling continuous time nonlinear systems in problems such as motion planning and trajectory tracking. A similar notion, called difference flatness, exists for discrete-time systems. Although many control systems evolve in continuous time, control implementation is performed digitally, requiring discretization. It is well known in the literature that discretization does not necessarily preserve structural properties, and it has been established that, in general, flatness is not preserved under discretization (whether exact or approximate). In this paper, inspired by our previous work [1] and based on the notion of discretization maps, we construct numerical schemes that preserve flatness.

</details>


### [112] [Language-Aided State Estimation](https://arxiv.org/abs/2511.11285)
*Yuki Miyoshi,Masaki Inoue,Yusuke Fujimoto*

Main category: eess.SY

TL;DR: 论文提出了一个语言辅助粒子滤波器（LAPF），通过自然语言处理整合人类观察数据，用于物理系统的状态估计，并在灌溉渠水位估计问题中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 利用社交媒体和聊天平台中易于获取的自然语言数据，将其作为人类感知信息，解决物理系统的状态估计问题。

Method: 提出了语言辅助粒子滤波器（LAPF），通过自然语言处理结构化人类观察数据，并将其纳入状态估计的更新步骤。

Result: LAPF在灌溉渠水位估计问题中表现出有效性。

Conclusion: 该方法通过自然语言处理成功整合人类观察数据，可用于物理系统的状态估计。

Abstract: Natural language data, such as text and speech, have become readily available through social networking services and chat platforms. By leveraging human observations expressed in natural language, this paper addresses the problem of state estimation for physical systems, in which humans act as sensing agents. To this end, we propose a Language-Aided Particle Filter (LAPF), a particle filter framework that structures human observations via natural language processing and incorporates them into the update step of the state estimation. Finally, the LAPF is applied to the water level estimation problem in an irrigation canal and its effectiveness is demonstrated.

</details>


### [113] [Modeling and Physics-Enhanced Fault Detection in Wastewater Pump Stations](https://arxiv.org/abs/2511.11304)
*Katayoun Eshkofti,Henrik Sandberg,Mikael Nilsson,Matthieu Barreau*

Main category: eess.SY

TL;DR: 该论文提出了一种高保真、物理增强的废水泵站模拟器，用于生成数据驱动的分析数据集，并开发了故障检测与隔离的统计和数学框架。


<details>
  <summary>Details</summary>
Motivation: 废水泵站是关键基础设施，但目前监测仍依赖人工，缺乏合适的算法方法和数据支持，因此需要开发模拟器和故障检测方法。

Method: 论文引入了一种参数驱动的三泵废水站模拟器，能够捕捉瞬态水力机械动态，并提出了故障检测与隔离的统计框架，包括嵌套模型F检验和切线残差方法。

Result: 模拟器与市政站的高频SCADA数据比较显示关键指标高度一致。提出的框架支持假设研究、早期故障诊断，并为基于状态的维护提供可行建议。

Conclusion: 该模拟器和故障检测框架为废水泵站的监测与维护提供了有效工具，有助于提升基础设施的可靠性和维护效率。

Abstract: Monitoring wastewater pump stations is essential because they are critical infrastructure. However, monitoring is still often performed manually due to the lack of suitable algorithmic methods and data. This paper introduces a high-fidelity, physics-enhanced simulator of a three-pump wastewater station that captures transient hydro-mechanical dynamics at a one-second resolution. The simulator is fully parameter-driven, adaptable to other wastewater stations, and capable of generating datasets for data-driven analytics. It can also generate balanced faulty datasets when real failures are scarce or confidential. A comparison with high-frequency SCADA data from a municipal station shows strong agreement across key operational metrics. Furthermore, the paper proposes robust statistical and mathematical frameworks for fault detection and isolation, including a nested-model F-test to detect pump degradation or system faults, and a tangent residual approach to distinguish pump faults from system faults using operating-point kinematics. This framework enables what-if studies, facilitates early fault diagnosis based on flow rate and head, and provides actionable insights for condition-based maintenance in wastewater pumping infrastructure.

</details>


### [114] [Policy Optimization for Unknown Systems using Differentiable Model Predictive Control](https://arxiv.org/abs/2511.11308)
*Riccardo Zuliani,Efe C. Balta,John Lygeros*

Main category: eess.SY

TL;DR: 论文提出了一种结合可微分优化和零阶优化的新型MPC策略优化框架，以解决模型不准确导致的性能问题。


<details>
  <summary>Details</summary>
Motivation: 基于模型的策略优化常因系统动力学模型不准确而导致闭环性能不佳，尤其在MPC策略中表现明显。

Method: 结合基于模型和无模型的梯度估计方法，利用可微分优化与零阶优化提升性能。

Result: 在12维四旋翼模型非线性控制任务中，方法展现了快速瞬态性能和收敛保证。

Conclusion: 该方法在模型不确定情况下也能保持良好性能，优于完全数据驱动的方案。

Abstract: Model-based policy optimization often struggles with inaccurate system dynamics models, leading to suboptimal closed-loop performance. This challenge is especially evident in Model Predictive Control (MPC) policies, which rely on the model for real-time trajectory planning and optimization. We introduce a novel policy optimization framework for MPC-based policies combining differentiable optimization with zeroth-order optimization. Our method combines model-based and model-free gradient estimation approaches, achieving faster transient performance compared to fully data-driven approaches while maintaining convergence guarantees, even under model uncertainty. We demonstrate the effectiveness of the proposed approach on a nonlinear control task involving a 12-dimensional quadcopter model.

</details>


### [115] [Data-Driven Stabilization of Continuous-Time LTI Systems from Noisy Input-Output Data](https://arxiv.org/abs/2511.11417)
*Alessandro Bosso,Marco Borghesi,Andrea Iannelli,Bowen Yi,Giuseppe Notarstefano*

Main category: eess.SY

TL;DR: 提出一种直接从受噪声影响的输入输出轨迹计算连续时间线性时不变系统稳定控制器的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在直接从噪声干扰的数据中设计稳定控制器，避免对系统模型的需求。

Method: 结合非最小实现观测器和基于LMI的反馈律，仅依赖可用数据。

Result: 在适当激励条件和噪声能量界限下，LMI的可行性是充分必要条件。

Conclusion: 方法有效，提供了可行性条件和噪声能量界限的计算指南。

Abstract: We present an approach to compute stabilizing controllers for continuous-time linear time-invariant systems directly from an input-output trajectory affected by process and measurement noise. The proposed output-feedback design combines (i) an observer of a non-minimal realization of the plant and (ii) a feedback law obtained from a linear matrix inequality (LMI) that depends solely on the available data. Under a suitable interval excitation condition and knowledge of a noise energy bound, the feasibility of the LMI is shown to be necessary and sufficient for stabilizing all non-minimal realizations consistent with the data. We further provide a condition for the feasibility of the LMI related to the signal-to-noise ratio, guidelines to compute the noise energy bound, and numerical simulations that illustrate the effectiveness of the approach.

</details>


### [116] [Heterogeneous CACC Coexistence: Simulation, Analysis, and Modeling](https://arxiv.org/abs/2511.11429)
*Lorenzo Ghiro,Marco Franceschini,Renato Lo Cigno,Michele Segata*

Main category: eess.SY

TL;DR: 研究了异构车辆在协同自适应巡航控制（CACC）编队中的性能，通过模拟实验评估了不同CACC组合的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 市场上不同制造商的车辆可能采用不同的CACC算法，这引发了对异构编队能否安全合作及其性能的疑问。

Method: 通过模拟实验评估了三种CACC算法的组合性能，包括微观安全性测试和宏观交通影响分析。

Result: 某些CACC组合表现稳健且安全，而其他组合在安全、舒适性或效率上存在局限。

Conclusion: 异构编队的系统设计需要谨慎，并需开发理论框架以支持建模与分析。

Abstract: The design of Cooperative Adaptive Cruise Control (CACC) algorithms for vehicle platooning has been extensively investigated, leading to a wide range of approaches with different requirements and performance. Most existing studies evaluate these algorithms under the assumption of homogeneous platoons, i.e., when all platoon members adopt the same CACC. However, market competition is likely to result in vehicles from different manufacturers implementing distinct CACCs. This raises fundamental questions about whether heterogeneous vehicles can safely cooperate within a platoon and what performance can be achieved. To date, these questions have received little attention, as heterogeneous platoons are difficult to model and analyze. In this work, we introduce the concept of mixed platoons, i.e., platoons made of vehicles running heterogeneous CACCs, and we study their performance through simulation-based experiments. We consider mixtures of three well-established CACCs from the literature. In the first part of the paper, we study a single mixed platoon in isolation to understand the microscopic effects on safety: we evaluate the performance of various CACC-mixtures across speed change and emergency braking scenarios. In the second part, we examine a high-density ring-road scenario to assess macroscopic impacts on safety, comfort, and traffic throughput, especially comparing throughput results with those obtained from vehicles controlled by a standard Adaptive Cruise Control (ACC) or by human drivers. Our findings highlight that some combinations of CACCs can operate robustly and safely, while others exhibit critical limitations in safety, comfort, or efficiency. These results emphasize the need for careful system design and the development of theoretical frameworks for modeling heterogeneous platoons.

</details>
